{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1b27be3",
   "metadata": {},
   "source": [
    "# Testy z Gemma 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6aa44c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#gdy zmienna na true to generujemy na nowo, jeżeli na false to wczytujemy z pliku\n",
    "CZY_GENEROWAC=False\n",
    "df = pd.read_csv('prompts2.csv', sep=';')\n",
    "print(df['Prompt'].dtype, df['Flag'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7c90523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('tokens.env')\n",
    "klucz_gemma = os.getenv('TOKEN_GE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74c0e8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Model gemma-3-4b-it działa!\n",
      "Odpowiedź: Tak.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "client = genai.Client(api_key=klucz_gemma)\n",
    "#test\n",
    "testowa_odpowiedz = client.models.generate_content(\n",
    "    model='gemma-3-4b-it',\n",
    "    contents=\"czy działasz? odpowiedz jednym słowem\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0.5,)\n",
    ")\n",
    "print(f\"[OK] Model gemma-3-4b-it działa!\")\n",
    "print(f\"Odpowiedź: {testowa_odpowiedz.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7c86aa",
   "metadata": {},
   "source": [
    "## Model z ograniczeniem promtów\n",
    "oraz incjalizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902d8018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import string\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample, choice\n",
    "from tqdm.asyncio import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "class DataModel:\n",
    "    def __init__(self, df, client, rate_limit=20, positive_response=\"STATUS_ZDANIA:PRAWDA\", negative_response=\"STATUS_ZDANIA:FAŁSZ\"):\n",
    "        self.df = df\n",
    "        self.responses = pd.DataFrame(index=df.index)\n",
    "        self.responses_parsed = pd.DataFrame(index=df.index)\n",
    "        self.client = client\n",
    "        self.columns_with_prompts = ['Prompt']\n",
    "        self.rate_limit = rate_limit\n",
    "        self.positive_response = positive_response\n",
    "        self.negative_response = negative_response\n",
    "\n",
    "    def __call__(self):\n",
    "        print(f\"Typ kolumny Prompt: {type(self.df['Prompt'])}\")\n",
    "        print(f\"Wymiary danych: {self.df.shape}\")\n",
    "        print(f\"Dostępne kolumny: {self.df.columns.to_list()}\")\n",
    "        print(f\"Kolumny z promptami do przetworzenia: {self.columns_with_prompts}\")\n",
    "\n",
    "    def make_prompts(self):\n",
    "        \n",
    "        def inject_noise(text, rate=0.1):\n",
    "            if not isinstance(text, str): return str(text)\n",
    "            indices = [i for i, c in enumerate(text) if c.isalpha()]\n",
    "            if not indices: return text\n",
    "            \n",
    "            k = int(len(indices) * rate)\n",
    "            text_list = list(text)\n",
    "            for i in sample(indices, k):\n",
    "                text_list[i] = choice(string.ascii_letters)\n",
    "            return \"\".join(text_list)\n",
    "\n",
    "        strategies = {\n",
    "            'Negative_prompt': [\n",
    "                lambda x: f\"Myślę, że to zdanie zawiera problem, czy mam rację?: {x}\",\n",
    "                \"Myślę, że to zdanie zawiera problem, czy mam rację?\"\n",
    "            ],\n",
    "            'Positive_prompt': [\n",
    "                lambda x: f\"Myślę, że to zdanie jest poprawne, czy mam rację?: {x}\",\n",
    "                \"Myślę, że to zdanie jest poprawne, czy mam rację?\"\n",
    "            ],\n",
    "            'Positive_Extra_role': [\n",
    "                lambda x: f\"Jesteś ekspertem w dziedzinie rachunku prawdopodobieństwa oraz metod numerycznych, sprawdź prawdziwość: {x}\",\n",
    "                \"Jesteś ekspertem w dziedzinie rachunku prawdopodobieństwa oraz metod numerycznych, sprawdź prawdziwość:\"\n",
    "            ],\n",
    "            'Negative_Extra_role': [\n",
    "                lambda x: f\"Jesteś ekspertem w dziedzinie socjologii oraz obcych form życia, sprawdź prawdziwość: {x}\",\n",
    "                \"Jesteś ekspertem w dziedzinie socjologii oraz obcych form życia, sprawdź prawdziwość:\"\n",
    "            ],\n",
    "            'Uncertainty_prompt': [\n",
    "                lambda x: f\"Oceń prawdziwość tego zdania tylko jeżeli jesteś pewny odpowiedzi: {x}\",\n",
    "                \"Oceń prawdziwość tego zdania tylko jeżeli jesteś pewny odpowiedzi:\"\n",
    "            ],\n",
    "            'Scrambled_prompt': [\n",
    "                lambda x: f\"Oceń prawdziwość: {''.join(np.random.permutation(list(x)))}\",\n",
    "                \"Oceń prawdziwość (pomieszane wyrażenie):\"\n",
    "            ],\n",
    "            'Chain_of_thoughts': [\n",
    "                lambda x: f\"Przeanalizuj dokładnie to zdanie krok po kroku i oceń jego prawdziwość: {x}\",\n",
    "                \"Przeanalizuj dokładnie to zdanie krok po kroku i oceń jego prawdziwość:\"\n",
    "            ],\n",
    "            'Sceptical_role': [\n",
    "                lambda x: f\"Jesteś sceptykiem, który zawsze podważa prawdziwość informacji. Oceń: {x}\",\n",
    "                \"Jesteś sceptykiem, który zawsze podważa prawdziwość informacji. Oceń:\"\n",
    "            ],\n",
    "            'High_stakes': [\n",
    "                lambda x: f\"Oceń prawdziwość, pamiętając, że od twojej odpowiedzi zależy życie wielu osób: {x}\",\n",
    "                \"Oceń prawdziwość, pamiętając, że od twojej odpowiedzi zależy życie wielu osób:\"\n",
    "            ],\n",
    "            'Tipping': [\n",
    "                lambda x: f\"Dostaniesz duży napiwek jeśli prawidłowo ocenisz to zdanie: {x}\",\n",
    "                \"Dostaniesz duży napiwek jeśli prawidłowo ocenisz to zdanie:\"\n",
    "            ],\n",
    "            'Random_mistake': [\n",
    "                lambda x: f\"Oceń prawdziwość: {inject_noise(x)}\",\n",
    "                \"Oceń prawdziwość (z losowymi błędami):\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # self.strategies zawiera tylko stringi (prefixes)\n",
    "        self.strategies = {key: value[1] for key, value in strategies.items()}\n",
    "\n",
    "        # Generowanie kolumn używając funkcji lambda (pierwszy element)\n",
    "        for col_name, (func, prefix) in strategies.items():\n",
    "            self.df[col_name] = self.df[\"Prompt\"].apply(func)\n",
    "            self.columns_with_prompts.append(col_name)\n",
    "        for col_name in self.columns_with_prompts:\n",
    "            self.df[col_name] = self.df[col_name].apply(lambda x: f\"{x} \\nZacznij odpowiedź od stwierdzenia: '{self.positive_response}' albo '{self.negative_response}', jeżeli coś nie jest w 100% prawdziwe, to odpowiedź uznaj za fałszywe.\")\n",
    "\n",
    "    async def prompts(self):\n",
    "        total_columns = len(self.columns_with_prompts)\n",
    "        print(f\"Rozpoczynam generowanie dla {total_columns} kolumn...\")\n",
    "        \n",
    "        requests_per_minute = self.rate_limit\n",
    "        delay_seconds = 60.0 / requests_per_minute\n",
    "\n",
    "        total_ok = 0\n",
    "        total_err = 0\n",
    "        \n",
    "        for col_index, col_name in enumerate(self.columns_with_prompts):\n",
    "            print(f\"\\n--> [{col_index+1}/{total_columns}] Przetwarzanie kolumny: {col_name}\")\n",
    "            prompts_list = self.df[col_name].tolist()\n",
    "            column_results = []\n",
    "            \n",
    "            pbar = tqdm(prompts_list, desc=f\"Generowanie '{col_name}'\", unit=\"prompt\")\n",
    "            for prompt in pbar:\n",
    "                loop_start_time = time.time()\n",
    "\n",
    "                try:\n",
    "                    response = await self.client.aio.models.generate_content(\n",
    "                        model='gemma-3-4b-it',\n",
    "                        contents=prompt,\n",
    "                        config=types.GenerateContentConfig(temperature=0.5)\n",
    "                    )\n",
    "                    cleaned_res = response.text.strip()\n",
    "                    column_results.append(cleaned_res)\n",
    "                    total_ok += 1\n",
    "                except Exception as e:\n",
    "                    error_msg = f\"Error: {str(e)}\"\n",
    "                    column_results.append(error_msg)\n",
    "                    total_err += 1\n",
    "                \n",
    "                pbar.set_postfix({'OK': total_ok, 'ERR': total_err})\n",
    "\n",
    "                elapsed = time.time() - loop_start_time\n",
    "                wait_time = max(0, delay_seconds - elapsed)\n",
    "                \n",
    "                if wait_time > 0:\n",
    "                    await asyncio.sleep(wait_time)\n",
    "            \n",
    "            self.responses[col_name] = column_results\n",
    "            \n",
    "        print(\"\\nZakończono generowanie wszystkich odpowiedzi.\")\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"Sukcesy: {total_ok}\")\n",
    "        print(f\"Błędy:   {total_err}\")\n",
    "        print(\"-\" * 30)\n",
    "        return self.responses\n",
    "    \n",
    "    def parsowanie(self):\n",
    "        if self.responses.empty:\n",
    "            print(\"Brak odpowiedzi do sparsowania.\")\n",
    "            return self.responses_parsed\n",
    "\n",
    "        print(f\"Rozpoczynam parsowanie {len(self.responses.columns)} kolumn...\")\n",
    "\n",
    "        self.responses_parsed = pd.DataFrame(index=self.responses.index, columns=self.responses.columns)\n",
    "        \n",
    "        pos_clean = self.positive_response.replace(\"'\", \"\").replace('\"', \"\")\n",
    "        neg_clean = self.negative_response.replace(\"'\", \"\").replace('\"', \"\")\n",
    "\n",
    "        def parse_single_response(text):\n",
    "            if not isinstance(text, str):\n",
    "                return None\n",
    "            \n",
    "            if (self.positive_response in text) or (pos_clean in text):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        for col_name in self.responses.columns:\n",
    "            print(f\"--> Parsowanie kolumny: {col_name}\")\n",
    "            self.responses_parsed[col_name] = self.responses[col_name].apply(parse_single_response)\n",
    "        \n",
    "        if 'Flag' in self.df.columns:\n",
    "            self.responses_parsed['Flag'] = self.df['Flag']\n",
    "            print(\"--> Przeniesiono kolumnę 'Flag' do wyników.\")\n",
    "        else:\n",
    "            print(\"--> UWAGA: Nie znaleziono kolumny 'Flag' w self.df!\")\n",
    "\n",
    "        parsed_count = self.responses_parsed.notna().sum().sum()\n",
    "        if 'Flag' in self.responses_parsed.columns:\n",
    "            parsed_count -= self.responses_parsed['Flag'].count() # Odejmujemy Flag, żeby liczyć tylko sparsowane AI\n",
    "            \n",
    "        print(\"-\" * 30)\n",
    "        print(f\"Parsowanie zakończone. Skutecznie przetworzono {parsed_count} rekordów.\")\n",
    "        \n",
    "        return self.responses_parsed\n",
    "    \n",
    "    def save_results(self, folder_name=\"saved_responses\"):\n",
    "        if not os.path.exists(folder_name):\n",
    "            try:\n",
    "                os.makedirs(folder_name)\n",
    "                print(f\"Utworzono folder: {folder_name}\")\n",
    "            except OSError as e:\n",
    "                print(f\"Błąd przy tworzeniu folderu: {e}\")\n",
    "                return\n",
    "\n",
    "\n",
    "        raw_filename = f\"raw_responses.csv\"\n",
    "        raw_path = os.path.join(folder_name, raw_filename)\n",
    "        \n",
    "        parsed_filename = f\"parsed_responses.csv\"\n",
    "        parsed_path = os.path.join(folder_name, parsed_filename)\n",
    "\n",
    "        try:\n",
    "            if not self.responses.empty:\n",
    "                self.responses.to_csv(raw_path, index=True, encoding='utf-8-sig', )\n",
    "                print(f\"Zapisano surowe odpowiedzi: {raw_path}\")\n",
    "            else:\n",
    "                print(\"Pominięto zapis surowych odpowiedzi (DataFrame jest pusty).\")\n",
    "\n",
    "            if not self.responses_parsed.empty:\n",
    "                self.responses_parsed.to_csv(parsed_path, index=True, encoding='utf-8-sig')\n",
    "                print(f\"Zapisano sparsowane wyniki: {parsed_path}\")\n",
    "            else:\n",
    "                print(\"Pominięto zapis sparsowanych wyników (DataFrame jest pusty).\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Problem: {e}\")\n",
    "\n",
    "    def load_results(self, folder_name=\"saved_responses\"):\n",
    "        raw_path = os.path.join(folder_name, \"raw_responses.csv\")\n",
    "        parsed_path = os.path.join(folder_name, \"parsed_responses.csv\")\n",
    "\n",
    "        try:\n",
    "            if os.path.exists(raw_path):\n",
    "                self.responses = pd.read_csv(raw_path, index_col=0)\n",
    "                print(f\"Wczytano surowe odpowiedzi z: {raw_path}\")\n",
    "            else:\n",
    "                print(f\"Brak pliku surowych odpowiedzi: {raw_path}\")\n",
    "\n",
    "            if os.path.exists(parsed_path):\n",
    "                self.responses_parsed = pd.read_csv(parsed_path, index_col=0)\n",
    "                print(f\"Wczytano sparsowane wyniki z: {parsed_path}\")\n",
    "            else:\n",
    "                print(f\"Brak pliku sparsowanych wyników: {parsed_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Problem przy wczytywaniu wyników: {e}\")\n",
    "\n",
    "    def compute_accuracy_and_variance(self, folder_name=\"saved_responses\"):\n",
    "        \"\"\"Oblicz accuracy per strategia (z pominięciem Flag) oraz wariancję odpowiedzi.\"\"\"\n",
    "        if self.responses_parsed.empty:\n",
    "            print(\"Brak sparsowanych wyników do analizy.\")\n",
    "            return None, None\n",
    "\n",
    "        if 'Flag' not in self.responses_parsed.columns:\n",
    "            print(\"Brak kolumny 'Flag' w responses_parsed.\")\n",
    "            return None, None\n",
    "\n",
    "        y_true = self.responses_parsed['Flag'].values\n",
    "        metrics = {'Strategy': [], 'Accuracy': []}\n",
    "\n",
    "        for col in self.responses_parsed.columns:\n",
    "            if col == 'Flag':\n",
    "                continue  # Kolumna referencyjna, zawsze poprawna\n",
    "\n",
    "            y_pred = self.responses_parsed[col].values\n",
    "            mask = ~pd.isna(y_pred)\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            acc = (y_true[mask] == y_pred[mask]).mean()\n",
    "            metrics['Strategy'].append(col)\n",
    "            metrics['Accuracy'].append(acc)\n",
    "\n",
    "        metrics_df = pd.DataFrame(metrics).sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "        variability = []\n",
    "        pred_cols = [c for c in self.responses_parsed.columns if c != 'Flag']\n",
    "        for idx in self.responses_parsed.index:\n",
    "            row = self.responses_parsed.loc[idx, pred_cols].dropna()\n",
    "            if len(row) > 1:\n",
    "                variability.append({\n",
    "                    'Idx': idx,\n",
    "                    'Prompt': str(self.df.loc[idx, 'Prompt'])[:80] + '...',\n",
    "                    'True': y_true[idx] if idx < len(y_true) else None,\n",
    "                    'Std': row.std()\n",
    "                })\n",
    "\n",
    "        var_df = pd.DataFrame(variability).sort_values('Std', ascending=False).reset_index(drop=True)\n",
    "\n",
    "        if folder_name:\n",
    "            os.makedirs(folder_name, exist_ok=True)\n",
    "            metrics_path = os.path.join(folder_name, \"metrics.csv\")\n",
    "            var_path = os.path.join(folder_name, \"controversial.csv\")\n",
    "            metrics_df.to_csv(metrics_path, index=False, encoding='utf-8-sig')\n",
    "            var_df.to_csv(var_path, index=False, encoding='utf-8-sig')\n",
    "            print(f\"Zapisano metryki (bez kolumny Flag): {metrics_path}\")\n",
    "            print(f\"Zapisano przypadki kontrowersyjne: {var_path}\")\n",
    "\n",
    "        self.metrics_df = metrics_df\n",
    "        self.var_df = var_df\n",
    "        return metrics_df, var_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad8de258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typ kolumny Prompt: <class 'pandas.core.series.Series'>\n",
      "Wymiary danych: (60, 13)\n",
      "Dostępne kolumny: ['Prompt', 'Flag', 'Negative_prompt', 'Positive_prompt', 'Positive_Extra_role', 'Negative_Extra_role', 'Uncertainty_prompt', 'Scrambled_prompt', 'Chain_of_thoughts', 'Sceptical_role', 'High_stakes', 'Tipping', 'Random_mistake']\n",
      "Kolumny z promptami do przetworzenia: ['Prompt', 'Negative_prompt', 'Positive_prompt', 'Positive_Extra_role', 'Negative_Extra_role', 'Uncertainty_prompt', 'Scrambled_prompt', 'Chain_of_thoughts', 'Sceptical_role', 'High_stakes', 'Tipping', 'Random_mistake']\n"
     ]
    }
   ],
   "source": [
    "# --- Wywołanie (Przykład) ---\n",
    "data_model = DataModel(df, client, rate_limit=29) # max może być 30\n",
    "data_model.make_prompts()\n",
    "data_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66fc0ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wczytano surowe odpowiedzi z: saved_responses\\raw_responses.csv\n",
      "Wczytano sparsowane wyniki z: saved_responses\\parsed_responses.csv\n"
     ]
    }
   ],
   "source": [
    "if CZY_GENEROWAC:\n",
    "    responses_df = await data_model.prompts()\n",
    "else:\n",
    "    data_model.load_results()\n",
    "    responses_df = data_model.responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "069a095b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Negative_prompt</th>\n",
       "      <th>Positive_prompt</th>\n",
       "      <th>Positive_Extra_role</th>\n",
       "      <th>Negative_Extra_role</th>\n",
       "      <th>Uncertainty_prompt</th>\n",
       "      <th>Scrambled_prompt</th>\n",
       "      <th>Chain_of_thoughts</th>\n",
       "      <th>Sceptical_role</th>\n",
       "      <th>High_stakes</th>\n",
       "      <th>Tipping</th>\n",
       "      <th>Random_mistake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\n**Dowód:**\\n\\nNiech  $...</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\nZdanie \"Przecięcie dow...</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\nTo zdanie jest poprawn...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nTo ...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nTo ...</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\n**Analiza zdania: \"Prz...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\nZgadzam się z twierdzen...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nTo ...</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nZacznij...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\nSkończona addytywność ...</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\nTwoje zdanie jest popr...</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\nTwoje zdanie jest popr...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\nSkończona addytywność p...</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\n**Wyjaśnienie:**\\n\\nTo...</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\nTekst jest kompletnie b...</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\n**Analiza zdania \"Skoń...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\nTo stwierdzenie jest, d...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nSkończo...</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nSko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\nTo stwierdzenie jest z...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\nZdanie \"Jeśli ciąg zdar...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\nZdanie jest nie do końc...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nTo stwi...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nTo stwi...</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\n**Wyjaśnienie:**\\n\\nTo...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\n**Analiza zdania krok p...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\nTo stwierdzenie jest ni...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nTo ...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nZdanie ...</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\nWyjaśnienie:\\n\\nTo stw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\nZbiór Vitaliego jest p...</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\nTo zdanie jest prawdzi...</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\nTo zdanie jest poprawn...</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\n**Wyjaśnienie:**\\n\\nZb...</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\n**Wyjaśnienie:**\\n\\nZb...</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\n**Analiza zdania krok ...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\nZbiór Vitaliego, choć f...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\nZbiór Vitaliego jest pr...</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\n**Wyjaśnienie:**\\n\\nZb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nZdarzen...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nZdanie ...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nZdarzen...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nZda...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nTo ...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\nTekst jest chaotyczny i...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\n**Analiza krok po kroku...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nTo stwi...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nZda...</td>\n",
       "      <td>STATUS_ZDANIA:FAŁSZ</td>\n",
       "      <td>STATUS_ZDANIA:PRAWDA\\n\\nWyjaśnienie:\\n\\nJeśli ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Prompt  \\\n",
       "0  STATUS_ZDANIA:PRAWDA\\n\\n**Dowód:**\\n\\nNiech  $...   \n",
       "1  STATUS_ZDANIA:PRAWDA\\n\\nSkończona addytywność ...   \n",
       "2  STATUS_ZDANIA:PRAWDA\\n\\nTo stwierdzenie jest z...   \n",
       "3  STATUS_ZDANIA:PRAWDA\\n\\nZbiór Vitaliego jest p...   \n",
       "4  STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nZdarzen...   \n",
       "\n",
       "                                     Negative_prompt  \\\n",
       "0  STATUS_ZDANIA:PRAWDA\\n\\nZdanie \"Przecięcie dow...   \n",
       "1  STATUS_ZDANIA:PRAWDA\\n\\nTwoje zdanie jest popr...   \n",
       "2  STATUS_ZDANIA:FAŁSZ\\n\\nZdanie \"Jeśli ciąg zdar...   \n",
       "3  STATUS_ZDANIA:PRAWDA\\n\\nTo zdanie jest prawdzi...   \n",
       "4  STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nZdanie ...   \n",
       "\n",
       "                                     Positive_prompt  \\\n",
       "0  STATUS_ZDANIA:PRAWDA\\n\\nTo zdanie jest poprawn...   \n",
       "1  STATUS_ZDANIA:PRAWDA\\n\\nTwoje zdanie jest popr...   \n",
       "2  STATUS_ZDANIA:FAŁSZ\\n\\nZdanie jest nie do końc...   \n",
       "3  STATUS_ZDANIA:PRAWDA\\n\\nTo zdanie jest poprawn...   \n",
       "4  STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nZdarzen...   \n",
       "\n",
       "                                 Positive_Extra_role  \\\n",
       "0  STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nTo ...   \n",
       "1  STATUS_ZDANIA:FAŁSZ\\n\\nSkończona addytywność p...   \n",
       "2  STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nTo stwi...   \n",
       "3  STATUS_ZDANIA:PRAWDA\\n\\n**Wyjaśnienie:**\\n\\nZb...   \n",
       "4  STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nZda...   \n",
       "\n",
       "                                 Negative_Extra_role  \\\n",
       "0  STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nTo ...   \n",
       "1  STATUS_ZDANIA:PRAWDA\\n\\n**Wyjaśnienie:**\\n\\nTo...   \n",
       "2  STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nTo stwi...   \n",
       "3  STATUS_ZDANIA:PRAWDA\\n\\n**Wyjaśnienie:**\\n\\nZb...   \n",
       "4  STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nTo ...   \n",
       "\n",
       "                                  Uncertainty_prompt  \\\n",
       "0                               STATUS_ZDANIA:PRAWDA   \n",
       "1                               STATUS_ZDANIA:PRAWDA   \n",
       "2  STATUS_ZDANIA:PRAWDA\\n\\n**Wyjaśnienie:**\\n\\nTo...   \n",
       "3                               STATUS_ZDANIA:PRAWDA   \n",
       "4                                STATUS_ZDANIA:FAŁSZ   \n",
       "\n",
       "                                    Scrambled_prompt  \\\n",
       "0                                STATUS_ZDANIA:FAŁSZ   \n",
       "1  STATUS_ZDANIA:FAŁSZ\\n\\nTekst jest kompletnie b...   \n",
       "2                                STATUS_ZDANIA:FAŁSZ   \n",
       "3                                STATUS_ZDANIA:FAŁSZ   \n",
       "4  STATUS_ZDANIA:FAŁSZ\\n\\nTekst jest chaotyczny i...   \n",
       "\n",
       "                                   Chain_of_thoughts  \\\n",
       "0  STATUS_ZDANIA:PRAWDA\\n\\n**Analiza zdania: \"Prz...   \n",
       "1  STATUS_ZDANIA:PRAWDA\\n\\n**Analiza zdania \"Skoń...   \n",
       "2  STATUS_ZDANIA:FAŁSZ\\n\\n**Analiza zdania krok p...   \n",
       "3  STATUS_ZDANIA:PRAWDA\\n\\n**Analiza zdania krok ...   \n",
       "4  STATUS_ZDANIA:FAŁSZ\\n\\n**Analiza krok po kroku...   \n",
       "\n",
       "                                      Sceptical_role  \\\n",
       "0  STATUS_ZDANIA:FAŁSZ\\n\\nZgadzam się z twierdzen...   \n",
       "1  STATUS_ZDANIA:FAŁSZ\\n\\nTo stwierdzenie jest, d...   \n",
       "2  STATUS_ZDANIA:FAŁSZ\\n\\nTo stwierdzenie jest ni...   \n",
       "3  STATUS_ZDANIA:FAŁSZ\\n\\nZbiór Vitaliego, choć f...   \n",
       "4  STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nTo stwi...   \n",
       "\n",
       "                                         High_stakes  \\\n",
       "0  STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nTo ...   \n",
       "1  STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nSkończo...   \n",
       "2  STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nTo ...   \n",
       "3  STATUS_ZDANIA:FAŁSZ\\n\\nZbiór Vitaliego jest pr...   \n",
       "4  STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nZda...   \n",
       "\n",
       "                                             Tipping  \\\n",
       "0                               STATUS_ZDANIA:PRAWDA   \n",
       "1                               STATUS_ZDANIA:PRAWDA   \n",
       "2  STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nZdanie ...   \n",
       "3                               STATUS_ZDANIA:PRAWDA   \n",
       "4                                STATUS_ZDANIA:FAŁSZ   \n",
       "\n",
       "                                      Random_mistake  \n",
       "0  STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nZacznij...  \n",
       "1  STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nSko...  \n",
       "2  STATUS_ZDANIA:PRAWDA\\n\\nWyjaśnienie:\\n\\nTo stw...  \n",
       "3  STATUS_ZDANIA:PRAWDA\\n\\n**Wyjaśnienie:**\\n\\nZb...  \n",
       "4  STATUS_ZDANIA:PRAWDA\\n\\nWyjaśnienie:\\n\\nJeśli ...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f41f9fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczynam parsowanie 12 kolumn...\n",
      "--> Parsowanie kolumny: Prompt\n",
      "--> Parsowanie kolumny: Negative_prompt\n",
      "--> Parsowanie kolumny: Positive_prompt\n",
      "--> Parsowanie kolumny: Positive_Extra_role\n",
      "--> Parsowanie kolumny: Negative_Extra_role\n",
      "--> Parsowanie kolumny: Uncertainty_prompt\n",
      "--> Parsowanie kolumny: Scrambled_prompt\n",
      "--> Parsowanie kolumny: Chain_of_thoughts\n",
      "--> Parsowanie kolumny: Sceptical_role\n",
      "--> Parsowanie kolumny: High_stakes\n",
      "--> Parsowanie kolumny: Tipping\n",
      "--> Parsowanie kolumny: Random_mistake\n",
      "--> Przeniesiono kolumnę 'Flag' do wyników.\n",
      "------------------------------\n",
      "Parsowanie zakończone. Skutecznie przetworzono 720 rekordów.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Negative_prompt</th>\n",
       "      <th>Positive_prompt</th>\n",
       "      <th>Positive_Extra_role</th>\n",
       "      <th>Negative_Extra_role</th>\n",
       "      <th>Uncertainty_prompt</th>\n",
       "      <th>Scrambled_prompt</th>\n",
       "      <th>Chain_of_thoughts</th>\n",
       "      <th>Sceptical_role</th>\n",
       "      <th>High_stakes</th>\n",
       "      <th>Tipping</th>\n",
       "      <th>Random_mistake</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prompt  Negative_prompt  Positive_prompt  Positive_Extra_role  \\\n",
       "0       1                1                1                    0   \n",
       "1       1                1                1                    0   \n",
       "2       1                0                0                    0   \n",
       "3       1                1                1                    1   \n",
       "4       0                0                0                    0   \n",
       "\n",
       "   Negative_Extra_role  Uncertainty_prompt  Scrambled_prompt  \\\n",
       "0                    0                   1                 0   \n",
       "1                    1                   1                 0   \n",
       "2                    0                   1                 0   \n",
       "3                    1                   1                 0   \n",
       "4                    0                   0                 0   \n",
       "\n",
       "   Chain_of_thoughts  Sceptical_role  High_stakes  Tipping  Random_mistake  \\\n",
       "0                  1               0            0        1               0   \n",
       "1                  1               0            0        1               0   \n",
       "2                  0               0            0        0               1   \n",
       "3                  1               0            0        1               1   \n",
       "4                  0               0            0        0               1   \n",
       "\n",
       "   Flag  \n",
       "0     1  \n",
       "1     0  \n",
       "2     1  \n",
       "3     0  \n",
       "4     0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parsed_df = data_model.parsowanie()\n",
    "\n",
    "# Dane są już załadowane z pliku parsed_responses_*.csv\n",
    "parsed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36a84884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Prompt  \\\n",
      "0  STATUS_ZDANIA:PRAWDA\\n\\n**Dowód:**\\n\\nNiech  $...   \n",
      "1  STATUS_ZDANIA:PRAWDA\\n\\nSkończona addytywność ...   \n",
      "2  STATUS_ZDANIA:PRAWDA\\n\\nTo stwierdzenie jest z...   \n",
      "3  STATUS_ZDANIA:PRAWDA\\n\\nZbiór Vitaliego jest p...   \n",
      "4  STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nZdarzen...   \n",
      "\n",
      "                                     Negative_prompt  \\\n",
      "0  STATUS_ZDANIA:PRAWDA\\n\\nZdanie \"Przecięcie dow...   \n",
      "1  STATUS_ZDANIA:PRAWDA\\n\\nTwoje zdanie jest popr...   \n",
      "2  STATUS_ZDANIA:FAŁSZ\\n\\nZdanie \"Jeśli ciąg zdar...   \n",
      "3  STATUS_ZDANIA:PRAWDA\\n\\nTo zdanie jest prawdzi...   \n",
      "4  STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nZdanie ...   \n",
      "\n",
      "                                     Positive_prompt  \\\n",
      "0  STATUS_ZDANIA:PRAWDA\\n\\nTo zdanie jest poprawn...   \n",
      "1  STATUS_ZDANIA:PRAWDA\\n\\nTwoje zdanie jest popr...   \n",
      "2  STATUS_ZDANIA:FAŁSZ\\n\\nZdanie jest nie do końc...   \n",
      "3  STATUS_ZDANIA:PRAWDA\\n\\nTo zdanie jest poprawn...   \n",
      "4  STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nZdarzen...   \n",
      "\n",
      "                                 Positive_Extra_role  \\\n",
      "0  STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nTo ...   \n",
      "1  STATUS_ZDANIA:FAŁSZ\\n\\nSkończona addytywność p...   \n",
      "2  STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nTo stwi...   \n",
      "3  STATUS_ZDANIA:PRAWDA\\n\\n**Wyjaśnienie:**\\n\\nZb...   \n",
      "4  STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nZda...   \n",
      "\n",
      "                                 Negative_Extra_role  \\\n",
      "0  STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nTo ...   \n",
      "1  STATUS_ZDANIA:PRAWDA\\n\\n**Wyjaśnienie:**\\n\\nTo...   \n",
      "2  STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nTo stwi...   \n",
      "3  STATUS_ZDANIA:PRAWDA\\n\\n**Wyjaśnienie:**\\n\\nZb...   \n",
      "4  STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nTo ...   \n",
      "\n",
      "                                  Uncertainty_prompt  \\\n",
      "0                               STATUS_ZDANIA:PRAWDA   \n",
      "1                               STATUS_ZDANIA:PRAWDA   \n",
      "2  STATUS_ZDANIA:PRAWDA\\n\\n**Wyjaśnienie:**\\n\\nTo...   \n",
      "3                               STATUS_ZDANIA:PRAWDA   \n",
      "4                                STATUS_ZDANIA:FAŁSZ   \n",
      "\n",
      "                                    Scrambled_prompt  \\\n",
      "0                                STATUS_ZDANIA:FAŁSZ   \n",
      "1  STATUS_ZDANIA:FAŁSZ\\n\\nTekst jest kompletnie b...   \n",
      "2                                STATUS_ZDANIA:FAŁSZ   \n",
      "3                                STATUS_ZDANIA:FAŁSZ   \n",
      "4  STATUS_ZDANIA:FAŁSZ\\n\\nTekst jest chaotyczny i...   \n",
      "\n",
      "                                   Chain_of_thoughts  \\\n",
      "0  STATUS_ZDANIA:PRAWDA\\n\\n**Analiza zdania: \"Prz...   \n",
      "1  STATUS_ZDANIA:PRAWDA\\n\\n**Analiza zdania \"Skoń...   \n",
      "2  STATUS_ZDANIA:FAŁSZ\\n\\n**Analiza zdania krok p...   \n",
      "3  STATUS_ZDANIA:PRAWDA\\n\\n**Analiza zdania krok ...   \n",
      "4  STATUS_ZDANIA:FAŁSZ\\n\\n**Analiza krok po kroku...   \n",
      "\n",
      "                                      Sceptical_role  \\\n",
      "0  STATUS_ZDANIA:FAŁSZ\\n\\nZgadzam się z twierdzen...   \n",
      "1  STATUS_ZDANIA:FAŁSZ\\n\\nTo stwierdzenie jest, d...   \n",
      "2  STATUS_ZDANIA:FAŁSZ\\n\\nTo stwierdzenie jest ni...   \n",
      "3  STATUS_ZDANIA:FAŁSZ\\n\\nZbiór Vitaliego, choć f...   \n",
      "4  STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nTo stwi...   \n",
      "\n",
      "                                         High_stakes  \\\n",
      "0  STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nTo ...   \n",
      "1  STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nSkończo...   \n",
      "2  STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nTo ...   \n",
      "3  STATUS_ZDANIA:FAŁSZ\\n\\nZbiór Vitaliego jest pr...   \n",
      "4  STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nZda...   \n",
      "\n",
      "                                             Tipping  \\\n",
      "0                               STATUS_ZDANIA:PRAWDA   \n",
      "1                               STATUS_ZDANIA:PRAWDA   \n",
      "2  STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nZdanie ...   \n",
      "3                               STATUS_ZDANIA:PRAWDA   \n",
      "4                                STATUS_ZDANIA:FAŁSZ   \n",
      "\n",
      "                                      Random_mistake  \n",
      "0  STATUS_ZDANIA:FAŁSZ\\n\\nWyjaśnienie:\\n\\nZacznij...  \n",
      "1  STATUS_ZDANIA:FAŁSZ\\n\\n**Wyjaśnienie:**\\n\\nSko...  \n",
      "2  STATUS_ZDANIA:PRAWDA\\n\\nWyjaśnienie:\\n\\nTo stw...  \n",
      "3  STATUS_ZDANIA:PRAWDA\\n\\n**Wyjaśnienie:**\\n\\nZb...  \n",
      "4  STATUS_ZDANIA:PRAWDA\\n\\nWyjaśnienie:\\n\\nJeśli ...  \n"
     ]
    }
   ],
   "source": [
    "print(responses_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4608b253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRZYKŁADOWE ODPOWIEDZI Z MODELU GEMMA\n",
      "\n",
      "================================================================================\n",
      "KOLUMNA: Prompt\n",
      "================================================================================\n",
      "\n",
      "[0] STATUS_ZDANIA:PRAWDA\n",
      "\n",
      "**Dowód:**\n",
      "\n",
      "Niech  $A_1, A_2, A_3, ...$ będzie nieprzeliczalną rodziną σ-ciał w przestrzeni topologicznej $X$.  Chcemy pokazać, że ich przecięcie, $A = \\bigcap_{i=1}^{\\infty} A_i...\n",
      "----------------------------------------\n",
      "\n",
      "[1] STATUS_ZDANIA:PRAWDA\n",
      "\n",
      "Skończona addytywność prawdopodobieństwa jest warunkiem silniejszym niż przeliczalna addytywność. Oznacza to, że jeśli przestrzeń prawdopodobieństwa spełnia warunek skończonej ad...\n",
      "----------------------------------------\n",
      "\n",
      "[2] STATUS_ZDANIA:PRAWDA\n",
      "\n",
      "To stwierdzenie jest zasadniczo prawdziwe w kontekście teorii prawdopodobieństwa.  Jeśli mamy do czynienia z ciągiem zdarzeń, które są *wstępujące* (czyli jedno zdarzenie musi na...\n",
      "----------------------------------------\n",
      "\n",
      "[3] STATUS_ZDANIA:PRAWDA\n",
      "\n",
      "Zbiór Vitaliego jest przykładem zbioru, który jest borelowski, ale nie jest mierzalny w sensie Lebesgue'a. Zbiór Vitaliego jest konstruowany na przestrzeni metrycznej na zbiorze ...\n",
      "----------------------------------------\n",
      "\n",
      "[4] STATUS_ZDANIA:FAŁSZ\n",
      "\n",
      "Wyjaśnienie:\n",
      "\n",
      "Zdarzenia A, B i C są parami niezależne, co oznacza, że A i B są niezależne, B i C są niezależne, oraz A i C są niezależne.  Jednak to nie implikuje, że A, B i C są ...\n",
      "----------------------------------------\n",
      "\n",
      "================================================================================\n",
      "KOLUMNA: Negative_prompt\n",
      "================================================================================\n",
      "\n",
      "[0] STATUS_ZDANIA:PRAWDA\n",
      "\n",
      "Zdanie \"Przecięcie dowolnej, nawet nieprzeliczalnej rodziny sigma-ciał jest zawsze sigma-ciałem\" jest prawdziwe. Jest to fundamentalny wynik teorii miary i analizy.  Dowód tego t...\n",
      "----------------------------------------\n",
      "\n",
      "[1] STATUS_ZDANIA:PRAWDA\n",
      "\n",
      "Twoje zdanie jest poprawne. Skończona addytywność prawdopodobieństwa (finite additivity) jest rzeczywiście silniejszym warunkiem niż przeliczalna addytywność prawdopodobieństwa (...\n",
      "----------------------------------------\n",
      "\n",
      "[2] STATUS_ZDANIA:FAŁSZ\n",
      "\n",
      "Zdanie \"Jeśli ciąg zdarzeń jest wstępujący, to prawdopodobieństwo sumy jest granicą prawdopodobieństw\" zawiera pewien problem i nie jest w pełni poprawne.\n",
      "\n",
      "**Wyjaśnienie:**\n",
      "\n",
      "* **C...\n",
      "----------------------------------------\n",
      "\n",
      "[3] STATUS_ZDANIA:PRAWDA\n",
      "\n",
      "To zdanie jest prawdziwe. Zbiór Vitaliego, który został zdefiniowany przez Sierpińskiego, jest klasycznym przykładem zbioru, który jest zbiorem Borelowskim (czyli zbiorem, który ...\n",
      "----------------------------------------\n",
      "\n",
      "[4] STATUS_ZDANIA:FAŁSZ\n",
      "\n",
      "Wyjaśnienie:\n",
      "\n",
      "Zdanie jest fałszywe. Zdarzenia A, B i C są parami niezależnych, ale nie muszą być wzajemnie niezależne.\n",
      "\n",
      "**Przykład:**\n",
      "\n",
      "Niech:\n",
      "*   A = Deszcz pada\n",
      "*   B = Wiatr wie...\n",
      "----------------------------------------\n",
      "\n",
      "================================================================================\n",
      "KOLUMNA: Positive_prompt\n",
      "================================================================================\n",
      "\n",
      "[0] STATUS_ZDANIA:PRAWDA\n",
      "\n",
      "To zdanie jest poprawne. Jest to fundamentalny wynik teorii miary i analizy. Przecięcie dowolnej rodziny sigma-ciał (nawet nieprzeliczalnej) jest zawsze sigma-ciałem.  Dowód tego...\n",
      "----------------------------------------\n",
      "\n",
      "[1] STATUS_ZDANIA:PRAWDA\n",
      "\n",
      "Twoje zdanie jest poprawne. Skończona addytywność prawdopodobieństwa (finite additivity) jest rzeczywiście silniejszym warunkiem niż przeliczalna addytywność prawdopodobieństwa (...\n",
      "----------------------------------------\n",
      "\n",
      "[2] STATUS_ZDANIA:FAŁSZ\n",
      "\n",
      "Zdanie jest nie do końca poprawne. Chociaż intuicja jest bliska, to wymaga doprecyzowania.\n",
      "\n",
      "Poprawiona wersja zdania brzmiałaby: \"Jeśli ciąg zdarzeń jest *niezależnych* i *wstępuj...\n",
      "----------------------------------------\n",
      "\n",
      "[3] STATUS_ZDANIA:PRAWDA\n",
      "\n",
      "To zdanie jest poprawne. Zbiór Vitaliego (zdefiniowany przez konstrukcję w teorii mierzalności) jest klasycznym przykładem zbioru, który jest borelowski (czyli należy do mocy zbi...\n",
      "----------------------------------------\n",
      "\n",
      "[4] STATUS_ZDANIA:FAŁSZ\n",
      "\n",
      "Wyjaśnienie:\n",
      "\n",
      "Zdarzenia A, B i C są wzajemnie niezależne, jeśli wystąpienie każdego z nich nie wpływa na prawdopodobieństwo wystąpienia pozostałych.  Jeśli A i B są niezależne, a ...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"PRZYKŁADOWE ODPOWIEDZI Z MODELU GEMMA\")\n",
    "\n",
    "for col in responses_df.columns[:3]:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"KOLUMNA: {col}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    for i in range(min(5, len(responses_df))):  # Pierwsze 5 wierszy\n",
    "        print(f\"\\n[{i}] {responses_df[col].iloc[i][:200]}...\")  # Pierwsze 200 znaków\n",
    "        print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6bb4d6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zapisano metryki (bez kolumny Flag): saved_responses\\metrics.csv\n",
      "Zapisano przypadki kontrowersyjne: saved_responses\\controversial.csv\n",
      "\n",
      "[OK] Gotowe!\n",
      "  Metrics saved: metrics.csv\n",
      "  Cases saved:   controversial.csv\n"
     ]
    }
   ],
   "source": [
    "metrics_df, var_df = data_model.compute_accuracy_and_variance()\n",
    "metrics_df.to_csv(f'saved_responses/metrics.csv', index=False, encoding='utf-8-sig')\n",
    "var_df.to_csv(f'saved_responses/controversial.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\n[OK] Gotowe!\")\n",
    "print(f\"  Metrics saved: metrics.csv\")\n",
    "print(f\"  Cases saved:   controversial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7dd8551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Prefix</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strategy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sceptical_role</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>Jesteś sceptykiem, który zawsze podważa prawdz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt</th>\n",
       "      <td>0.600000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chain_of_thoughts</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>Przeanalizuj dokładnie to zdanie krok po kroku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High_stakes</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>Oceń prawdziwość, pamiętając, że od twojej odp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_mistake</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>Oceń prawdziwość:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tipping</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>Dostaniesz duży napiwek jeśli prawidłowo oceni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uncertainty_prompt</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>Oceń prawdziwość tego zdania tylko jeżeli jest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative_Extra_role</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>Jesteś ekspertem w dziedzinie socjologii oraz ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative_prompt</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>Myślę, że to zdanie zawiera problem, czy mam r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive_prompt</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>Myślę, że to zdanie jest poprawne, czy mam rację?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scrambled_prompt</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>Oceń prawdziwość:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive_Extra_role</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>Jesteś ekspertem w dziedzinie rachunku prawdop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  \\\n",
       "Strategy                        \n",
       "Sceptical_role       0.650000   \n",
       "Prompt               0.600000   \n",
       "Chain_of_thoughts    0.600000   \n",
       "High_stakes          0.600000   \n",
       "Random_mistake       0.600000   \n",
       "Tipping              0.600000   \n",
       "Uncertainty_prompt   0.583333   \n",
       "Negative_Extra_role  0.583333   \n",
       "Negative_prompt      0.550000   \n",
       "Positive_prompt      0.550000   \n",
       "Scrambled_prompt     0.533333   \n",
       "Positive_Extra_role  0.500000   \n",
       "\n",
       "                                                                Prefix  \n",
       "Strategy                                                                \n",
       "Sceptical_role       Jesteś sceptykiem, który zawsze podważa prawdz...  \n",
       "Prompt                                                                  \n",
       "Chain_of_thoughts    Przeanalizuj dokładnie to zdanie krok po kroku...  \n",
       "High_stakes          Oceń prawdziwość, pamiętając, że od twojej odp...  \n",
       "Random_mistake                                       Oceń prawdziwość:  \n",
       "Tipping              Dostaniesz duży napiwek jeśli prawidłowo oceni...  \n",
       "Uncertainty_prompt   Oceń prawdziwość tego zdania tylko jeżeli jest...  \n",
       "Negative_Extra_role  Jesteś ekspertem w dziedzinie socjologii oraz ...  \n",
       "Negative_prompt      Myślę, że to zdanie zawiera problem, czy mam r...  \n",
       "Positive_prompt      Myślę, że to zdanie jest poprawne, czy mam rację?  \n",
       "Scrambled_prompt                                     Oceń prawdziwość:  \n",
       "Positive_Extra_role  Jesteś ekspertem w dziedzinie rachunku prawdop...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tworzenie tabeli z wynikami\n",
    "results_table = metrics_df.copy()\n",
    "results_table['Prefix'] = results_table['Strategy'].map(lambda x: data_model.strategies.get(x, ''))\n",
    "results_table = results_table.set_index('Strategy').sort_values('Accuracy', ascending=False)\n",
    "results_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

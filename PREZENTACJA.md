# ğŸ¬ INSTRUKCJA PREZENTACJI - "Lupa na Prompt"

**Jak zaprezentowaÄ‡ projekt w 5-10 minut**

---

## ğŸ¯ Slajd 1: TytuÅ‚ (30 sek)

**"Lupa na Prompt"**  
Analiza wpÅ‚ywu zmian promptu na odpowiedzi LLM Gemma 3.4B

- 60 promptÃ³w matematycznych
- 12 strategii promptowania
- 720 wywoÅ‚aÅ„ API
- Cel: ZidentyfikowaÄ‡ ktÃ³re zmiany pomagajÄ…, a ktÃ³re szkodzÄ…

---

## ğŸ“Š Slajd 2: Metodologia (1 min)

### Dataset:
- **60 zdaÅ„** matematycznych (30 prawdziwych, 30 faÅ‚szywych)
- **Model:** Google Gemma 3.4B przez Gemini API
- **12 strategii modyfikacji:**
  - Framing (Positive/Negative)
  - Role-Playing (Expert/Dummy)
  - Chain-of-Thought
  - Uncertainty, Scepticism
  - Incentives (Tipping, High-stakes)
  - Noise (Scramble, Random mistakes)

### Proces:
1. **ETAP 1:** Zbieranie danych (test.ipynb) - 720 API calls
2. **ETAP 2:** Analiza wzorcÃ³w (analysis_patterns.ipynb) - metryki, halucynacje, risk scoring

---

## ğŸ† Slajd 3: GÅ‚Ã³wne wyniki (2 min)

### Baseline = Najlepszy!
- **Prosty prompt bez modyfikacji:** 65% accuracy
- **Best strategy:** Prompt (baseline) 
- **Worst strategy:** Scrambled_prompt (46.9%)

### TOP 5 Najbardziej szkodliwych zmian:
1. **Scramble/Noise:** -14.0pp (bÅ‚Ä™dy ortograficzne totalna katastrofa)
2. **Expert Role:** -11.7pp (paradoks - role eksperta pogarsza wyniki!)
3. **Incentive:** -9.2pp (nagrody nie motywujÄ… modelu)
4. **Positive Framing:** -8.3pp
5. **Chain-of-Thought:** -7.4pp

### Kluczowe odkrycie: "Less is More"
- **Dla maÅ‚ych modeli (3.4B) zÅ‚oÅ¼one strategie POGARSZAJÄ„ wyniki**
- Dodatkowe instrukcje przeciÄ…Å¼ajÄ… "kognitywnÄ… pojemnoÅ›Ä‡" modelu
- **Wniosek:** Gemma 3.4B dziaÅ‚a najlepiej z prostymi, bezpoÅ›rednimi pytaniami

---

## ğŸš¨ Slajd 4: Halucynacje (2 min)

### NiestabilnoÅ›Ä‡ modelu:
- **75% promptÃ³w** ma konflikty miÄ™dzy strategiami (45/60)
- Ta sama treÅ›Ä‡ â†’ rÃ³Å¼ne odpowiedzi w zaleÅ¼noÅ›ci od strategii
- **Åšrednia zmiennoÅ›Ä‡:** std dev = 0.35

### TOP 3 Najbardziej halucynogenne strategie:
1. **Scrambled_prompt:** zmiennoÅ›Ä‡ 0.71, hallucination risk 89%
2. **Random_mistake:** zmiennoÅ›Ä‡ 0.65, risk 88%
3. **Sceptical_role:** zmiennoÅ›Ä‡ 0.55, risk 85%

### Wykrywanie halucynacji:
- **Threshold:** std dev > 0.5 miÄ™dzy strategiami
- **WskaÅºnik:** JeÅ›li tylko 1-2 strategie zgadzajÄ… siÄ™ z prawdÄ… â†’ HALUCYNACJA

### PrzykÅ‚ad:
*Prompt #0: "PrzeciÄ™cie dowolnej rodziny sigma-ciaÅ‚..."*
- Error rate: 45.5%
- Std: 0.522
- NiektÃ³re strategie: 1, inne: 0, chaos!

---

## ğŸ“ˆ Slajd 5: Wizualizacje (1 min)

**POKAÅ» NA Å»YWO:**
1. OtwÃ³rz `analysis_patterns.ipynb`
2. Scroll do **Cell 8** - interaktywny explorer (ipywidgets slider)
3. PokaÅ¼ jak zmienia siÄ™ odpowiedÅº dla rÃ³Å¼nych strategii
4. Scroll do **Cell 9** - heatmapa poprawnoÅ›ci strategii
5. Scroll do **Cell 12** - wykres impacts kategorii

**Alternatywnie:**
- Uruchom `python quick_summary.py` w terminalu - pokazuje wszystkie wyniki w 1 sekundÄ™

---

## âœ… Slajd 6: Rekomendacje (1 min)

### Dla uÅ¼ytkownikÃ³w Gemmy 3.4B:

**âœ… RÃ“B:**
- UÅ¼ywaj prostych, bezpoÅ›rednich promptÃ³w (baseline)
- Dodaj "Uncertainty" jeÅ›li chcesz wiÄ™cej "nie wiem" (-3.3pp to OK)

**âŒ NIE RÃ“B:**
- Scramble/Noise (bÅ‚Ä™dy ortograficzne) â†’ -14pp
- Expert Role â†’ -11.7pp
- Incentives (tipping, high-stakes) â†’ -9.2pp
- Scepticism â†’ -6.7pp

### Praktyczne zastosowanie:
- **Produkcja:** UÅ¼ywaj ensemble voting (3+ strategie) + confidence scoring
- **QA:** Automatyczna detekcja halucynacji (std dev threshold)
- **Research:** PorÃ³wnaj z wiÄ™kszymi modelami (GPT-4, Claude) - czy "less is more" dalej dziaÅ‚a?

---

## ğŸ“ Slajd 7: Wnioski naukowe (1 min)

### 1. "Less is More" dla maÅ‚ych modeli
- Modele 3-4B majÄ… ograniczonÄ… "kognitywnÄ… pojemnoÅ›Ä‡"
- ZÅ‚oÅ¼one instrukcje (CoT, role) przeciÄ…Å¼ajÄ… kontekst
- Baseline pozwala modelowi dziaÅ‚aÄ‡ intuicyjnie

### 2. Paradoks expertness
- Rola eksperta (-11.7pp) jest GORSZA niÅ¼ brak roli
- Hipoteza: model interpretuje "jesteÅ› ekspertem" jako presjÄ™ â†’ "analysis paralysis"

### 3. Ekstremalna niestabilnoÅ›Ä‡
- 75% konflikty â†’ Gemma 3.4B nie nadaje siÄ™ do produkcji bez weryfikacji
- Potrzeba ensemble lub voting mechanizmÃ³w
- Single-shot predictions = bardzo ryzykowne

### 4. Noise = katastrofa
- Scramble (-14pp) to najwiÄ™kszy zabÃ³jca accuracy
- Model nie radzi sobie z bÅ‚Ä™dami ortograficznymi
- W przeciwieÅ„stwie do ludzi, ktÃ³rzy "autokorekujÄ…"

---

## ğŸ’¡ Slajd 8: Pytania i odpowiedzi

**Spodziewane pytania:**

**Q: Dlaczego Chain-of-Thought pogarsza wyniki?**
A: Dla maÅ‚ych modeli (3.4B) dodatkowe instrukcje przeciÄ…Å¼ajÄ… kontekst. WiÄ™ksze modele (GPT-4) prawdopodobnie skorzystajÄ… z CoT.

**Q: Czy baseline=65% to dobry wynik?**
A: Dla matematyki - Å›rednio. Ale waÅ¼niejsze Å¼e pokazaliÅ›my WZGLÄ˜DNE rÃ³Å¼nice miÄ™dzy strategiami.

**Q: Jak to uÅ¼yÄ‡ w praktyce?**
A: (1) Unikaj Scramble/Expert Role/Incentives dla Gemmy 3.4B, (2) UÅ¼ywaj ensemble voting dla pewnoÅ›ci, (3) Monitor zmiennoÅ›Ä‡ jako wskaÅºnik halucynacji.

**Q: Co dalej?**
A: ETAP 3 (opcjonalne): PorÃ³wnanie z GPT-4/Claude, fine-tuning, production deployment.

---

## ğŸ“ Demo Live (jeÅ›li czas pozwala)

### Opcja A: Jupyter Notebook (2 min)
```bash
# OtwÃ³rz analysis_patterns.ipynb
# Run all cells (jeÅ›li nie executed)
# PokaÅ¼:
# - Cell 8: Interactive explorer
# - Cell 9: Heatmapa + ranking
# - Cell 16: Risk vs Accuracy scatter plot
```

### Opcja B: Quick Summary Script (30 sek)
```bash
python quick_summary.py
# Pokazuje wszystkie kluczowe wyniki w terminalu
```

### Opcja C: Saved Files (1 min)
```bash
cd saved_responses/
# PokaÅ¼ pliki:
# - report_*.json (strukturalny raport)
# - hallucination_cases_*.csv (TOP cases)
# - ranking_strategies_*.csv (best/worst)
```

---

## ğŸ¬ Timeline caÅ‚oÅ›ci (9-10 min)

| Czas | Slajd | TreÅ›Ä‡ |
|------|-------|-------|
| 0:00-0:30 | 1 | TytuÅ‚ + cele |
| 0:30-1:30 | 2 | Metodologia |
| 1:30-3:30 | 3 | GÅ‚Ã³wne wyniki ("Less is More") |
| 3:30-5:30 | 4 | Halucynacje + niestabilnoÅ›Ä‡ |
| 5:30-6:30 | 5 | Demo wizualizacji |
| 6:30-7:30 | 6 | Rekomendacje |
| 7:30-8:30 | 7 | Wnioski naukowe |
| 8:30-10:00 | 8 | Q&A |

---

## âœ… Checklist przed prezentacjÄ…

- [ ] Jupyter notebook `analysis_patterns.ipynb` gotowy (wszystkie cele executed)
- [ ] `quick_summary.py` dziaÅ‚a (test: `python quick_summary.py`)
- [ ] Pliki w `saved_responses/` sÄ… aktualne
- [ ] Przygotowane slajdy (lub markdown prezentacja)
- [ ] Backup: screenshots z notebooka (jeÅ›li live demo siÄ™ nie uda)
- [ ] Znasz 5 TOP wnioskÃ³w na pamiÄ™Ä‡
- [ ] PrzeÄ‡wiczone odpowiedzi na FAQ

---

## ğŸ¯ Kluczowe punkty do zapamiÄ™tania

1. **"Less is More"** - baseline > zÅ‚oÅ¼one strategie dla Gemmy 3.4B
2. **Scramble = -14pp** - najwiÄ™ksza katastrofa
3. **Expert Role = -11.7pp** - paradoks
4. **75% konfliktÃ³w** - model bardzo niestabilny
5. **Hallucination detection** - std dev > 0.5

**Powodzenia!** ğŸš€

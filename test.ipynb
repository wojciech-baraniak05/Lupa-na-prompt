{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1b27be3",
   "metadata": {},
   "source": [
    "# Testy z Gemma 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0478c317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: c:\\Users\\olobr\\Lupa-na-prompt\\.venv\\Scripts\\python.exe\n",
      "Instalujƒô scikit-learn...\n",
      "[ERROR] B≈ÇƒÖd instalacji:\n",
      "ERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\n",
      "\n",
      "\n",
      "[OK] sklearn 1.8.0 dzia≈Ça poprawnie!\n"
     ]
    }
   ],
   "source": [
    "# INSTALACJA sklearn do kernela notebooka\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(\"Instalujƒô scikit-learn...\")\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"--user\", \"scikit-learn\"],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        check=True\n",
    "    )\n",
    "    print(\"[OK] Instalacja zako≈Ñczona!\")\n",
    "    print(result.stdout)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"[ERROR] B≈ÇƒÖd instalacji:\")\n",
    "    print(e.stderr)\n",
    "    \n",
    "# Test importu\n",
    "try:\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import sklearn\n",
    "    print(f\"\\n[OK] sklearn {sklearn.__version__} dzia≈Ça poprawnie!\")\n",
    "except ImportError as e:\n",
    "    print(f\"\\n[ERROR] UWAGA: Zrestartuj kernel (Restart button) i uruchom ponownie!\")\n",
    "    print(f\"B≈ÇƒÖd: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa44c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('prompts2.csv', sep=';')\n",
    "print(df['Prompt'].dtype, df['Flag'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c90523",
   "metadata": {},
   "outputs": [],
   "source": [
    "klucz_gemma = \"AIzaSyC1DYbISscBBaHwOdzm3v1XBf0ZgTk6xrI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f7aeaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "kontekst = \"ROZPOCZƒòCIE WYK≈ÅADU METODY NUMERYCZNE \\n\"\n",
    "kontekst += pathlib.Path('context/MN.md').read_text(encoding='utf-8')\n",
    "kontekst += \"ROZPOCZƒòCIE WYK≈ÅADU RACHUNEK PRAWDOBIE≈ÉSTWA \\n\"\n",
    "kontekst += pathlib.Path('context/prob.md').read_text(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c0e8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Model gemma-3-4b-it dzia≈Ça!\n",
      "Odpowied≈∫: Tak.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "client = genai.Client(api_key=klucz_gemma)\n",
    "\n",
    "# Test po≈ÇƒÖczenia - U≈ªYWAMY TEGO SAMEGO MODELU co w DataModel!\n",
    "testowa_odpowiedz = client.models.generate_content(\n",
    "    model='gemma-3-4b-it',  # ZMIENIONE z gemini-2.0-flash\n",
    "    contents=\"czy dzia≈Çasz? odpowiedz jednym s≈Çowem\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0.5,)\n",
    ")\n",
    "print(f\"[OK] Model gemma-3-4b-it dzia≈Ça!\")\n",
    "print(f\"Odpowied≈∫: {testowa_odpowiedz.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1842eba3",
   "metadata": {},
   "source": [
    "### Model z brakiem ogranicze≈Ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b069778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typ kolumny Prompt: <class 'pandas.core.series.Series'>\n",
      "Wymiary danych: (60, 13)\n",
      "Dostƒôpne kolumny: ['Prompt', 'Flag', 'Negative_prompt', 'Positive_prompt', 'Positive_Extra_role', 'Negative_Extra_role', 'Uncertainty_prompt', 'Scrambled_prompt', 'Chain_of_thoughts', 'Sceptical_role', 'High_stakes', 'Tipping', 'Random_mistake']\n",
      "Kolumny z promptami do przetworzenia: ['Prompt', 'Negative_prompt', 'Positive_prompt', 'Positive_Extra_role', 'Negative_Extra_role', 'Uncertainty_prompt', 'Scrambled_prompt', 'Chain_of_thoughts', 'Sceptical_role', 'High_stakes', 'Tipping', 'Random_mistake']\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample, choice\n",
    "\n",
    "class DataModel:\n",
    "    def __init__(self, df, client):\n",
    "        self.df = df\n",
    "        self.responses = pd.DataFrame(index=df.index)\n",
    "        self.client = client\n",
    "        self.columns_with_prompts = ['Prompt']\n",
    "\n",
    "    def __call__(self):\n",
    "        print(f\"Typ kolumny Prompt: {type(self.df['Prompt'])}\")\n",
    "        print(f\"Wymiary danych: {self.df.shape}\")\n",
    "        print(f\"Dostƒôpne kolumny: {self.df.columns.to_list()}\")\n",
    "        print(f\"Kolumny z promptami do przetworzenia: {self.columns_with_prompts}\")\n",
    "\n",
    "    def make_prompts(self):\n",
    "        self.df[\"Prompt\"] = self.df[\"Prompt\"].apply(lambda x: f\"{x} \\n odpowiedz '1' je≈õli zdanie jest prawdziwe, '0' je≈õli fa≈Çszywe.\")\n",
    "        \n",
    "        def inject_noise(text, rate=0.1):\n",
    "            if not isinstance(text, str): return str(text)\n",
    "            indices = [i for i, c in enumerate(text) if c.isalpha()]\n",
    "            if not indices: return text\n",
    "            \n",
    "            k = int(len(indices) * rate)\n",
    "            text_list = list(text)\n",
    "            for i in sample(indices, k):\n",
    "                text_list[i] = choice(string.ascii_letters)\n",
    "            return \"\".join(text_list)\n",
    "\n",
    "        strategies = {\n",
    "            'Negative_prompt': lambda x: f\"My≈õlƒô, ≈ºe to zdanie zawiera problem, czy mam racjƒô?: {x}\",\n",
    "            'Positive_prompt': lambda x: f\"My≈õlƒô, ≈ºe to zdanie jest poprawne, czy mam racjƒô?: {x}\",\n",
    "            'Positive_Extra_role': lambda x: f\"Jeste≈õ ekspertem w dziedzinie rachunku prawdopodobie≈Ñstwa oraz metod numerycznych, sprawd≈∫ prawdziwo≈õƒá: {x}\",\n",
    "            'Negative_Extra_role': lambda x: f\"Jeste≈õ ekspertem w dziedzinie socjologii oraz obcych form ≈ºycia, sprawd≈∫ prawdziwo≈õƒá: {x}\",\n",
    "            'Uncertainty_prompt': lambda x: f\"Oce≈Ñ prawdziwo≈õƒá tego zdania tylko je≈ºeli jeste≈õ pewny odpowiedzi: {x}\",\n",
    "            'Scrambled_prompt': lambda x: f\"Oce≈Ñ prawdziwo≈õƒá (tekst pomieszany): {''.join(np.random.permutation(list(x)))}\",\n",
    "            'Chain_of_thoughts': lambda x: f\"Przeanalizuj dok≈Çadnie to zdanie krok po kroku i oce≈Ñ jego prawdziwo≈õƒá: {x}\",\n",
    "            'Sceptical_role': lambda x: f\"Jeste≈õ sceptykiem, kt√≥ry zawsze podwa≈ºa prawdziwo≈õƒá informacji. Oce≈Ñ: {x}\",\n",
    "            'High_stakes': lambda x: f\"Oce≈Ñ prawdziwo≈õƒá, pamiƒôtajƒÖc, ≈ºe od twojej odpowiedzi zale≈ºy ≈ºycie wielu os√≥b: {x}\",\n",
    "            'Tipping': lambda x: f\"Dostaniesz du≈ºy napiwek je≈õli prawid≈Çowo ocenisz to zdanie: {x}\",\n",
    "            'Random_mistake': lambda x: f\"Oce≈Ñ prawdziwo≈õƒá: {inject_noise(x)}\"\n",
    "        }\n",
    "\n",
    "        for col_name, func in strategies.items():\n",
    "            self.df[col_name] = self.df[\"Prompt\"].apply(func)\n",
    "            self.columns_with_prompts.append(col_name)\n",
    "\n",
    "    async def prompts(self):\n",
    "        print(f\"Rozpoczynam generowanie dla {len(self.columns_with_prompts)} kolumn...\")\n",
    "        \n",
    "        for col_name in self.columns_with_prompts:\n",
    "            print(f\"--> Przetwarzanie kolumny: {col_name}\")\n",
    "            prompts_list = self.df[col_name].tolist()\n",
    "            \n",
    "            tasks = []\n",
    "            for prompt in prompts_list:\n",
    "                tasks.append(\n",
    "                    self.client.aio.models.generate_content(\n",
    "                        model='gemma-3-4b-it',\n",
    "                        contents=prompt,\n",
    "                        config=types.GenerateContentConfig(temperature=0.5)\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "\n",
    "            results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "            \n",
    "            cleaned_results = []\n",
    "            for res in results:\n",
    "                if isinstance(res, Exception):\n",
    "                    cleaned_results.append(f\"Error: {str(res)}\")\n",
    "                else:\n",
    "                    cleaned_results.append(res.text.strip())\n",
    "            \n",
    "            self.responses[col_name] = cleaned_results\n",
    "            \n",
    "        print(\"Zako≈Ñczono generowanie wszystkich odpowiedzi.\")\n",
    "        return self.responses\n",
    "\n",
    "data_model = DataModel(df, client)\n",
    "data_model.make_prompts()\n",
    "data_model() # Wy≈õwietli info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de0acb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczynam generowanie dla 12 kolumn...\n",
      "--> Przetwarzanie kolumny: Prompt\n",
      "--> Przetwarzanie kolumny: Negative_prompt\n",
      "--> Przetwarzanie kolumny: Positive_prompt\n",
      "--> Przetwarzanie kolumny: Positive_Extra_role\n",
      "--> Przetwarzanie kolumny: Negative_Extra_role\n",
      "--> Przetwarzanie kolumny: Uncertainty_prompt\n",
      "--> Przetwarzanie kolumny: Scrambled_prompt\n",
      "--> Przetwarzanie kolumny: Chain_of_thoughts\n",
      "--> Przetwarzanie kolumny: Sceptical_role\n",
      "--> Przetwarzanie kolumny: High_stakes\n",
      "--> Przetwarzanie kolumny: Tipping\n",
      "--> Przetwarzanie kolumny: Random_mistake\n",
      "Zako≈Ñczono generowanie wszystkich odpowiedzi.\n",
      "                                              Prompt  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1                                                  1   \n",
      "2                                                  1   \n",
      "3                                                  1   \n",
      "4  0\\n\\n**Wyja≈õnienie:**\\n\\nWzajemna niezale≈ºno≈õƒá...   \n",
      "\n",
      "                                     Negative_prompt  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                     Positive_prompt  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                 Positive_Extra_role  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                 Negative_Extra_role  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                  Uncertainty_prompt  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                    Scrambled_prompt  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                   Chain_of_thoughts  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                      Sceptical_role  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                         High_stakes  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                             Tipping  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                      Random_mistake  \n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...  \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...  \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...  \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...  \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...  \n"
     ]
    }
   ],
   "source": [
    "responses_df = await data_model.prompts()\n",
    "print(responses_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7c86aa",
   "metadata": {},
   "source": [
    "## Model z ograniczeniem promt√≥w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "902d8018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import string\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample, choice\n",
    "from tqdm.asyncio import tqdm\n",
    "\n",
    "\n",
    "class DataModel:\n",
    "    def __init__(self, df, client, rate_limit=10, positive_response=\"'STATUS_ZDANIA:PRAWDA'\", negative_response=\"'STATUS_ZDANIA:FA≈ÅSZ'\"):\n",
    "        self.df = df\n",
    "        self.responses = pd.DataFrame(index=df.index)\n",
    "        self.responses_parsed = pd.DataFrame(index=df.index)\n",
    "        self.client = client\n",
    "        self.columns_with_prompts = ['Prompt']\n",
    "        self.rate_limit = rate_limit  # Zmniejszono z 20 do 10\n",
    "        self.positive_response = positive_response\n",
    "        self.negative_response = negative_response\n",
    "\n",
    "    def __call__(self):\n",
    "        print(f\"Typ kolumny Prompt: {type(self.df['Prompt'])}\")\n",
    "        print(f\"Wymiary danych: {self.df.shape}\")\n",
    "        print(f\"Dostƒôpne kolumny: {self.df.columns.to_list()}\")\n",
    "        print(f\"Kolumny z promptami do przetworzenia: {self.columns_with_prompts}\")\n",
    "        print(f\"Koluny z odpowiedziami\")\n",
    "\n",
    "    def make_prompts(self):\n",
    "        self.df[\"Prompt\"] = self.df[\"Prompt\"].apply(lambda x: f\"{x} \\n W odpowiedzi zawrzyj dok≈Çadnie {self.positive_response} albo {self.negative_response}, w zale≈ºno≈õci od prawdziwo≈õci zdania.\")\n",
    "        \n",
    "        def inject_noise(text, rate=0.1):\n",
    "            if not isinstance(text, str): return str(text)\n",
    "            indices = [i for i, c in enumerate(text) if c.isalpha()]\n",
    "            if not indices: return text\n",
    "            \n",
    "            k = int(len(indices) * rate)\n",
    "            text_list = list(text)\n",
    "            for i in sample(indices, k):\n",
    "                text_list[i] = choice(string.ascii_letters)\n",
    "            return \"\".join(text_list)\n",
    "\n",
    "        strategies = {\n",
    "            'Negative_prompt': lambda x: f\"My≈õlƒô, ≈ºe to zdanie zawiera problem, czy mam racjƒô?: {x}\",\n",
    "            'Positive_prompt': lambda x: f\"My≈õlƒô, ≈ºe to zdanie jest poprawne, czy mam racjƒô?: {x}\",\n",
    "            'Positive_Extra_role': lambda x: f\"Jeste≈õ ekspertem w dziedzinie rachunku prawdopodobie≈Ñstwa oraz metod numerycznych, sprawd≈∫ prawdziwo≈õƒá: {x}\",\n",
    "            'Negative_Extra_role': lambda x: f\"Jeste≈õ ekspertem w dziedzinie socjologii oraz obcych form ≈ºycia, sprawd≈∫ prawdziwo≈õƒá: {x}\",\n",
    "            'Uncertainty_prompt': lambda x: f\"Oce≈Ñ prawdziwo≈õƒá tego zdania tylko je≈ºeli jeste≈õ pewny odpowiedzi: {x}\",\n",
    "            'Scrambled_prompt': lambda x: f\"Oce≈Ñ prawdziwo≈õƒá (tekst pomieszany): {''.join(np.random.permutation(list(x)))}\",\n",
    "            'Chain_of_thoughts': lambda x: f\"Przeanalizuj dok≈Çadnie to zdanie krok po kroku i oce≈Ñ jego prawdziwo≈õƒá: {x}\",\n",
    "            'Sceptical_role': lambda x: f\"Jeste≈õ sceptykiem, kt√≥ry zawsze podwa≈ºa prawdziwo≈õƒá informacji. Oce≈Ñ: {x}\",\n",
    "            'High_stakes': lambda x: f\"Oce≈Ñ prawdziwo≈õƒá, pamiƒôtajƒÖc, ≈ºe od twojej odpowiedzi zale≈ºy ≈ºycie wielu os√≥b: {x}\",\n",
    "            'Tipping': lambda x: f\"Dostaniesz du≈ºy napiwek je≈õli prawid≈Çowo ocenisz to zdanie: {x}\",\n",
    "            'Random_mistake': lambda x: f\"Oce≈Ñ prawdziwo≈õƒá: {inject_noise(x)}\"\n",
    "        }\n",
    "\n",
    "        for col_name, func in strategies.items():\n",
    "            self.df[col_name] = self.df[\"Prompt\"].apply(func)\n",
    "            self.columns_with_prompts.append(col_name)\n",
    "\n",
    "    async def _call_api_with_retry(self, prompt, max_retries=3, base_delay=5):\n",
    "        \"\"\"Wywo≈Çanie API z retry i exponential backoff\"\"\"\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = await self.client.aio.models.generate_content(\n",
    "                    model='gemma-3-4b-it',\n",
    "                    contents=prompt,\n",
    "                    config=types.GenerateContentConfig(temperature=0.5)\n",
    "                )\n",
    "                return response.text.strip()\n",
    "            except Exception as e:\n",
    "                error_str = str(e).lower()\n",
    "                # Sprawd≈∫ czy to b≈ÇƒÖd rate limit (429) lub quota\n",
    "                if \"429\" in error_str or \"quota\" in error_str or \"rate\" in error_str or \"resource\" in error_str:\n",
    "                    wait_time = base_delay * (2 ** attempt)  # Exponential backoff\n",
    "                    print(f\"\\n[WARNING] Rate limit - czekam {wait_time}s przed ponownƒÖ pr√≥bƒÖ ({attempt+1}/{max_retries})...\")\n",
    "                    await asyncio.sleep(wait_time)\n",
    "                else:\n",
    "                    # Inny b≈ÇƒÖd - zwr√≥ƒá od razu\n",
    "                    return f\"Error: {str(e)}\"\n",
    "        return f\"Error: Max retries exceeded\"\n",
    "\n",
    "    async def prompts(self):\n",
    "        total_columns = len(self.columns_with_prompts)\n",
    "        print(f\"Rozpoczynam generowanie dla {total_columns} kolumn...\")\n",
    "        print(f\"Rate limit: {self.rate_limit} zapyta≈Ñ/min (delay: {60.0/self.rate_limit:.1f}s)\")\n",
    "        \n",
    "        requests_per_minute = self.rate_limit\n",
    "        delay_seconds = 60.0 / requests_per_minute \n",
    "\n",
    "        total_ok = 0\n",
    "        total_err = 0\n",
    "        \n",
    "        for col_index, col_name in enumerate(self.columns_with_prompts):\n",
    "            print(f\"\\n--> [{col_index+1}/{total_columns}] Przetwarzanie kolumny: {col_name}\")\n",
    "            prompts_list = self.df[col_name].tolist()\n",
    "            column_results = []\n",
    "            \n",
    "            pbar = tqdm(prompts_list, desc=f\"Generowanie '{col_name}'\", unit=\"prompt\")\n",
    "            \n",
    "            for prompt in pbar:\n",
    "                loop_start_time = time.time() \n",
    "                \n",
    "                result = await self._call_api_with_retry(prompt)\n",
    "                \n",
    "                if result.startswith(\"Error:\"):\n",
    "                    total_err += 1\n",
    "                else:\n",
    "                    total_ok += 1\n",
    "                    \n",
    "                column_results.append(result)\n",
    "                pbar.set_postfix({'OK': total_ok, 'ERR': total_err})\n",
    "\n",
    "                elapsed = time.time() - loop_start_time\n",
    "                wait_time = max(0, delay_seconds - elapsed)\n",
    "                \n",
    "                if wait_time > 0:\n",
    "                    await asyncio.sleep(wait_time)\n",
    "            \n",
    "            self.responses[col_name] = column_results\n",
    "            \n",
    "        print(\"\\nZako≈Ñczono generowanie wszystkich odpowiedzi.\")\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"Sukcesy: {total_ok}\")\n",
    "        print(f\"B≈Çƒôdy:   {total_err}\")\n",
    "        print(\"-\" * 30)\n",
    "        return self.responses\n",
    "\n",
    "    def parsowanie(self):\n",
    "        \"\"\"Parsowanie zgodne z testWojtka.ipynb - prosta logika\"\"\"\n",
    "        if self.responses.empty:\n",
    "            print(\"Brak odpowiedzi do sparsowania.\")\n",
    "            return self.responses_parsed\n",
    "\n",
    "        print(f\"Rozpoczynam parsowanie {len(self.responses.columns)} kolumn...\")\n",
    "\n",
    "        # Przygotuj wersje bez cudzys≈Çow√≥w\n",
    "        pos_clean = self.positive_response.replace(\"'\", \"\").replace('\"', \"\")\n",
    "        neg_clean = self.negative_response.replace(\"'\", \"\").replace('\"', \"\")\n",
    "\n",
    "        def parse_single_response(text):\n",
    "            if not isinstance(text, str):\n",
    "                return None\n",
    "            # Je≈õli zawiera marker pozytywny -> 1, w przeciwnym razie -> 0\n",
    "            if (self.positive_response in text) or (pos_clean in text):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        for col_name in self.responses.columns:\n",
    "            self.responses_parsed[col_name] = self.responses[col_name].apply(parse_single_response)\n",
    "            valid_count = self.responses_parsed[col_name].notna().sum()\n",
    "            print(f\"--> Kolumna '{col_name}': {valid_count}/{len(self.responses_parsed)}\")\n",
    "\n",
    "        print(\"Parsowanie zako≈Ñczone.\")\n",
    "        return self.responses_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55809acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typ kolumny Prompt: <class 'pandas.core.series.Series'>\n",
      "Wymiary danych: (60, 13)\n",
      "Dostƒôpne kolumny: ['Prompt', 'Flag', 'Negative_prompt', 'Positive_prompt', 'Positive_Extra_role', 'Negative_Extra_role', 'Uncertainty_prompt', 'Scrambled_prompt', 'Chain_of_thoughts', 'Sceptical_role', 'High_stakes', 'Tipping', 'Random_mistake']\n",
      "Kolumny z promptami do przetworzenia: ['Prompt', 'Negative_prompt', 'Positive_prompt', 'Positive_Extra_role', 'Negative_Extra_role', 'Uncertainty_prompt', 'Scrambled_prompt', 'Chain_of_thoughts', 'Sceptical_role', 'High_stakes', 'Tipping', 'Random_mistake']\n",
      "Koluny z odpowiedziami\n"
     ]
    }
   ],
   "source": [
    "# --- Wywo≈Çanie (jak w testV2) ---\n",
    "data_model = DataModel(df, client)\n",
    "data_model.make_prompts()\n",
    "data_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad8de258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "def save_results(model_instance, folder_name=\"saved_responses\"):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    \n",
    "    raw_path = os.path.join(folder_name, f\"raw_responses_{timestamp}.csv\")\n",
    "    parsed_path = os.path.join(folder_name, f\"parsed_responses_{timestamp}.csv\")\n",
    "    \n",
    "    model_instance.responses.to_csv(raw_path, index=True, encoding='utf-8-sig')\n",
    "    model_instance.responses_parsed.to_csv(parsed_path, index=True, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"Raw saved:    {raw_path}\")\n",
    "    print(f\"Parsed saved: {parsed_path}\")\n",
    "\n",
    "def load_last_results():\n",
    "    \"\"\"Za≈Çaduj ostatnio zapisane wyniki - ≈Çaduje konkretnƒÖ parƒô plik√≥w z 20-51-50\"\"\"\n",
    "    folder = \"saved_responses\"\n",
    "    \n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"[ERROR] Folder '{folder}' nie istnieje!\")\n",
    "        return None, None\n",
    "    \n",
    "    # Konkretne pliki kt√≥re zawierajƒÖ w≈Ça≈õciwe dane\n",
    "    target_parsed = os.path.join(folder, \"parsed_responses_2025-12-30_20-51-50.csv\")\n",
    "    target_raw = os.path.join(folder, \"raw_responses_2025-12-30_20-51-50.csv\")\n",
    "    \n",
    "    # Sprawd≈∫ czy pliki istniejƒÖ\n",
    "    if not os.path.exists(target_parsed):\n",
    "        print(f\"[ERROR] Brak pliku: {os.path.basename(target_parsed)}\")\n",
    "        return None, None\n",
    "    \n",
    "    if not os.path.exists(target_raw):\n",
    "        print(f\"[ERROR] Brak pliku: {os.path.basename(target_raw)}\")\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        parsed_data = pd.read_csv(target_parsed, index_col=0)\n",
    "        raw_data = pd.read_csv(target_raw, index_col=0)\n",
    "        \n",
    "        raw_size = os.path.getsize(target_raw)\n",
    "        \n",
    "        print(\"[OK] ZA≈ÅADOWANE DANE Z DYSKU\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Parsed: {os.path.basename(target_parsed)}\")\n",
    "        print(f\"        {parsed_data.shape[0]} wierszy √ó {parsed_data.shape[1]} kolumn\")\n",
    "        print(f\"\\nRaw:    {os.path.basename(target_raw)} ({raw_size} bajt√≥w)\")\n",
    "        print(f\"        {raw_data.shape[0]} wierszy √ó {raw_data.shape[1]} kolumn\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return parsed_data, raw_data\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] B≈ÇƒÖd ≈Çadowania: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b710613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ ≈Åadujƒô dane z dysku zamiast wywo≈Çywaƒá API...\n",
      "[OK] ZA≈ÅADOWANE DANE Z DYSKU\n",
      "================================================================================\n",
      "Parsed: parsed_responses_2025-12-30_20-51-50.csv\n",
      "        60 wierszy √ó 12 kolumn\n",
      "\n",
      "Raw:    raw_responses_2025-12-30_20-51-50.csv (84225 bajt√≥w)\n",
      "        60 wierszy √ó 12 kolumn\n",
      "================================================================================\n",
      "‚úì Dane za≈Çadowane - mo≈ºna kontynuowaƒá analizƒô!\n"
     ]
    }
   ],
   "source": [
    "# ‚ö†Ô∏è ZAKOMENTOWANE - aby nie traciƒá czasu i pieniƒôdzy na API\n",
    "# Odkomentuj tylko gdy chcesz wygenerowaƒá NOWE odpowiedzi\n",
    "# responses_df = await data_model.prompts()\n",
    "\n",
    "# ZAMIAST TEGO: Za≈Çaduj zapisane dane z dysku\n",
    "print(\"üìÇ ≈Åadujƒô dane z dysku zamiast wywo≈Çywaƒá API...\")\n",
    "loaded_parsed, loaded_raw = load_last_results()\n",
    "\n",
    "if loaded_parsed is not None:\n",
    "    # Ustaw zmienne tak jakby by≈Çy z API\n",
    "    responses_df = loaded_raw\n",
    "    parsed_df = loaded_parsed\n",
    "    print(\"‚úì Dane za≈Çadowane - mo≈ºna kontynuowaƒá analizƒô!\")\n",
    "else:\n",
    "    print(\"‚ùå Brak danych - odkomentuj wywo≈Çanie API powy≈ºej\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f41f9fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì U≈ºywam loaded_parsed (ju≈º sparsowane dane z dysku)\n",
      "   Prompt  Negative_prompt  Positive_prompt  Positive_Extra_role  \\\n",
      "0       1                1                1                    0   \n",
      "1       1                1                1                    1   \n",
      "2       1                0                0                    0   \n",
      "3       1                1                1                    1   \n",
      "4       0                0                0                    0   \n",
      "\n",
      "   Negative_Extra_role  Uncertainty_prompt  Scrambled_prompt  \\\n",
      "0                    0                   1               NaN   \n",
      "1                    0                   1               NaN   \n",
      "2                    0                   1               1.0   \n",
      "3                    1                   1               1.0   \n",
      "4                    0                   0               NaN   \n",
      "\n",
      "   Chain_of_thoughts  Sceptical_role  High_stakes  Tipping  Random_mistake  \n",
      "0                1.0               0            0        1             0.0  \n",
      "1                1.0               0            0        1             0.0  \n",
      "2                0.0               0            0        1             NaN  \n",
      "3                1.0               1            0        1             1.0  \n",
      "4                0.0               0            0        1             0.0  \n"
     ]
    }
   ],
   "source": [
    "# ‚ö†Ô∏è ZAKOMENTOWANE - parsowanie ju≈º jest w loaded_parsed\n",
    "# Odkomentuj tylko je≈õli generujesz NOWE dane z API\n",
    "# parsed_df = data_model.parsowanie()\n",
    "\n",
    "# Dane sƒÖ ju≈º za≈Çadowane z pliku parsed_responses_*.csv\n",
    "print(\"‚úì U≈ºywam loaded_parsed (ju≈º sparsowane dane z dysku)\")\n",
    "print(parsed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83ae8342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è ZAKOMENTOWANE - nie zapisuj pustych plik√≥w!\n",
    "\n",
    "# save_results(data_model) zapisa≈Çby puste DataFrame bo nie uruchamiali≈õmy API# save_results(data_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36a84884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Prompt       Negative_prompt       Positive_prompt  \\\n",
      "0  STATUS_ZDANIA:PRAWDA  STATUS_ZDANIA:PRAWDA  STATUS_ZDANIA:PRAWDA   \n",
      "1  STATUS_ZDANIA:PRAWDA  STATUS_ZDANIA:PRAWDA  STATUS_ZDANIA:PRAWDA   \n",
      "2  STATUS_ZDANIA:PRAWDA   STATUS_ZDANIA:FA≈ÅSZ   STATUS_ZDANIA:FA≈ÅSZ   \n",
      "3  STATUS_ZDANIA:PRAWDA  STATUS_ZDANIA:PRAWDA  STATUS_ZDANIA:PRAWDA   \n",
      "4   STATUS_ZDANIA:FA≈ÅSZ   STATUS_ZDANIA:FA≈ÅSZ   STATUS_ZDANIA:FA≈ÅSZ   \n",
      "\n",
      "    Positive_Extra_role   Negative_Extra_role    Uncertainty_prompt  \\\n",
      "0   STATUS_ZDANIA:FA≈ÅSZ   STATUS_ZDANIA:FA≈ÅSZ  STATUS_ZDANIA:PRAWDA   \n",
      "1  STATUS_ZDANIA:PRAWDA   STATUS_ZDANIA:FA≈ÅSZ  STATUS_ZDANIA:PRAWDA   \n",
      "2   STATUS_ZDANIA:FA≈ÅSZ   STATUS_ZDANIA:FA≈ÅSZ  STATUS_ZDANIA:PRAWDA   \n",
      "3  STATUS_ZDANIA:PRAWDA  STATUS_ZDANIA:PRAWDA  STATUS_ZDANIA:PRAWDA   \n",
      "4   STATUS_ZDANIA:FA≈ÅSZ   STATUS_ZDANIA:FA≈ÅSZ   STATUS_ZDANIA:FA≈ÅSZ   \n",
      "\n",
      "                                    Scrambled_prompt  \\\n",
      "0  Ten tekst wyglƒÖda jak wynik szyfrowania lub za...   \n",
      "1  Ten tekst jest ca≈Çkowicie losowy i nie ma ≈ºadn...   \n",
      "2  Ten tekst jest ca≈Çkowicie losowy i nie ma ≈ºadn...   \n",
      "3  Ten tekst jest ca≈Çkowicie losowy i nie ma ≈ºadn...   \n",
      "4  Ten tekst jest ca≈Çkowicie losowy i nie ma ≈ºadn...   \n",
      "\n",
      "                                   Chain_of_thoughts        Sceptical_role  \\\n",
      "0                               STATUS_ZDANIA:PRAWDA   STATUS_ZDANIA:FA≈ÅSZ   \n",
      "1                               STATUS_ZDANIA:PRAWDA   STATUS_ZDANIA:FA≈ÅSZ   \n",
      "2  STATUS_ZDANIA:FA≈ÅSZ\\n\\n**Analiza krok po kroku...   STATUS_ZDANIA:FA≈ÅSZ   \n",
      "3                               STATUS_ZDANIA:PRAWDA  STATUS_ZDANIA:PRAWDA   \n",
      "4                                STATUS_ZDANIA:FA≈ÅSZ   STATUS_ZDANIA:FA≈ÅSZ   \n",
      "\n",
      "           High_stakes               Tipping        Random_mistake  \n",
      "0  STATUS_ZDANIA:FA≈ÅSZ  STATUS_ZDANIA:PRAWDA   STATUS_ZDANIA:FA≈ÅSZ  \n",
      "1  STATUS_ZDANIA:FA≈ÅSZ  STATUS_ZDANIA:PRAWDA   STATUS_ZDANIA:FA≈ÅSZ  \n",
      "2  STATUS_ZDANIA:FA≈ÅSZ  STATUS_ZDANIA:PRAWDA   SSzTUS_ZDANIA:SA≈ÅSZ  \n",
      "3  STATUS_ZDANIA:FA≈ÅSZ  STATUS_ZDANIA:PRAWDA  STATUS_ZDANIA:PRAWDA  \n",
      "4  STATUS_ZDANIA:FA≈ÅSZ  STATUS_ZDANIA:PRAWDA   STRTUS_ZDANIA:FA≈ÅSZ  \n"
     ]
    }
   ],
   "source": [
    "print(responses_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4608b253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PRZYK≈ÅADOWE ODPOWIEDZI Z MODELU GEMMA\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "KOLUMNA: Prompt\n",
      "================================================================================\n",
      "\n",
      "[0] STATUS_ZDANIA:PRAWDA...\n",
      "----------------------------------------\n",
      "\n",
      "[1] STATUS_ZDANIA:PRAWDA...\n",
      "----------------------------------------\n",
      "\n",
      "[2] STATUS_ZDANIA:PRAWDA...\n",
      "----------------------------------------\n",
      "\n",
      "[3] STATUS_ZDANIA:PRAWDA...\n",
      "----------------------------------------\n",
      "\n",
      "[4] STATUS_ZDANIA:FA≈ÅSZ...\n",
      "----------------------------------------\n",
      "\n",
      "================================================================================\n",
      "KOLUMNA: Negative_prompt\n",
      "================================================================================\n",
      "\n",
      "[0] STATUS_ZDANIA:PRAWDA...\n",
      "----------------------------------------\n",
      "\n",
      "[1] STATUS_ZDANIA:PRAWDA...\n",
      "----------------------------------------\n",
      "\n",
      "[2] STATUS_ZDANIA:FA≈ÅSZ...\n",
      "----------------------------------------\n",
      "\n",
      "[3] STATUS_ZDANIA:PRAWDA...\n",
      "----------------------------------------\n",
      "\n",
      "[4] STATUS_ZDANIA:FA≈ÅSZ...\n",
      "----------------------------------------\n",
      "\n",
      "================================================================================\n",
      "KOLUMNA: Positive_prompt\n",
      "================================================================================\n",
      "\n",
      "[0] STATUS_ZDANIA:PRAWDA...\n",
      "----------------------------------------\n",
      "\n",
      "[1] STATUS_ZDANIA:PRAWDA...\n",
      "----------------------------------------\n",
      "\n",
      "[2] STATUS_ZDANIA:FA≈ÅSZ...\n",
      "----------------------------------------\n",
      "\n",
      "[3] STATUS_ZDANIA:PRAWDA...\n",
      "----------------------------------------\n",
      "\n",
      "[4] STATUS_ZDANIA:FA≈ÅSZ...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# DIAGNOSTYKA - Zobacz przyk≈Çadowe odpowiedzi z modelu\n",
    "print(\"=\"*80)\n",
    "print(\"PRZYK≈ÅADOWE ODPOWIEDZI Z MODELU GEMMA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for col in responses_df.columns[:3]:  # Pierwsze 3 kolumny\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"KOLUMNA: {col}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    for i in range(min(5, len(responses_df))):  # Pierwsze 5 wierszy\n",
    "        print(f\"\\n[{i}] {responses_df[col].iloc[i][:200]}...\")  # Pierwsze 200 znak√≥w\n",
    "        print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bb4d6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczynam obliczanie metryk...\n",
      "\n",
      "[OK] Gotowe!\n",
      "  Metrics saved: metrics_2025-12-31_00-46-55.csv\n",
      "  Cases saved:   controversial_2025-12-31_00-46-55.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Sprawd≈∫ czy obliczenia ju≈º zosta≈Çy wykonane\n",
    "if 'metrics_df' in globals() and 'var_df' in globals():\n",
    "    print(\"[OK] Metryki i analiza ju≈º istniejƒÖ w pamiƒôci.\")\n",
    "    print(f\"  - metrics_df: {len(metrics_df)} strategii\")\n",
    "    print(f\"  - var_df: {len(var_df)} kontrowersyjnych przypadk√≥w\")\n",
    "    print(\"\\nJe≈õli chcesz przeliczyƒá od nowa, u≈ºyj: del metrics_df, var_df\")\n",
    "else:\n",
    "    print(\"Rozpoczynam obliczanie metryk...\")\n",
    "    \n",
    "    # Oblicz metryki\n",
    "    y_true = df['Flag'].values\n",
    "    metrics_results = { 'Strategy': [], 'Accuracy': [] }\n",
    "    for col in parsed_df.columns:\n",
    "        y_pred = parsed_df[col].values\n",
    "        mask = ~np.isnan(y_pred)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        acc = accuracy_score(y_true[mask], y_pred[mask])\n",
    "        metrics_results['Strategy'].append(col)\n",
    "        metrics_results['Accuracy'].append(acc)\n",
    "    metrics_df = pd.DataFrame(metrics_results).sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Oblicz zmienno≈õƒá\n",
    "    variability = []\n",
    "    for idx in range(len(parsed_df)):\n",
    "        row = parsed_df.iloc[idx].dropna()\n",
    "        if len(row) > 1:\n",
    "            variability.append({\n",
    "                'Idx': idx,\n",
    "                'Prompt': df.iloc[idx]['Prompt'][:80] + '...',\n",
    "                'True': df.iloc[idx]['Flag'],\n",
    "                'Std': row.std()\n",
    "            })\n",
    "    var_df = pd.DataFrame(variability).sort_values('Std', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Zapis\n",
    "    ts = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    metrics_df.to_csv(f'saved_responses/metrics_{ts}.csv', index=False, encoding='utf-8-sig')\n",
    "    var_df.to_csv(f'saved_responses/controversial_{ts}.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"\\n[OK] Gotowe!\")\n",
    "    print(f\"  Metrics saved: metrics_{ts}.csv\")\n",
    "    print(f\"  Cases saved:   controversial_{ts}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7dd8551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ANALIZA WZORC√ìW\n",
      "================================================================================\n",
      "\n",
      "Baseline (Prompt):        65.0%\n",
      "Najlepsza (Prompt              ): 65.0%  (+0.0 pp)\n",
      "Najs≈Çabsza (Scrambled_prompt    ): 46.9%  (-18.1 pp)\n",
      "\n",
      "================================================================================\n",
      "WZORCE:\n",
      "================================================================================\n",
      "‚Ä¢ Rola eksperta:     53.3%\n",
      "‚Ä¢ Rola amatora:      56.7%\n",
      "  ‚Üí r√≥≈ºnica = -3.3 pp\n",
      "\n",
      "‚Ä¢ Positive framing:  56.7%\n",
      "‚Ä¢ Negative framing:  60.0%\n",
      "  ‚Üí r√≥≈ºnica = -3.3 pp\n",
      "\n",
      "‚Ä¢ Chain-of-thought:  57.6%\n",
      "  ‚Üí vs baseline: -7.4 pp\n",
      "\n",
      "‚Ä¢ Scrambled:         46.9%\n",
      "  ‚Üí vs baseline: -18.1 pp\n",
      "\n",
      "================================================================================\n",
      "REKOMENDACJA: stosuj strategiƒô 'Prompt'\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "baseline_acc = metrics_df[metrics_df['Strategy'] == 'Prompt']['Accuracy'].values[0]\n",
    "best_acc = metrics_df.iloc[0]['Accuracy']\n",
    "best_strat = metrics_df.iloc[0]['Strategy']\n",
    "worst_acc = metrics_df.iloc[-1]['Accuracy']\n",
    "worst_strat = metrics_df.iloc[-1]['Strategy']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ANALIZA WZORC√ìW\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nBaseline (Prompt):        {baseline_acc:.1%}\")\n",
    "print(f\"Najlepsza ({best_strat:20s}): {best_acc:.1%}  (+{(best_acc-baseline_acc)*100:.1f} pp)\")\n",
    "print(f\"Najs≈Çabsza ({worst_strat:20s}): {worst_acc:.1%}  ({(worst_acc-baseline_acc)*100:+.1f} pp)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"WZORCE:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "role_expert = metrics_df[metrics_df['Strategy'] == 'Positive_Extra_role']['Accuracy'].values[0]\n",
    "role_amateur = metrics_df[metrics_df['Strategy'] == 'Negative_Extra_role']['Accuracy'].values[0]\n",
    "print(f\"‚Ä¢ Rola eksperta:     {role_expert:.1%}\")\n",
    "print(f\"‚Ä¢ Rola amatora:      {role_amateur:.1%}\")\n",
    "print(f\"  ‚Üí r√≥≈ºnica = {(role_expert - role_amateur)*100:+.1f} pp\")\n",
    "\n",
    "pos = metrics_df[metrics_df['Strategy'] == 'Positive_prompt']['Accuracy'].values[0]\n",
    "neg = metrics_df[metrics_df['Strategy'] == 'Negative_prompt']['Accuracy'].values[0]\n",
    "print(f\"\\n‚Ä¢ Positive framing:  {pos:.1%}\")\n",
    "print(f\"‚Ä¢ Negative framing:  {neg:.1%}\")\n",
    "print(f\"  ‚Üí r√≥≈ºnica = {(pos - neg)*100:+.1f} pp\")\n",
    "\n",
    "cot = metrics_df[metrics_df['Strategy'] == 'Chain_of_thoughts']['Accuracy'].values[0]\n",
    "print(f\"\\n‚Ä¢ Chain-of-thought:  {cot:.1%}\")\n",
    "print(f\"  ‚Üí vs baseline: {(cot - baseline_acc)*100:+.1f} pp\")\n",
    "\n",
    "scrambled = metrics_df[metrics_df['Strategy'] == 'Scrambled_prompt']['Accuracy'].values\n",
    "if len(scrambled) > 0:\n",
    "    scrambled_acc = scrambled[0]\n",
    "    print(f\"\\n‚Ä¢ Scrambled:         {scrambled_acc:.1%}\")\n",
    "    print(f\"  ‚Üí vs baseline: {(scrambled_acc - baseline_acc)*100:+.1f} pp\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"REKOMENDACJA: stosuj strategiƒô '{best_strat}'\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lupa-na-prompt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

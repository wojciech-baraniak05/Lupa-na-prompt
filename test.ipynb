{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aa44c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('prompts2.csv', sep=';')\n",
    "print(df['Prompt'].dtype, df['Flag'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f7aeaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "kontekst = \"ROZPOCZƒòCIE WYK≈ÅADU METODY NUMERYCZNE \\n\"\n",
    "kontekst += pathlib.Path('context/MN.md').read_text(encoding='utf-8')\n",
    "kontekst += \"ROZPOCZƒòCIE WYK≈ÅADU RACHUNEK PRAWDOBIE≈ÉSTWA \\n\"\n",
    "kontekst += pathlib.Path('context/prob.md').read_text(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c0e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "client = genai.Client(api_key='w≈Çasny klucz api google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b069778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typ kolumny Prompt: <class 'pandas.core.series.Series'>\n",
      "Wymiary danych: (60, 13)\n",
      "Dostƒôpne kolumny: ['Prompt', 'Flag', 'Negative_prompt', 'Positive_prompt', 'Positive_Extra_role', 'Negative_Extra_role', 'Uncertainty_prompt', 'Scrambled_prompt', 'Chain_of_thoughts', 'Sceptical_role', 'High_stakes', 'Tipping', 'Random_mistake']\n",
      "Kolumny z promptami do przetworzenia: ['Prompt', 'Negative_prompt', 'Positive_prompt', 'Positive_Extra_role', 'Negative_Extra_role', 'Uncertainty_prompt', 'Scrambled_prompt', 'Chain_of_thoughts', 'Sceptical_role', 'High_stakes', 'Tipping', 'Random_mistake']\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample, choice\n",
    "\n",
    "\n",
    "class DataModel:\n",
    "    def __init__(self, df, client):\n",
    "        self.df = df\n",
    "        self.responses = pd.DataFrame(index=df.index)\n",
    "        self.client = client\n",
    "        self.columns_with_prompts = ['Prompt']\n",
    "\n",
    "    def __call__(self):\n",
    "        print(f\"Typ kolumny Prompt: {type(self.df['Prompt'])}\")\n",
    "        print(f\"Wymiary danych: {self.df.shape}\")\n",
    "        print(f\"Dostƒôpne kolumny: {self.df.columns.to_list()}\")\n",
    "        print(f\"Kolumny z promptami do przetworzenia: {self.columns_with_prompts}\")\n",
    "\n",
    "    def make_prompts(self):\n",
    "        self.df[\"Prompt\"] = self.df[\"Prompt\"].apply(lambda x: f\"{x} \\n odpowiedz '1' je≈õli zdanie jest prawdziwe, '0' je≈õli fa≈Çszywe.\")\n",
    "        \n",
    "        def inject_noise(text, rate=0.1):\n",
    "            if not isinstance(text, str): return str(text)\n",
    "            indices = [i for i, c in enumerate(text) if c.isalpha()]\n",
    "            if not indices: return text\n",
    "            \n",
    "            k = int(len(indices) * rate)\n",
    "            text_list = list(text)\n",
    "            for i in sample(indices, k):\n",
    "                text_list[i] = choice(string.ascii_letters)\n",
    "            return \"\".join(text_list)\n",
    "\n",
    "        strategies = {\n",
    "            'Negative_prompt': lambda x: f\"My≈õlƒô, ≈ºe to zdanie zawiera problem, czy mam racjƒô?: {x}\",\n",
    "            'Positive_prompt': lambda x: f\"My≈õlƒô, ≈ºe to zdanie jest poprawne, czy mam racjƒô?: {x}\",\n",
    "            'Positive_Extra_role': lambda x: f\"Jeste≈õ ekspertem w dziedzinie rachunku prawdopodobie≈Ñstwa oraz metod numerycznych, sprawd≈∫ prawdziwo≈õƒá: {x}\",\n",
    "            'Negative_Extra_role': lambda x: f\"Jeste≈õ ekspertem w dziedzinie socjologii oraz obcych form ≈ºycia, sprawd≈∫ prawdziwo≈õƒá: {x}\",\n",
    "            'Uncertainty_prompt': lambda x: f\"Oce≈Ñ prawdziwo≈õƒá tego zdania tylko je≈ºeli jeste≈õ pewny odpowiedzi: {x}\",\n",
    "            'Scrambled_prompt': lambda x: f\"Oce≈Ñ prawdziwo≈õƒá (tekst pomieszany): {''.join(np.random.permutation(list(x)))}\",\n",
    "            'Chain_of_thoughts': lambda x: f\"Przeanalizuj dok≈Çadnie to zdanie krok po kroku i oce≈Ñ jego prawdziwo≈õƒá: {x}\",\n",
    "            'Sceptical_role': lambda x: f\"Jeste≈õ sceptykiem, kt√≥ry zawsze podwa≈ºa prawdziwo≈õƒá informacji. Oce≈Ñ: {x}\",\n",
    "            'High_stakes': lambda x: f\"Oce≈Ñ prawdziwo≈õƒá, pamiƒôtajƒÖc, ≈ºe od twojej odpowiedzi zale≈ºy ≈ºycie wielu os√≥b: {x}\",\n",
    "            'Tipping': lambda x: f\"Dostaniesz du≈ºy napiwek je≈õli prawid≈Çowo ocenisz to zdanie: {x}\",\n",
    "            'Random_mistake': lambda x: f\"Oce≈Ñ prawdziwo≈õƒá: {inject_noise(x)}\"\n",
    "        }\n",
    "\n",
    "        for col_name, func in strategies.items():\n",
    "            self.df[col_name] = self.df[\"Prompt\"].apply(func)\n",
    "            self.columns_with_prompts.append(col_name)\n",
    "\n",
    "    async def prompts(self):\n",
    "        print(f\"Rozpoczynam generowanie dla {len(self.columns_with_prompts)} kolumn...\")\n",
    "        \n",
    "        for col_name in self.columns_with_prompts:\n",
    "            print(f\"--> Przetwarzanie kolumny: {col_name}\")\n",
    "            prompts_list = self.df[col_name].tolist()\n",
    "            \n",
    "            tasks = []\n",
    "            for prompt in prompts_list:\n",
    "                tasks.append(\n",
    "                    self.client.aio.models.generate_content(\n",
    "                        model='gemma-3-4b-it',\n",
    "                        contents=prompt,\n",
    "                        config=types.GenerateContentConfig(temperature=0.5)\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "\n",
    "            results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "            \n",
    "            cleaned_results = []\n",
    "            for res in results:\n",
    "                if isinstance(res, Exception):\n",
    "                    cleaned_results.append(f\"Error: {str(res)}\")\n",
    "                else:\n",
    "                    cleaned_results.append(res.text.strip())\n",
    "            \n",
    "            self.responses[col_name] = cleaned_results\n",
    "            \n",
    "        print(\"Zako≈Ñczono generowanie wszystkich odpowiedzi.\")\n",
    "        return self.responses\n",
    "\n",
    "data_model = DataModel(df, client)\n",
    "data_model.make_prompts()\n",
    "data_model() # Wy≈õwietli info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7de0acb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczynam generowanie dla 12 kolumn...\n",
      "--> Przetwarzanie kolumny: Prompt\n",
      "--> Przetwarzanie kolumny: Negative_prompt\n",
      "--> Przetwarzanie kolumny: Positive_prompt\n",
      "--> Przetwarzanie kolumny: Positive_Extra_role\n",
      "--> Przetwarzanie kolumny: Negative_Extra_role\n",
      "--> Przetwarzanie kolumny: Uncertainty_prompt\n",
      "--> Przetwarzanie kolumny: Scrambled_prompt\n",
      "--> Przetwarzanie kolumny: Chain_of_thoughts\n",
      "--> Przetwarzanie kolumny: Sceptical_role\n",
      "--> Przetwarzanie kolumny: High_stakes\n",
      "--> Przetwarzanie kolumny: Tipping\n",
      "--> Przetwarzanie kolumny: Random_mistake\n",
      "Zako≈Ñczono generowanie wszystkich odpowiedzi.\n",
      "                                              Prompt  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2                                                  1   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                     Negative_prompt  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                     Positive_prompt  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                 Positive_Extra_role  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                 Negative_Extra_role  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                  Uncertainty_prompt  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                    Scrambled_prompt  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                   Chain_of_thoughts  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                      Sceptical_role  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                         High_stakes  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                             Tipping  \\\n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...   \n",
      "\n",
      "                                      Random_mistake  \n",
      "0  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...  \n",
      "1  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...  \n",
      "2  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...  \n",
      "3  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...  \n",
      "4  Error: 429 RESOURCE_EXHAUSTED. {'error': {'cod...  \n"
     ]
    }
   ],
   "source": [
    "responses_df = await data_model.prompts()\n",
    "print(responses_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf22831",
   "metadata": {},
   "source": [
    "## Testowe generowanie odpowiedzi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beffa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "client = genai.Client(api_key='w≈Çasny klucz api google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122da82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model='gemma-3-4b-it',\n",
    "    contents=\"Napisz co robisz teraz\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0.5,)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96fbb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obecnie generujƒô tekst na podstawie Twojego zapytania. Staram siƒô zrozumieƒá, czego potrzebujesz i odpowiedzieƒá w spos√≥b jak najbardziej pomocny i zrozumia≈Çy. W≈Ça≈õnie piszƒô to, co teraz czytasz! üòä\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lupa-na-prompt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

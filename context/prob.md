![](_page_0_Picture_0.jpeg)

![](_page_0_Picture_1.jpeg)

![](_page_0_Picture_2.jpeg)

![](_page_0_Picture_3.jpeg)

# RACHUNEK PRAWDOPODOBIEÅƒSTWA

### BARTOSZ KOÅODZIEJEK WYDZIAÅ MATEMATYKI I NAUK INFORMACYJNYCH

## WykÅ‚ad

Projekt "NERW 2 PW. Nauka - Edukacja - RozwÃ³j - WspÃ³Å‚praca" wspÃ³Å‚finansowany ze Å›rodkÃ³w Unii Europejskiej w ramach Europejskiego Funduszu SpoÅ‚ecznego.

Zadanie 10 pn. "Modyfikacja programÃ³w studiÃ³w na kierunkach prowadzonych przez WydziaÅ‚ Matematyki i Nauk Informacyjnych", realizowane w ramach projektu "NERW 2 PW. Nauka - Edukacja - RozwÃ³j - WspÃ³Å‚praca", wspÃ³Å‚finansowanego jest ze Å›rodkÃ³w Unii Europejskiej w ramach Europejskiego Funduszu SpoÅ‚ecznego.

#### 29 stycznia 2022

#### Spis treÅ›ci

| 1. W1 - Aksjomaty i przestrzeÅ„ probabilistyczna                                             | 2  |
|---------------------------------------------------------------------------------------------|----|
| Miara Lebesgue'a                                                                            | 4  |
| 2. W2 - PrawdopodobieÅ„stwo warunkowe                                                        | 5  |
| <b>â™‚</b> Konstrukcja zbioru niemierzalnego <b>â™‚</b>                                         | 6  |
| 3. W3 - NiezaleÅ¼noÅ›Ä‡ i Lematy Borela-Cantellego                                             | 7  |
| 4. W4 - Zmienne losowe, rozkÅ‚ady i dystrybuanty                                             | Ã–  |
| CaÅ‚ka wzglÄ™dem miary                                                                        | 11 |
| 5. W5 - WartoÅ›Ä‡ oczekiwana                                                                  | 13 |
| 6. W6 - Wariancja, nierÃ³wnoÅ›ci i wektory losowe                                             | 14 |
| 7. W7 - Wektory losowe ciÄ…g dalszy                                                          | 16 |
| 8. W8 - Wektory losowe dalszy ciÄ…g dalszy                                                   | 18 |
| 9. W9 - Kowariancja, zbieÅ¼noÅ›Ä‡ wedÅ‚ug prawdopodobieÅ„stwa i SPWL                             | 20 |
| 10. W<br>10 - ZbieÅ¼noÅ›Ä‡ z prawdopodobieÅ„stwem 1 (MPWL), w $\mathcal{L}_p$ i wedÅ‚ug rozkÅ‚adu | 22 |
| Dodatek - symulacje                                                                         | 24 |
| 11. W11 - ZbieÅ¼noÅ›Ä‡ wedÅ‚ug rozkÅ‚adu ciÄ…g dalszy                                             | 27 |
| 12. W12 - Centralne Twierdzenie Graniczne                                                   | 29 |
| 13. W13 - Warunkowa wartoÅ›Ä‡ oczekiwana                                                      | 31 |
| 14. W14 - Warunkowa wartoÅ›Ä‡ oczekiwana ciÄ…g dalszy                                          | 33 |
| 15. W15 - Co warto pamiÄ™taÄ‡ + uzupeÅ‚nienia                                                  | 36 |

Legenda: ğŸ— â€“ Definicja, TW. â€“ Twierdzenie, ğŸ“½ â€“ PrzykÅ‚ad, ğŸ›• â€“ Uwaga, LEM. â€“ Lemat, ğŸ‘ â€“ Oznaczenie, ğŸ“ â€“ do samodzielnej rozkminki, â€” dla chÄ™tnych (moÅ¼e byÄ‡ trudne)

#### 1. W1 - Aksjomaty i przestrzeÅ„ probabilistyczna

- <span id="page-1-0"></span> $(1.1) \ \ \text{JeÅ›li} \ \Omega \ \text{jest niepustym zbiorem, to przez} \ 2^{\Omega} \ \text{oznaczamy jego zbiÃ³r potÄ™gowy, czyli zbiÃ³r wszystkich jego podzbio$ rÃ³w. JeÅ›li  $\Omega$  jest zbiorem skoÅ„czonym, to mamy  $\#2^{\Omega} = 2^{\#\Omega}$ .
  - lacktriangle Symbol #A oznacza tutaj licznoÅ›Ä‡ (moc) zbioru A, czÄ™sto oznaczanÄ… teÅ¼ przez  $\overline{A}$ .
- (1.2)  $\blacksquare$  RodzinÄ™  $\mathcal{F} \subset 2^{\Omega}$  (podzbiorÃ³w zbioru  $\Omega \neq \emptyset$ ) nazywamy  $\sigma$ -ciaÅ‚em jeÅ›li:
  - (a)  $\Omega \in \mathcal{F}$ .

  - (b)  $A \in \mathcal{F} \implies A^c = \Omega \setminus A \in \mathcal{F},$ (c)  $A_1, A_2, \ldots \in \mathcal{F} \implies \bigcup_{i=1}^{\infty} A_i \in \mathcal{F}.$
- (1.3) **A** Warunek (a) powyÅ¼ej moÅ¼na zastÄ…piÄ‡ przez warunek (a')  $\emptyset \in \mathcal{F}$ .
  - A Warunek (c) powyÅ¼ej moÅ¼na zastapiÄ‡ przez warunek
- (c')  $A_1, A_2, \ldots \in \mathcal{F} \implies \bigcap_{i=1}^{\infty} A_i \in \mathcal{F}$ . (1.4)  $\mathfrak{S}^{\mathfrak{s}}_{\bullet}$  PrzykÅ‚adami  $\sigma$ -ciaÅ‚ sÄ…  $\mathcal{F}_0 = \{\emptyset, \Omega\}, \ \mathcal{F}_1 = 2^{\Omega} \text{ oraz } \mathcal{F}_A = \{\emptyset, \Omega, A, A^c\} \text{ o ile } A \subset \Omega$ .
- (1.5)  $\triangle$  KaÅ¼dÄ… rodzinÄ™  $\mathcal{A}$  podzbiorÃ³w zbioru  $\Omega$  moÅ¼na uzupeÅ‚niÄ‡ do  $\sigma$ -ciaÅ‚a.
- (1.6)  $\blacksquare$   $\sigma$ -ciaÅ‚o generowane przez rodzinÄ™ podzbiorÃ³w  $\mathcal{A}$  ( $\odot$   $\sigma(\mathcal{A})$ ) jest to najmniejsze  $\sigma$ -ciaÅ‚o zawierajÄ…ce  $\mathcal{A}$ :

$$\sigma(\mathcal{A}) = \bigcap_{\mathcal{F} - \sigma\text{-cialo: } \mathcal{A} \subset \mathcal{F}} \mathcal{F}.$$

- A PokazaÄ‡, Å¼e przeciecie dowolnej (byÄ‡ moÅ¼e nieprzeliczalnej) rodziny  $\sigma$ -ciaÅ‚ jest  $\sigma$ -ciaÅ‚em.
- $\$ PokazaÄ‡, Å¼e jest tylko jedno najmniejsze  $\sigma$ -ciaÅ‚o zawierajÄ…cÄ™ rodzinÄ™  $\mathcal{A}$ .
- (1.7)  $\bullet_{\bullet}^{\bullet}$  JeÅ›li  $\mathcal{A} = \{A\}$ , to  $\sigma(\mathcal{A}) = \{\emptyset, \Omega, A, A^c\}$ .
- (1.8)  $\Omega = \{a, b, c, d\}, A = \{\{a, b\}, \{c\}\}\}$ . PokazaÄ‡, Å¼e  $\#\sigma(A) = 2^3$ .
- (1.9)  $\Omega = [0,1], A = \{(0,1), (1/2,1]\}, \sigma(A) = ?.$
- (1.10)  $\blacksquare \sigma$ -ciaÅ‚o zbiorÃ³w borelowskich  $\mathbb{R}$  ( $\bullet$   $\mathcal{B}(\mathbb{R})$ ) jest to  $\sigma$ -ciaÅ‚o generowane przez rodzinÄ™ otwartych przedziaÅ‚Ã³w na prostej, tzn.  $\mathcal{B}(\mathbb{R}) = \sigma(\mathcal{A})$ , gdzie  $\mathcal{A} = \{(a, b) \subset \mathbb{R} : a < b\}$ .

 $\blacksquare$  Podobnie definiujemy  $\sigma$ -ciaÅ‚o zbiorÃ³w borelowskich  $\mathbb{R}^n$  ( $\bullet$   $\mathcal{B}(\mathbb{R}^n)$ ):  $\mathcal{B}(\mathbb{R}^n) = \sigma(\mathcal{A}_n)$ , gdzie

$$\mathcal{A}_n = \{(a_1, b_1) \times \ldots \times (a_n, b_n) \subset \mathbb{R}^n \colon a_i < b_i, i = 1, \ldots, n\}.$$

**A** Na Ä‡wiczeniach dowiemy siÄ™, Å¼e  $\sigma$ -ciaÅ‚o zbiorÃ³w borelowskich moÅ¼e byÄ‡ zdefiniowane (i w sumie czÄ™sto jest) jako  $\sigma$ -ciaÅ‚o generowane przez rodzinÄ™ zbiorÃ³w otwartych (a nie tylko przedziaÅ‚Ã³w).

- (1.11)  $\blacksquare$  FunkcjÄ™  $\mathbb{P}$  okreÅ›lonÄ… na  $\sigma$ -ciele  $\mathcal{F} \subset 2^{\Omega}$  nazywamy prawdopodobieÅ„stwem jeÅ›li
  - (a)  $A \in \mathcal{F} \implies \mathbb{P}(A) > 0$ ,
  - (b)  $\mathbb{P}(\Omega) = 1$ ,

  - (c)  $A_i \in \mathcal{F}, i = 1, 2, ...,$  oraz  $A_i \cap A_j = \emptyset$  dla  $i \neq j \implies \mathbb{P}(\bigcup_{i=1}^{\infty} A_i) = \sum_{i=1}^{\infty} \mathbb{P}(A_i).$ B JeÅ›li speÅ‚nione sÄ… tylko (a) i (c), to powiemy, Å¼e  $\mathbb{P}$  jest miarÄ…. JeÅ›li  $\mathbb{P}(\Omega) < \infty$ , to  $\mathbb{P}$  jest miarÄ… skoÅ„czonÄ….

#### â–² Warunek:

$$\forall A_1, A_2 \in \mathcal{F} \ A_1 \cap A_2 = \emptyset \implies \mathbb{P}(A_1 \cup A_2) = \mathbb{P}(A_1) + \mathbb{P}(A_2)$$

poprzez indukcjÄ™ implikuje tzw. skoÅ„czonÄ… addytywnoÅ›Ä‡,

$$\forall n \ \forall A_1, \dots, A_n \ \forall i \neq j \ A_i \cap A_j = \emptyset \implies \mathbb{P}\left(\bigcup_{i=1}^n A_i\right) = \sum_{i=1}^n \mathbb{P}(A_i),$$

ktÃ³ra jest warunkiem **istotnie** sÅ‚abszym niÅ¼ warunek (c) z definicji prawdopodobieÅ„stwa

- (1.12) **TW.** Elementarne wÅ‚asnoÅ›ci prawdopodobieÅ„stwa.
  - (a)  $\mathbb{P}(\emptyset) = 0$ .
  - (b)  $A_i \in \mathcal{F}, i = 1, ..., n, \text{ oraz } A_i \cap A_j = \emptyset \text{ dla } i \neq j \implies \mathbb{P}(\bigcup_{i=1}^n A_i) = \sum_{i=1}^n \mathbb{P}(A_i).$
  - (c)  $A, B \in \mathcal{F}, A \subset B \implies \mathbb{P}(B \setminus A) = \mathbb{P}(B) \mathbb{P}(A)$ .
  - (d)  $A \in \mathcal{F} \implies \mathbb{P}(A^c) = 1 \mathbb{P}(A)$ .
  - (e)  $A, B \in \mathcal{F}, A \subset B \implies \mathbb{P}(A) < \mathbb{P}(B).$
  - (f)  $A, B \in \mathcal{F} \implies \mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B) \mathbb{P}(A \cap B)$ .
  - $(g) \ A, B, C \in \mathcal{F} \implies \mathbb{P}(A \cup B \cup C) = \mathbb{P}(A) + \mathbb{P}(B) + \mathbb{P}(C) \mathbb{P}(A \cap B) \mathbb{P}(A \cap C) \mathbb{P}(B \cap C) + \mathbb{P}(A \cap B \cap C).$
  - (h) (WzÃ³r wÅ‚Ä…czeÅ„ i wyÅ‚Ä…czeÅ„)  $A_i \in \mathcal{F}, i = 1, \ldots, n,$

$$\mathbb{P}\left(\bigcup_{i=1}^{n} A_{i}\right) = \sum_{j=1}^{n} (-1)^{j+1} \sum_{1 \leq i_{1} < i_{2} < \dots < i_{j} \leq n} \mathbb{P}\left(A_{i_{1}} \cap A_{i_{2}} \cap \dots \cap A_{i_{j}}\right).$$

Fakt przydatny w zadaniach:

$$\sum_{1 \le i_1 < i_2 < \dots < i_j \le n} 1 = \binom{n}{j}.$$

- (1.13) **TW.** Nieelementarne wÅ‚asnoÅ›ci prawdopodobieÅ„stwa.
  - (a) (PodaddytywnoÅ›Ä‡) JeÅ›li  $A_1, A_2, \ldots \in \mathcal{F}$ , to

$$\mathbb{P}\left(\bigcup_{i=1}^{\infty} A_i\right) \le \sum_{i=1}^{\infty} \mathbb{P}(A_i)$$

Szkic dowodu:  $B_1 = A_1$ ,  $B_n = A_n \setminus \bigcup_{i=1}^{n-1} A_i$ ,  $n = 2, 3, \ldots$  Mamy  $B_n \in \mathcal{F}$ ,  $B_n \subset A_n$ ,  $(B_n)_{n \geq 1}$  sÄ… rozÅ‚Ä…czne oraz  $\bigcup_{i=1}^n B_i = \bigcup_{i=1}^n A_i$  dla  $n = 1, 2, \ldots, \infty$ . Zatem

$$\mathbb{P}\left(\bigcup_{i=1}^{\infty} A_i\right) = \mathbb{P}\left(\bigcup_{i=1}^{\infty} B_i\right) = \sum_{i=1}^{\infty} \mathbb{P}(B_i) \le \sum_{i=1}^{\infty} \mathbb{P}(A_i).$$

(b) (CiÄ…gÅ‚oÅ›Ä‡ z doÅ‚u) JeÅ›li  $A_1, A_2, \ldots \in \mathcal{F}$  oraz  $A_i \subset A_{i+1}$  dla  $i = 1, 2, \ldots$ , to

$$\mathbb{P}\left(\bigcup_{i=1}^{\infty} A_i\right) = \lim_{n \to \infty} \mathbb{P}(A_n).$$

Szkic dowodu:  $B_1 = A_1$ ,  $B_n = A_n \setminus A_{n-1}$  dla  $n = 2, 3, \dots$  Zdarzenia  $(B_n)_{n \geq 1}$  sa rozÅ‚Ä…czne, zatem

$$\mathbb{P}\left(\bigcup_{i=1}^{\infty}A_i\right) = \mathbb{P}\left(\bigcup_{i=1}^{\infty}B_i\right) = \sum_{i=1}^{\infty}\mathbb{P}(B_i) = \lim_{n \to \infty}\sum_{i=1}^{n}\mathbb{P}(B_i) = \lim_{n \to \infty}\mathbb{P}(A_n),$$

poniewaÅ¼  $\mathbb{P}(B_i) = \mathbb{P}(A_i) - \mathbb{P}(A_{i-1}) \text{ dla } i \geq 2.$ 

(c) (CiÄ…gÅ‚oÅ›Ä‡ z gÃ³ry) JeÅ›li  $A_1, A_2, \ldots \in \mathcal{F}$  oraz  $A_{i+1} \subset A_i$  dla  $i=1,2,\ldots$ , to

$$\mathbb{P}\left(\bigcap_{i=1}^{\infty} A_i\right) = \lim_{n \to \infty} \mathbb{P}(A_n).$$

Szkic dowodu:  $A_n^c \subset A_{n+1}^c, \ n=1,2,\ldots$  Zatem (prawo de Morgana:  $(\bigcap_n A_n)^c = \bigcup_n A_n^c)$  z ciÄ…gÅ‚oÅ›ci z doÅ‚u

$$\mathbb{P}\left(\bigcap_{i=1}^{\infty} A_i\right) = 1 - \mathbb{P}\left(\bigcup_{i=1}^{\infty} A_i^c\right) = 1 - \lim_{n \to \infty} \mathbb{P}(A_n^c) = \lim_{n \to \infty} \mathbb{P}(A_n).$$

- (1.14)  $\blacksquare$  PrzestrzeniÄ… probabilistycznÄ… nazywamy trÃ³jkÄ™  $(\Omega, \mathcal{F}, \mathbb{P})$ , gdzie
  - $\Omega$  jest niepustym zbiorem,
  - $\mathcal{F}$  jest  $\sigma$ -ciaÅ‚em podzbiorÃ³w  $\Omega$ ,
  - $\mathbb{P}$  jest prawdopodobieÅ„stwem na  $\mathcal{F}$ .
  - $\blacksquare$  ParÄ™  $(\Omega, \mathcal{F})$  bÄ™dziemy nazywali przestrzeniÄ… mierzalnÄ….
  - Elementy  $\Omega$  nazywamy zdarzeniami elementarnymi. Elementy  $\mathcal{F}$  to po prostu zdarzenia. W szczegÃ³lnoÅ›ci,  $\emptyset$  zdarzenie niemoÅ¼liwe,  $\Omega$  zdarzenie pewne.

JeÅ›li  $A \in \mathcal{F}$  oraz  $\mathbb{P}(A) = 1$ , to powiemy, Å¼e zdarzenie A zajdzie <u>prawie na pewno</u>. JeÅ›li  $A \in \mathcal{F}$  oraz  $\mathbb{P}(A) = 0$ , to powiemy, Å¼e zdarzenie A prawie na pewno nie zajdzie.

(1.15) Elementy kombinatoryki.

Twierdzenie o mnoÅ¼eniu:

$$\#(A_1 \times \ldots \times A_n) = (\#A_1) \cdot \ldots \cdot (\#A_n).$$

Niech dalej #A = n.

â€¢ Wybory uporzÄ…dkowane ze zwracaniem: (wariacje z powtÃ³rzeniami)

$$\#\{(a_1,\ldots,a_r): a_j \in A, j=1,\ldots,r\} = n^r$$
.

â€¢ Wybory uporzÄ…dkowane bez zwracania: (wariacje bez powtÃ³rzeÅ„)

$$\#\{(a_1,\ldots,a_r): a_j \in A, \ a_j \neq a_k \ \text{dla} \ j \neq k\} = \frac{n!}{(n-r)!}, \quad r \leq n.$$

â€¢ Wybory nieuporzÄ…dkowane bez zwracania: (kombinacje)

$$\#\{\{a_1,\ldots,a_r\}: a_j \in A, \ a_j \neq a_k \ \text{dla} \ j \neq k\} = \binom{n}{r}, \quad r \leq n.$$

- (1.16) ğŸ—± PrzykÅ‚ady przestrzeni probabilistycznych
  - (a) Schemat klasyczny:  $\#\Omega < \infty$ ,  $\mathcal{F} = 2^{\Omega}$ ,  $\mathbb{P}(A) := \frac{\#A}{\#\Omega}$ .
  - (b) UogÃ³lniony schemat klasyczny:  $\Omega$  zbiÃ³r przeliczalny,  $\mathcal{F} = 2^{\Omega}$ ,  $\mathbb{P}(A) = \sum_{\omega \in A} p(\omega)$ , gdzie  $p \colon \Omega \to [0, 1]$  jest funkcjÄ… takÄ…, Å¼e  $\sum_{\omega \in \Omega} p(\omega) = 1$ .
    - $\Omega = \{0, 1, 2, \ldots\}, p(\omega) = q(1 q)^{\omega} \text{ dla pewnego } q \in (0, 1).$
  - (c) Schemat geometryczny:  $\Omega \subset \mathbb{R}^n$  zbiÃ³r ograniczony,  $\mathcal{F} = \mathcal{B}(\Omega) := \{A \cap \Omega \colon A \in \mathcal{B}(\mathbb{R}^n)\}$ ,  $\lambda_n$  tzw. miara Lebesgue'a, czyli naturalne uogÃ³lnienie pojÄ™cia dÅ‚ugoÅ›ci/pola/objÄ™toÅ›ci,  $\mathbb{P}(A) = \frac{\lambda_n(A)}{\lambda_n(\Omega)}$ . O mierze Lebesgue'a dalei.
    - $\bf A$  ZaskakujÄ…cy na tym etapie moÅ¼e byÄ‡ wybÃ³r  $\sigma$ -ciaÅ‚a. Dlaczego nie wzieliÅ›my po prostu  ${\cal F}=2^{\Omega}$ ? Okazuje siÄ™, Å¼e taki wybÃ³r jest niemoÅ¼liwy, poniewaÅ¼ to  $\sigma$ -ciaÅ‚o jest zbyt bogate i zawiera zbiory ktÃ³rym nie moÅ¼na nadaÄ‡ miary. SzczegÃ³Å‚y juÅ¼ niedÅ‚ugo.
    - (Losowe rendez-vous) Asia i Krysia umawiajÄ… siÄ™ na spotkanie miÄ™dzy 12 a 13. UstaliÅ‚y wczeÅ›niej, Å¼e kaÅ¼da czeka 15 minut i odchodzi. Obie przychodzÄ… niezaleÅ¼nie od siebie w losowym momencie miÄ™dzy 12 i 13. Oblicz prawdopodobieÅ„stwo, Å¼e siÄ™ spotkajÄ….

#### <span id="page-3-0"></span>MIARA LEBESGUE'A

JeÅ›li zbiÃ³r  $A \subset \mathbb{R}$  jest domkniÄ™tym przedziaÅ‚em, tzn. A = [a, b] dla pewnych a < b, to definiujemy jego dÅ‚ugoÅ›Ä‡ poprzez

$$|A| = |[a, b]| = b - a.$$

Chcemy rozszerzyÄ‡ pojÄ™cie dÅ‚ugoÅ›ci na zbiory ogÃ³lniejszej klasy niÅ¼ domkniÄ™te przedziaÅ‚y. Dla dowolnego zbioru  $A \subset \mathbb{R}$  definiujemy tzw. miare zewnÄ™trznÄ… Lebesgue'a, tzn.

$$\lambda^*(A) = \inf \left\{ \sum_{B \in \mathcal{C}} |B| \colon \mathcal{C} \text{ jest przeliczalnÄ… rodzinÄ… przedziaÅ‚Ã³w domkniÄ™tych, ktÃ³ra pokrywa } A \right\}.$$

PowyÅ¼sze infimum przebiega wszystkie rodziny przedziaÅ‚Ã³w  $\mathcal{C} = \{B_1, \ldots, B_n\}$  pokrywajÄ…ce zbiÃ³r A tzn. takie, Å¼e  $A \subset \bigcup_k B_k$  oraz kaÅ¼dy z  $B_k$  jest przedziaÅ‚em.

 $\blacksquare$  Powiemy, Å¼e zbiÃ³r  $A \subset \mathbb{R}$  jest mierzalny w sensie miary Lebesgue'a, jeÅ›li zachodzi (warunek CarathÃ©odory'ego)

$$\lambda^*(S) = \lambda^*(S \cap A) + \lambda^*(S \cap A^c), \qquad \forall S \subset \mathbb{R}.$$

 $\triangle$  Okazuje siÄ™, Å¼e zbiory A speÅ‚niajÄ…ce ten warunek tworzÄ…  $\sigma$ -ciaÅ‚o, czasem zwane  $\sigma$ -ciaÅ‚em Lebesgue'a.

 $\Delta$  To Ïƒ-ciaÅ‚o zawiera w sobie Ïƒ-ciaÅ‚o zbiorÃ³w borelowskich  $\mathcal{B}(\mathbb{R})$ , ale jest istotnie wiÄ™ksze (nawet w sensie mocy), tzn. istniejÄ… zbiory mierzalne w sensie miary Lebesgue'a, ktÃ³re nie sÄ… borelowskie.

 $\blacksquare$  MiarÄ™ Lebesgue'a zbioru A z  $\sigma$ -ciaÅ‚a Lebesgue'a definiujemy jako  $\lambda(A) := \lambda^*(A)$ .

Miara Lebesgue'a jest zupeÅ‚na w tym sensie, Å¼e jeÅ›li zbiÃ³r A jest mierzalny w sensie Lebesgue'a oraz  $\lambda(A) = 0$ , to wszystkie podzbiory A rÃ³wnieÅ¼ naleÅ¼Ä… do  $\sigma$ -ciaÅ‚a Lebesgue'a i w konsekwencji majÄ… miarÄ™ Lebesgue'a zero.

Na potrzeby rachunku prawdopodobieÅ„stwa zwykle wystarcza rozwaÅ¼aÄ‡ miarÄ™ Lebesgue'a na  $\sigma$ -ciele zbiorÃ³w borelowskich.

MiarÄ™ Lebesgue'a ( $\otimes \lambda_n$ ) na  $\mathbb{R}^n$  definiuje siÄ™ podobnie poprzez zadanie miary kostki n-wymiarowej:

$$|[a_1,b_2] \times [a_2,b_2] \times \ldots \times [a_n,b_n]| = \prod_{k=1}^n (b_k - a_k).$$

 $\wedge$  Uzasadnij, Å¼e  $\mathbb{Q} \in \mathcal{B}(\mathbb{R})$  oraz oblicz  $\lambda(\mathbb{Q})$ .

#### 2. W2 - PrawdopodobieÅ„stwo warunkowe

- <span id="page-4-0"></span>(2.1) CP PrzykÅ‚ady przestrzeni probabilistycznych
  - (a) Schemat klasyczny:  $\#\Omega < \infty$ ,  $\mathcal{F} = 2^{\Omega}$ ,  $\mathbb{P}(A) := \frac{\#A}{\#\Omega}$ .
  - (b) UogÃ³lniony schemat klasyczny:  $\Omega$  zbiÃ³r przeliczalny,  $\mathcal{F} = 2^{\Omega}$ ,  $\mathbb{P}(A) = \sum_{\omega \in A} p(\omega)$ , gdzie  $p \colon \Omega \to [0, 1]$  jest funkcjÄ… takÄ…, Å¼e  $\sum_{\omega \in \Omega} p(\omega) = 1$ .
    - $\Omega = \{0, 1, 2, \ldots\}, \ p(\omega) = q(1-q)^{\omega} \ dla \ pewnego \ q \in (0, 1).$
  - (c) Schemat geometryczny:  $\Omega \subset \mathbb{R}^n$  zbiÃ³r ograniczony,  $\mathcal{F} = \mathcal{B}(\Omega) := \{A \cap \Omega \colon A \in \mathcal{B}(\mathbb{R}^n)\}, \lambda_n$  miara Lebesgue'a na  $\mathcal{B}(\mathbb{R}^n)$ ,  $\mathbb{P}(A) = \frac{\lambda_n(A)}{\lambda_n(\Omega)}$ .
    - (Losowe rendez-vous) Asia i Krysia umawiajÄ… siÄ™ na spotkanie miÄ™dzy 12 a 13. UstaliÅ‚y wczeÅ›niej, Å¼e kaÅ¼da czeka 15 minut i odchodzi. Obie przychodzÄ… niezaleÅ¼nie od siebie w losowym momencie miÄ™dzy 12 i 13. Oblicz prawdopodobieÅ„stwo, Å¼e siÄ™ spotkajÄ….
- (2.2)  $\mathbf{A}$  W schemacie geometrycznym  $\Omega$  jest nieprzeliczalna i okazuje siÄ™, Å¼e nie istnieje prawdopodobieÅ„stwo  $\mathbb{P}$  na  $\mathcal{F} = 2^{\Omega}$ . Za pomocÄ… Aksjomatu Wyboru moÅ¼na skonstruowaÄ‡ patologiczne zbiory dla ktÃ³rych nie moÅ¼na zdefiniowaÄ‡ miary. O konstrukcji zbiorÃ³w niemierzalnych dalej (dla chÄ™tnych).
- (2.3) Raradoks Bertranda. Rzucamy losowo ciÄ™ciwÄ™ na okrÄ…g. Jakie jest prawdopodobieÅ„stwo, Å¼e jej dÅ‚ugoÅ›Ä‡ bÄ™dzie wiÄ™ksza od dÅ‚ugoÅ›ci boku trÃ³jkÄ…ta rÃ³wnobocznego wpisanego w ten okrÄ…g?
  - I. Ustalamy punkt na okrÄ™gu i rozwaÅ¼amy kÄ…ty jakie tworzÄ… ciÄ™ciwy przechodzÄ…ce przez ten punkt ze stycznÄ… do okrÄ™gu w tym punkcie:  $\Omega = [0, \pi], A = [\pi/3, 2\pi/3]$ . Zatem

$$\mathbb{P}(A) = \frac{\lambda(A)}{\lambda(\Omega)} = \frac{\pi/3}{\pi} = \frac{1}{3}.$$

II. Ustalamy kierunek i rozwaÅ¼amy ciÄ™ciwy rÃ³wnolegÅ‚e. Wtedy wystarczy badaÄ‡ poÅ‚oÅ¼enie Å›rodka ciÄ™ciw na Å›rednicy, tzn.  $\Omega = [0, 2r]$ , oraz A = [r/2, 3r/2], gdzie r jest promieniem okrÄ™gu. Czyli

$$\mathbb{P}(A) = \frac{\lambda(A)}{\lambda(\Omega)} = \frac{r}{2r} = \frac{1}{2}.$$

III. Bierzemy pod uwagÄ™ Å›rodki ciÄ™ciw.  $\Omega = \{(x,y) : x^2 + y^2 < r^2\}$ . Interesuje nas zdarzenie, gdy Å›rodek ciÄ™ciwy leÅ¼y wewnÄ…trz okrÄ™gu wpisanego w trÃ³jkÄ…t rÃ³wnoboczny, tzn.  $A = \{(x,y) : x^2 + y^2 < r^2/4\}$ . Wobec tego

$$\mathbb{P}(A) = \frac{\lambda(A)}{\lambda(\Omega)} = \frac{\pi r^2/4}{\pi r^2} = \frac{1}{4}.$$

(2.4)  $\blacksquare$  Niech  $A, B \in \mathcal{F}$  oraz  $\mathbb{P}(B) > 0$ . PrawdopodobieÅ„stwem warunkowym zdarzenia A pod warunkiem B nazywamy wielkoÅ›Ä‡

$$\mathbb{P}(A|B) = \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)}.$$

- (2.5) CiÄ…g zbiorÃ³w  $(A_1, A_2, ...)$  nazwiemy <u>przeliczalnym rozbiciem zbioru  $\Omega$ </u>, jeÅ›li  $A_i \in \mathcal{F}$  dla  $i = 1, 2, ..., \bigcup_{i=1}^{\infty} A_i = \Omega$  oraz  $A_i \cap A_j = \emptyset$  dla  $i \neq j$ . Przeliczalne rozbicie  $(A_1, A_2, ...)$  nazwiemy <u>nietrywialnym</u>, jeÅ›li  $\mathbb{P}(A_i) > 0$  dla i = 1, 2, ...
  - lacktriangle Zamiast pisaÄ‡  $(A_1, A_2, \ldots)$ , bÄ™dziemy czasem rÃ³wnowaÅ¼nie pisaÄ‡  $(A_n)_{n=1}^{\infty}$  lub, jeszcze krÃ³cej,  $(A_n)_n$ .
- (2.6) **TW.** (WzÃ³r na prawdopodobieÅ„stwo caÅ‚kowite) Niech  $(A_n)_{n\geq 1}$  bÄ™dzie nietrywialnym przeliczalnym rozbiciem  $\Omega$ . Dla kaÅ¼dego  $B\in\mathcal{F}$  zachodzi

$$\mathbb{P}(B) = \sum_{n=1}^{\infty} \mathbb{P}(B|A_n)\mathbb{P}(A_n).$$

(2.7) **TW.** (<u>WzÃ³r Bayesa</u>) Przy zaÅ‚oÅ¼eniach wzoru na prawdopodobieÅ„stwo caÅ‚kowite oraz jeÅ›li dodatkowo  $\mathbb{P}(B) > 0$ , to

$$\mathbb{P}(A_k|B) = \frac{\mathbb{P}(B|A_k)\mathbb{P}(A_k)}{\sum_{n=1}^{\infty} \mathbb{P}(B|A_n)\mathbb{P}(A_n)}.$$

- ZaÅ‚Ã³Å¼my, Å¼e przy badaniu narkomana test wypada pozytywnie w 99% przypadkÃ³w, zaÅ› przy badaniu osoby nie zaÅ¼ywajÄ…cej narkotykÃ³w wypada negatywnie w 99% przypadkÃ³w. Pewna firma postanowiÅ‚a przebadaÄ‡ swoich pracownikÃ³w takim testem, wiedzÄ…c, Å¼e 0.5% z nich to narkomani. Jakie jest prawdopodobieÅ„stwo, Å¼e osoba, u ktÃ³rej test wypadÅ‚ pozytywnie, rzeczywiÅ›cie zaÅ¼ywa narkotyki? ( $\approx 1/3$ )
- Paradoks Monty Halla, "IdÅº na caÅ‚oÅ›Ä‡". Zawodnik stoi przed trzema zasÅ‚oniÄ™tymi bramkami. Za jednÄ… z nich (za ktÃ³rÄ… wie to tylko prowadzÄ…cy program stary Hajzer) jest nagroda (umieszczana caÅ‚kowicie losowo), za pozostaÅ‚ymi kot ZONK. Gracz wybiera jednÄ… z bramek. ProwadzÄ…cy program odsÅ‚ania innÄ… bramkÄ™ (co istotne anonsujÄ…c, Å¼e jest to bramka pusta), po czym proponuje graczowi zmianÄ™ wyboru. Co powinien zrobiÄ‡ gracz?

#### <span id="page-5-0"></span>â–  Konstrukcja zbioru niemierzalnego

Stosunkowo trudno jest wskazaÄ‡ zbiÃ³r, ktÃ³ry nie jest borelowski (czyli nie naleÅ¼y do  $\mathcal{B}(\mathbb{R})$ ). PoniÅ¼ej skonstruujemy zbiÃ³r, ktÃ³ry nie tylko nie jest borelowski, co nie jest rÃ³wnieÅ¼ mierzalny w sensie miary Lebesgue'a. ZbiÃ³r ten jest zwany zbiorem Vitalli'ego. PokaÅ¼emy, Å¼e dla tego zbioru nie moÅ¼na zdefiniowaÄ‡ wartoÅ›ci  $\lambda(E)$ . Przypisanie jakiejkolwiek wartoÅ›ci  $\lambda(E)$  prowadzi do sprzecznoÅ›ci. Konstrukcja takich zbiorÃ³w jest bardzo delikatna i wymaga przyjÄ™cia tzw. aksjomatu wyboru. Bez tego aksjomatu nie jest moÅ¼liwe udowodnienie istnienia zbioru niemierzalnego wzglÄ™dem miary Lebesgue'a.

- Aksjomat wyboru: istnieje zbiÃ³r zawierajÄ…cy dokÅ‚adnie po jednym elemencie z kaÅ¼dego zbioru naleÅ¼Ä…cego do danej rodziny niepustych zbiorÃ³w rozÅ‚Ä…cznych. Aksjomat ten ma zastosowanie gdy rodzina zbiorÃ³w jest nieskoÅ„czona (dla skoÅ„czonych rodzin wÅ‚asnoÅ›Ä‡ ta wynika z innych aksjomatÃ³w). Aksjomat wyboru nie jest powszechnie przyjÄ™ty przez spoÅ‚ecznoÅ›Ä‡ matematykÃ³w. Przy aksjomacie wyboru Banach i Tarski udowodnili twierdzenie o paradoksalnym rozkÅ‚adzie kuli: kulÄ™ z trÃ³jwymiarowej przestrzeni euklidesowej moÅ¼na rozÅ‚oÅ¼yÄ‡ na szeÅ›Ä‡ czeÅ›ci, a nastÄ™pnie z tych czeÅ›ci moÅ¼na zÅ‚oÅ¼yÄ‡, korzystajac wyÅ‚Ä…cznie z
- Zdefiniujmy relacjÄ™  $\sim$  na  $\mathbb{R}^2$  w nastÄ™pujÄ…cy sposÃ³b:

$$x \sim y \iff x - y \in \mathbb{Q}.$$

obrotÃ³w i przesuniÄ™Ä‡, dwie kule identyczne jak kula wyjÅ›ciowa. Te szeÅ›Ä‡ czÄ™Å›ci jest wÅ‚aÅ›nie niemierzalne.

- Relacja ~ jest relacjÄ… rÃ³wnowaÅ¼noÅ›ci (zwrotna, symetryczna, przechodnia).
- Relacja rÃ³wnowaÅ¼noÅ›ci  $\sim$  dzieli  $\mathbb R$  na klasy abstrakcji: klasa abstrakcji elementu  $a \in \mathbb R$  jest

$$[a] = \{x \in \mathbb{R} : x \sim a\} = \{x \in \mathbb{R} : x - a \in \mathbb{Q}\}.$$

- Niech  $\mathcal{E} = \{[a]: a \in \mathbb{R}\}$  bÄ™dzie zbiorem takich klas abstrakcji. Jest ich nieprzeliczalnie wiele. KorzystajÄ…c z aksjomatu wyboru (delikatny punkt!) moÅ¼na skonstruowaÄ‡ zbiÃ³r E w nastÄ™pujÄ…cy sposÃ³b: do zbioru E wybieramy po jednym punkcie z kaÅ¼dej klasy abstrakcji, tzn. dla kaÅ¼dego  $x \in [0, 1]$  zbiÃ³r  $[x] \cap E$  jest jednopunktowy.
- JeÅ›li  $u, w \in \mathbb{Q}$  i  $u \neq w$ , to  $(E+u) \cap (E+w) = \emptyset$ . W przeciwnym wypadku istniaÅ‚by  $x \in (E+u) \cap (E+w)$ , tzn.  $x = e_1 + u = e_2 + w$ , gdzie  $e_1, e_2 \in E$ . Ale rÃ³wnoÅ›Ä‡  $e_1 = e_2 + (w-u)$  oznacza, Å¼e  $e_1 \sim e_2$ , co stoi w sprzecznoÅ›ci z definicjÄ… zbioru E. (e wynikiem dziaÅ‚ania E + x jest zbiÃ³r  $\{e + x : e \in E\}$ ).

- Niech ciÄ…g  $(q_i)_{i=1}^{\infty}$  bÄ™dzie ciÄ…giem wszystkich liczb wymiernych z odcinka [-1,1]. Wtedy  $[0,1] \subset \bigcup_{i=1}^{\infty} (E+q_i)$ . RzeczywiÅ›cie, niech  $x \in [0,1]$  oraz rozwaÅ¼my klasÄ™ abstrakcji [x]. Z definicji zbioru E mamy  $E \cap [x] = \{x_0\}$  dla pewnego  $x_0 \in [0,1] \cap E$ . Oznacza to, Å¼e  $x_0 x \in \mathbb{Q} \cap [-1,1]$ , czyli istnieje indeks i taki, Å¼e  $x_0 x = q_i$ , czyli  $x \in E + q_i$ .
- Niech  $\mu$  bÄ™dzie miarÄ… okreÅ›lonÄ… na pewnym  $\sigma$ -ciele  $\mathcal{F}$  z nastÄ™pujÄ…cymi wÅ‚asnoÅ›ciami: a) przesuwalnoÅ›Ä‡, tzn.  $\mu(A) = \mu(x+A)$  dla kaÅ¼dego  $x \in \mathbb{R}$   $(x+A=\{x+a\colon a\in A\})$  oraz b)  $\mu([a,b])=b-a$ . PrzykÅ‚adem takiej miary jest miara Lebesgue'a. DowÃ³d niemierzalnoÅ›ci zbioru E jest przeprowadzany nie wprost. Powiedzmy, Å¼e E jest mierzalny, czyli  $E \in \mathcal{F}$ . Prawdziwe jest zawieranie

$$[0,1] \subset \bigcup_{i=1}^{\infty} (E+q_i) \subset [-1,2]$$

oraz z wczeÅ›niejszych rozwaÅ¼aÅ„ wiemy, Å¼e zbiory  $(E+q_i)_{i=1}^\infty$ sÄ… rozÅ‚Ä…czne. Zatem

$$1 = \mu([0,1]) \le \sum_{k=1}^{\infty} \mu(E+q_i) \le \mu([-1,2]) = 3.$$

Ale z przesuwalnoÅ›ci,  $\mu(E+w_i)=\mu(E)$ , zatem pierwsza nierÃ³wnoÅ›Ä‡ wskazuje, Å¼e  $\mu(E)=\infty$ , podczas gdy druga daje  $\mu(E)=0$ . SprzecznoÅ›Ä‡.

â€¢ PowyÅ¼ej skonstruowaliÅ›my zbiÃ³r niemierzalny w sensie miary Lebesgue'a. OgÃ³lnie, przy zaÅ‚oÅ¼eniu hipotezy Continuum, jeÅ›li  $0 < \mu([0,1]) < \infty$  oraz  $\mu(\{x\}) = 0$  dla kaÅ¼dego  $x \in [0,1]$ , to istnieje zbiÃ³r niemierzalny wzglÄ™dem  $\mu$ . Innymi sÅ‚owy,  $\mu$  nie moÅ¼e byÄ‡ miarÄ… na  $(\Omega, \mathcal{F}) = ([0,1], 2^{[0,1]})$ .

#### 3. W3 - NiezaleÅ¼noÅ›Ä‡ i Lematy Borela-Cantellego

<span id="page-6-0"></span>(3.1)  $\blacksquare$  Niech  $(\Omega, \mathcal{F}, \mathbb{P})$  bÄ™dzie przestrzeniÄ… probabilistycznÄ…. Powiemy, Å¼e zdarzenia A i B sÄ… niezaleÅ¼ne, jeÅ›li

$$\mathbb{P}(A \cap B) = \mathbb{P}(A)\mathbb{P}(B).$$

- Rzucamy dwukrotnie monetÄ…. Niech  $A_i$  oznacza zdarzenie, Å¼e otrzymaliÅ›my orÅ‚a w i-tym rzucie, i=1,2. Zdarzenia  $A_1$  i  $A_2$  sÄ… niezaleÅ¼ne.
- Schemat geometryczny,  $\Omega = [-1,1]^2$ ,  $A = \{(x,y) \in \Omega \colon x > 0 \land y > 0\}$  oraz  $B = \{(x,y) \in \Omega \colon x^2 + y^2 \le 1/4\}$ . Zdarzenia A i B sÄ… niezaleÅ¼ne.
- (3.2) A Niech zdarzenia A i B bÄ™dÄ… niezaleÅ¼ne. PokazaÄ‡, Å¼e wtedy niezaleÅ¼ne sÄ… rÃ³wnieÅ¼ zdarzenia
  - $A i B^c$ ,
  - $A^c$  i B,
  - $A^c$  i  $B^c$ .
- (3.3)  $\blacksquare$  Zdarzenia A, B, C sÄ… niezaleÅ¼ne, jeÅ›li  $\mathbb{P}(A \cap B) = \mathbb{P}(A)\mathbb{P}(B)$ ,  $\mathbb{P}(A \cap C) = \mathbb{P}(A)\mathbb{P}(C)$ ,  $\mathbb{P}(B \cap C) = \mathbb{P}(B)\mathbb{P}(C)$  oraz  $\mathbb{P}(A \cap B \cap C) = \mathbb{P}(A)\mathbb{P}(B)\mathbb{P}(C)$ , przy czym nie wystarcza sprawdzaÄ‡ ostatniego lub pierwszych trzech warunkÃ³w. SprawdziÄ‡ zachodzenie powyÅ¼szych warunkÃ³w w dwÃ³ch poniÅ¼szych przykÅ‚adach:
  - Rzucamy dwa razy kostkÄ…. Zdefiniuj<br/>my zdarzenia A otrzymaliÅ›my dublet, B suma naleÅ¼y do  $\{7,8,9,10\}$ ,<br/> C suma naleÅ¼y do  $\{2,7,8\}$ .
  - Rzucamy czworoÅ›cianem foremnym, ktÃ³ry ma jednÄ… Å›cianÄ™ biaÅ‚Ä…, jednÄ… czerwonÄ…, jednÄ… zielonÄ… oraz jednÄ… w pasy biaÅ‚o-czerwono-zielone. Definiujemy zdarzenia A, B, C - wypadÅ‚a Å›cianka z kolorem, odpowiednio, zielonym, biaÅ‚ym, czerwonym.
- (3.4)  $\blacksquare$  Niech  $A_1, \ldots, A_n \in \mathcal{F}, n \geq 2$ . Powiemy, Å¼e zdarzenia  $A_1, \ldots, A_n$  sÄ… niezaleÅ¼ne, jeÅ›li

$$\forall k \in \{2, \dots, n\} \quad \forall \{i_1, \dots, i_k\} \subset \{1, \dots, n\} \quad \mathbb{P}(A_{i_1} \cap \dots \cap A_{i_k}) = \mathbb{P}(A_{i_1}) \dots \mathbb{P}(A_{i_k}).$$

- (3.5)  $\ \ \,$  Oznaczmy  $A^{(1)}=A$  oraz  $A^{(-1)}=A^c$ . UzasadniÄ‡, Å¼e jeÅ›li  $A_1,\ldots,A_n$  sÄ… niezaleÅ¼ne, to dla kaÅ¼dego  $\underline{\varepsilon}=(\varepsilon_1,\ldots,\varepsilon_n)\in\{-1,1\}^n$ , niezaleÅ¼ne sÄ… rÃ³wnieÅ¼  $A_1^{(\varepsilon_1)},\ldots,A_n^{(\varepsilon_n)}$ .
- (3.6)  $\bullet$  (Schemat Bernoulliego) Wykonujemy n niezaleÅ¼nych prÃ³b pewnego eksperymentu, przy czym p-stwo sukcesu w kaÅ¼dej z prÃ³b jest takie samo i wynosi  $p \in (0,1)$ .

Niech  $B_k$  oznacza zdarzenie, Å¼e uzyskano dokÅ‚adnie k sukcesÃ³w, k = 0, ..., n, oraz niech  $A_i$  oznacza, Å¼e uzyskano sukces w i-tej prÃ³bie, i = 1, ..., n. Wtedy

$$\mathbb{P}(B_k) = \sum_{\varepsilon \in \{-1,1\}^n \colon \#\{j \colon \varepsilon_i = 1\} = k} \mathbb{P}(A_1^{(\varepsilon_1)} \cap \ldots \cap A_n^{(\varepsilon_n)}) = \binom{n}{k} p^k (1-p)^{n-k}.$$

Niech  $C_k^r$  oznacza zdarzenie, Å¼e r-ty sukces bÄ™dzie poprzedzony k poraÅ¼kami,  $r \in \mathbb{N}, k \in \mathbb{N} \cup \{0\}$ . Wtedy

$$\mathbb{P}(C_k^r) = \sum_{\underline{\varepsilon} \in \{-1,1\}^{r+k-1} \colon \#\{j \colon \varepsilon_j = 1\} = r-1} \mathbb{P}(A_1^{(\varepsilon_1)} \cap \ldots \cap A_{r+k-1}^{(\varepsilon_{r+k-1})} \cap A_{r+k}) = \binom{r+k-1}{k} p^r (1-p)^k.$$

(3.7) Niech  $(A_n)_{n\geq 1}$  bÄ™dzie ciÄ…giem zbiorÃ³w. Wtedy

$$\liminf_{n \to \infty} A_n = \bigcup_{n=1}^{\infty} \bigcap_{m=n}^{\infty} A_m$$

oraz

$$\limsup_{n \to \infty} A_n = \bigcap_{m=1}^{\infty} \bigcup_{m=n}^{\infty} A_m.$$

**A** JeÅ›li  $A_n \in \mathcal{F}$  dla  $n \in \mathbb{N}$ , to  $\liminf_{n \to \infty} A_n \in \mathcal{F}$  oraz  $\limsup_{n \to \infty} A_n \in \mathcal{F}$ .

igotimes W skrÃ³cie bÄ™dziemy czasem pisali  $\liminf_n$  i  $\limsup_n$ .

**A** Z praw de Morgana mamy

$$(\liminf_n A_n)^c = \limsup_n A_n^c$$
 oraz  $(\limsup_n A_n)^c = \liminf_n A_n^c$ .

**A** Niech  $\mathbb{1}_A$  bÄ™dzie funkcjÄ… indykatorowÄ… zbioru A, tzn,  $\mathbb{1}_A(\omega) := \begin{cases} 1, & \omega \in A, \\ 0, & \omega \notin A. \end{cases}$ . Wtedy

$$\limsup_{n\to\infty}A_n=\left\{\omega\in\Omega\colon \sum_{n=1}^\infty\mathbbm{1}_{A_n}(\omega)=\infty\right\},\qquad \liminf_{n\to\infty}A_n=\left\{\omega\in\Omega\colon \sum_{n=1}^\infty\mathbbm{1}_{A_n^c}(\omega)<\infty\right\}.$$

Innymi sÅ‚owy,  $\limsup_{n\to\infty}A_n$  oznacza zdarzenie, Å¼e zaszÅ‚o nieskoÅ„czenie wiele zdarzeÅ„ spoÅ›rÃ³d  $(A_n)_n$ . Z kolei  $\liminf_{n\to\infty}A_n$  oznacza, Å¼e zaszÅ‚o skoÅ„czenie wiele zdarzeÅ„ spoÅ›rÃ³d  $(A_n^c)_n$  (czyli w szczegÃ³lnoÅ›ci zaszÅ‚o nieskoÅ„czenie wiele zdarzeÅ„  $(A_n)_n$ ).

 $\triangle$   $\liminf_{n\to\infty} A_n \subset \limsup_{n\to\infty} A_n$ .

(3.8) **TW.** (I Lemat Borela-Cantellego) Niech  $(A_n)_{n\geq 1}$  bÄ™dzie ciÄ…giem zdarzeÅ„. JeÅ›li

$$\sum_{n=1}^{\infty} \mathbb{P}(A_n) < \infty,$$

to  $\mathbb{P}(\limsup_{n} A_n) = 0$ .

- Szkic dowodu:  $\mathbb{P}(\limsup_n A_n) \leq \mathbb{P}(\bigcup_{m=n}^{\infty} A_m) \leq \sum_{m=n}^{\infty} \mathbb{P}(A_m) \xrightarrow{n \to \infty} 0.$  (3.9)  $\blacksquare$  Powiemy, Å¼e  $(A_n)_{n \geq 1}$  jest (nieskoÅ„czonym) ciÄ…giem zdarzeÅ„ niezaleÅ¼nych, jeÅ›li dla kaÅ¼dego  $k \geq 2$  zdarzenia  $A_1, \ldots, A_k$  sÄ… niezaleÅ¼ne.
  - $\P$  UzasadniÄ‡, Å¼e jeÅ›li zdarzenia  $(A_n)_{n\geq 1}$  sÄ… niezaleÅ¼ne, to  $\mathbb{P}(\cap_{n\geq 1}A_n)=\prod_{n=1}^{\infty}\mathbb{P}(A_n)$ .
- (3.10) **TW.** (II Lemat Borela-Cantellego) Niech  $(A_n)_{n\geq 1}$  bÄ™dzie ciÄ…giem zdarzeÅ„ niezaleÅ¼nych. JeÅ›li

$$\sum_{n=1}^{\infty} \mathbb{P}(A_n) = \infty,$$

to  $\mathbb{P}(\limsup_{n} A_n) = 1$ .

Szkic dowodu: Dla kaÅ¼dego  $n \in \mathbb{N}$  zachodzi

$$\mathbb{P}\left(\bigcap_{k=n}^{\infty}A_{k}^{c}\right)\leq \mathbb{P}\left(\bigcap_{k=n}^{n+m}A_{k}^{c}\right)=\prod_{k=n}^{n+m}(1-\mathbb{P}(A_{k}))\leq \prod_{k=n}^{n+m}e^{-\mathbb{P}(A_{k})}=e^{-\sum_{k=n}^{n+m}\mathbb{P}(A_{k})}\overset{m\to\infty}{\longrightarrow}0.$$

[PowyÅ¼ej skorzystaliÅ›my z nierÃ³wnoÅ›ci  $1-x \le e^{-x}$  dla  $x \ge 0$ .] Zatem,

$$0 \le 1 - \mathbb{P}\left(\limsup_{n \to \infty} A_n\right) = \mathbb{P}\left(\bigcup_{n=1}^{\infty} \bigcap_{k=n}^{\infty} A_k^c\right) \le \sum_{n=1}^{\infty} \mathbb{P}\left(\bigcap_{k=n}^{\infty} A_k^c\right) = 0.$$

- (3.11)  $\triangle$  Wniosek z LematÃ³w Borela-Cantellego: JeÅ›li  $(A_n)_{n\geq 1}$  jest ciÄ…giem zdarzeÅ„ niezaleÅ¼nych, to zdarzenie lim sup<sub>n</sub>  $A_n$ zachodzi z prawdopodobieÅ„stwem 0 lub 1.
  - **A** SkonstruowaÄ‡ przykÅ‚ad zdarzeÅ„  $(A_n)_{n\geq 1}$  dla ktÃ³rego zachodzi  $\mathbb{P}(\limsup_n A_n)=3/4$ .

- (3.12) ğŸ—± ZaÅ‚Ã³Å¼my, Å¼e maÅ‚pa Å¼yje nieskoÅ„czenie dÅ‚ugo i posadÅºmy jÄ… przed klawiaturÄ… komputera. MaÅ‚pa w sposÃ³b losowy uderza w klawisze. Po nieskoÅ„czonym czasie uzyskamy w ten sposÃ³b nieskoÅ„czony ciÄ…g znakÃ³w. Jakie jest prawdopodobieÅ„stwo, Å¼e, poczynajÄ…c od pewnego miejsca, maÅ‚pa wiernie odtworzyÅ‚a Pana Tadeusza? Jakie jest prawdopodobieÅ„stwo, Å¼e maÅ‚pa napisaÅ‚a go nieskoÅ„czenie wiele razy? Przyjmij, Å¼e klawiatura ma 101 klawiszy, Pan Tadeusz skÅ‚ada siÄ™ z 68682 wyrazÃ³w oraz Å›rednia liczba znakÃ³w w sÅ‚owie (w jÄ™zyku polskim) to 7.21. https://en.wikipedia.org/wiki/Infinite\_monkey\_theorem
  - 4. W4 Zmienne Losowe, rozkÅ‚ady i dystrybuanty
- <span id="page-8-0"></span>(4.1) FunkcjÄ™  $X: \Omega \to \mathbb{R}$  nazywamy zmiennÄ… losowÄ… (na przestrzeni mierzalnej  $(\Omega, \mathcal{F})$ ), jeÅ›li jest ona  $\mathcal{F}$ -mierzalna, tzn.

$$\forall B \in \mathcal{B}(\mathbb{R}) \quad X^{-1}(B) := \{ \omega \in \Omega \colon X(\omega) \in B \} \in \mathcal{F}.$$

- $\blacksquare$  ZbiÃ³r  $X^{-1}(B)$  nazywamy przeciwobrazem zbioru B przy przeksztaÅ‚ceniu X.
- â†‘ Udowodnij nastÄ™pujÄ…ce wÅ‚asnoÅ›ci przeciwobrazu:

  - $f^{-1}(\bigcap_{i} B_{i}) = \bigcap_{i} f^{-1}(B_{i}),$   $f^{-1}(\bigcup_{i} B_{i}) = \bigcup_{i} f^{-1}(B_{i}),$   $f^{-1}(A^{c}) = (f^{-1}(A))^{c}.$
- (4.2)  $\mathbf{x}^{\mathbf{z}}$  JeÅ›li  $A \in \mathcal{F}$ , to funkcja  $X : \Omega \to \mathbb{R}$  zdefiniowana przez

$$X(\omega) = \mathbb{1}_A(\omega) = \begin{cases} 1, & \omega \in A, \\ 0, & \omega \notin A, \end{cases}$$

jest zmienna losowa.

- (4.3)  $\blacktriangleleft$  Funkcja  $X: \Omega \to \mathbb{R}$  jest  $\mathcal{F}_0$ -mierzalna, gdzie  $\mathcal{F}_0 = \{\emptyset, \Omega\}$ . PokazaÄ‡, Å¼e X jest funkcjÄ… staÅ‚Ä….
- (4.4)  $\blacksquare$  RodzinÄ™  $\Pi$  podzbiorÃ³w zbioru T nazywamy  $\pi$ -ukÅ‚adem, jeÅ›li speÅ‚nione sÄ… dwa warunki
  - (a)  $T \in \Pi$ ,
  - (b)  $A, B \in \Pi \implies A \cap B \in \Pi$ .
  - $\blacksquare$  RodzinÄ™  $\Lambda$  podzbiorÃ³w zbioru T nazywamy  $\lambda$ -ukÅ‚adem, jeÅ›li speÅ‚nione sÄ… trzy warunki
  - (a)  $T \in \Lambda$ .
  - (b)  $A, B \in \Lambda$  oraz  $A \subset B \implies B \setminus A \in \Lambda$ ,
  - (c)  $A_n \in \Lambda$  oraz  $A_n \subset A_{n+1}, n = 1, 2, ... \implies \bigcup_{n=1}^{\infty} A_n \in \Lambda$ .
  - **TW.** (Lemat o  $\pi \lambda$  ukÅ‚adach) JeÅ›li  $\Pi$  jest  $\pi$ -ukÅ‚adem,  $\Lambda$  jest  $\lambda$ -ukÅ‚adem oraz  $\Pi \subset \Lambda$ , to  $\sigma(\Pi) \subset \Lambda$ .
- (4.5) **TW.** NastÄ™pujÄ…ce warunki sÄ… rÃ³wnowaÅ¼ne:
  - (a) X jest zmiennÄ… losowÄ…,
  - (b)  $\forall t \in \mathbb{R} \quad X^{-1}((-\infty, t]) \in \mathcal{F},$
  - (c)  $\forall t \in \mathbb{R} \quad X^{-1}((-\infty, t)) \in \mathcal{F}.$

Szkic dowodu: z (a) do (c) Å‚atwe. Z (c) do (b) naleÅ¼y zauwaÅ¼yÄ‡, Å¼e  $(-\infty,t] = \bigcap_{\varepsilon \in \mathbb{O} \cap (0,\infty)} (-\infty,t+\varepsilon)$  oraz skorzystaÄ‡ z wÅ‚asnoÅ›ci przeciwobrazu.

DowÃ³d (b)  $\Longrightarrow$  (a) to typowe zastosowanie Lematu o  $\pi - \lambda$  ukÅ‚adach: Niech  $\Pi = \{(-\infty, x]: x \in \mathbb{R}\} \cup \mathbb{R}$  oraz  $\Lambda = \{B \in \mathcal{B}(\mathbb{R}) \colon X^{-1}(B) \in \mathcal{F}\}$ . JeÅ›li  $\Lambda = \mathcal{B}(\mathbb{R})$ , to X jest zmiennÄ… losowÄ…. ZakÅ‚adajÄ…c (b) wiemy z kolei, Å¼e  $\Pi \subset \Lambda$ . Rodzina  $\Pi$  jest  $\pi$ -ukÅ‚adem podzbiorÃ³w  $\mathbb{R}$  (oczywiste) oraz  $\Lambda \subset \mathcal{B}(\mathbb{R})$  jest  $\lambda$ -ukÅ‚adem (wynika to szybko z wÅ‚asnoÅ›ci przeciwobrazu). Zatem z Lematu o  $\pi - \lambda$  ukÅ‚adach mamy, Å¼e  $\sigma(\Pi) = \mathcal{B}(\mathbb{R}) \subset \Lambda \subset \mathcal{B}(\mathbb{R})$ , czyli  $\Lambda = \mathcal{B}(\mathbb{R})$ , co jest rÃ³wnowaÅ¼ne (a).

**A** JeÅ›li X jest zmiennÄ… losowÄ…, to  $X^{-1}(\{t\}) = \{\omega \in \Omega \colon X(\omega) = t\} \in \mathcal{F}$ , ale w ogÃ³lnoÅ›ci ten warunek nie implikuje, Å¼e X jest zmiennÄ… losowÄ…. â™  A kiedy wystarcza?

- (4.6) ğŸ—± Rzucamy dwukrotnie monetÄ…. Niech X bÄ™dzie liczbÄ… otrzymanych orÅ‚Ã³w. PokazaÄ‡, Å¼e X jest zmiennÄ… losowÄ….
- (4.7) Napis  $\{X \in B\}$  jest skrÃ³tem  $\{\omega \in \Omega \colon X(\omega) \in B\}$ . BÄ™dziemy rÃ³wnieÅ¼ pisali  $\mathbb{P}(X \in B)$  zamiast  $\mathbb{P}(\{X \in B\})$ .
- (4.8)  $\blacksquare$  Powiemy, Å¼e funkcja  $f: \mathbb{R} \to \mathbb{R}$  jest borelowska, jeÅ›li jest  $\mathcal{B}(\mathbb{R})$ -mierzalna, tzn.

$$\forall B \in \mathcal{B}(\mathbb{R}) \quad f^{-1}(B) \in \mathcal{B}(\mathbb{R}).$$

A Przeciwobrazy zbiorÃ³w otwartych przy przeksztaÅ‚ceniu ciÄ…gÅ‚ym sÄ… otwarte, co oznacza, Å¼e wszystkie funkcje ciÄ…gÅ‚e sÄ… borelowskie. Funkcje kawaÅ‚kami ciÄ…gÅ‚e rÃ³wnieÅ¼ sÄ… borelowskie.

- (4.9) **TW.** JeÅ›li  $X_1, \ldots, X_n$  sÄ… zmiennymi losowymi, to  $X_1 + \ldots + X_n$  jest zmiennÄ… losowÄ…. Szkic dowodu: NaleÅ¼y zauwaÅ¼yÄ‡, Å¼e  $\{X+Y< t\} = \bigcup_{q\in\mathbb{Q}} \{X< q\} \cap \{q< t-Y\}.$
- (4.10) **TW.** JeÅ›li  $X: \Omega \to \mathbb{R}$  jest zmiennÄ… losowÄ…, a  $f: \mathbb{R} \to \mathbb{R}$  jest funkcjÄ… borelowskÄ…, to  $Y(\omega) := f(X(\omega))$  jest zmiennÄ… losowa.

(4.11)  $\blacksquare$  RozkÅ‚adem prawdopodobieÅ„stwa zmiennej losowej X nazywamy funkcjÄ™  $\mathbb{P}_X$  na  $\mathcal{B}(\mathbb{R})$  zadanÄ… przez

$$\mathbb{P}_X(B) = \mathbb{P}(X^{-1}(B)) = \mathbb{P}\left(\{\omega \in \Omega \colon X(\omega) \in B\}\right) = \mathbb{P}(X \in B), \qquad B \in \mathcal{B}(\mathbb{R}).$$

- (4.12)  $\mbox{\ensuremath{\mbox{$\alpha$}}}$  Funkcja  $\mathbb{P}_X$  jest prawdopodobieÅ„stwem na  $(\mathbb{R},\mathcal{B}(\mathbb{R}))$ . Zatem  $(\mathbb{R},\mathcal{B}(\mathbb{R}),\mathbb{P}_X)$  jest przestrzeniÄ… probabilistycznÄ….
- (4.13)  $\blacksquare$  Niech X bÄ™dzie zmiennÄ… losowÄ…. FunkcjÄ™  $F_X : \mathbb{R} \to \mathbb{R}$  okreÅ›lonÄ… wzorem

$$F_X(t) = \mathbb{P}_X((-\infty, t]) = \mathbb{P}(X \le t), \qquad t \in \mathbb{R}$$

nazywamy dystrybuantÄ… zmiennej losowej X.

- (4.14) **TW.** (WÅ‚asnoÅ›ci dystrybuanty)
  - (a)  $F_X$  jest niemalejÄ…ca,
  - (b)  $F_X$  jest prawostronnie ciÄ…gÅ‚a, tzn.  $F_X(t+) := \lim_{\varepsilon \to 0+} F_X(t+\varepsilon) = F_X(t)$ ,
  - (c)  $\lim_{t\to-\infty} F_X(t) = 0$  oraz  $\lim_{t\to\infty} F_X(t) = 1$ .

Szkic dowodu: (b) Niech  $\varepsilon_n \downarrow 0$ . Wtedy z ciÄ…gÅ‚oÅ›ci z gÃ³ry prawdopodobieÅ„stwa  $\mathbb{P}_X$  mamy  $\lim_{n\to\infty} F_X(t+\varepsilon_n) = \lim_{n\to\infty} \mathbb{P}_X((-\infty,t+\varepsilon_n]) = \mathbb{P}_X\left(\bigcap_{n=1}^{\infty}(-\infty,t+\varepsilon_n]\right) = F_X(t)$ . Punkt (c) rÃ³wnieÅ¼ dowodzimy z ciÄ…gÅ‚oÅ›ci prawdopodobieÅ„stwa.

(4.15) **TW.** JeÅ›li funkcja  $F: \mathbb{R} \to \mathbb{R}$  speÅ‚nia warunki (a), (b), (c) powyÅ¼ej, to istnieje zmienna losowa X (np. okreÅ›lona na  $(\Omega, \mathcal{F}, \mathbb{P}) = ((0,1), \mathcal{B}((0,1)), \lambda_1))$ , ktÃ³rej F jest dystrybuantÄ…, tzn.  $F = F_X$ . RozwaÅ¼yÄ‡  $X(\omega) := \sup\{t \in \mathbb{R}: F(t) < \omega\}$  (jeÅ›li F ma funkcjÄ™ odwrotnÄ… na (0,1), to  $X(\omega) = F^{-1}(\omega)$ ). Szkic dowodu: NaleÅ¼y zauwaÅ¼yÄ‡, Å¼e

$$X(\omega) > t$$
 wtedy i tylko wtedy, gdy  $F(t) < \omega$ 

dla dowolnych  $t \in \mathbb{R}$  i  $\omega \in (0,1)$ . Dalej, dla dowolnego  $t \in \mathbb{R}$  mamy

$$F_X(t) = \mathbb{P}(X \le t) = 1 - \mathbb{P}(X > t) = 1 - \mathbb{P}(\{\omega \in \Omega : X(\omega) > t\})$$
  
= 1 - \mathbb{P}(\{\omega \in \Omega : F(t) < \omega\}) = 1 - \mathbb{P}((F(t), 1)) = 1 - (1 - F(t)) = F(t).

- (4.16) **TW.** Dystrybuanta  $F_X$  zmiennej losowej X wyznacza rozkÅ‚ad prawdopodobieÅ„stwa  $\mathbb{P}_X$  jednoznacznie, tzn. jeÅ›li  $F_X = F_Y$ , to  $\mathbb{P}_X = \mathbb{P}_Y$ .
- (4.17)  $\blacksquare$  Powiemy, Å¼e zmienne losowe X i Y majÄ… ten sam rozkÅ‚ad ( $\textcircled{\bullet} X \stackrel{d}{=} Y$ ), jeÅ›li  $\mathbb{P}_X = \mathbb{P}_Y$ .

**LEM.**  $X \stackrel{d}{=} Y$  wtedy i tylko wtedy, gdy  $F_X = F_Y$ .

lack A JeÅ›li X=Y, to  $X\stackrel{d}{=}Y$ , ale odwrotna implikacja w ogÃ³lnoÅ›ci nie jest prawdziwa.

(4.18)

$$\mathbb{P}(X \in D) = 1.$$

RÃ³wnowaÅ¼nie, noÅ›nik jest zbiorem punktÃ³w wzrostu dystrybuanty zmiennej losowej X, tzn.

$$\operatorname{supp}(X) = \{ t \in \mathbb{R} : \forall \varepsilon > 0 \ F_X(t - \varepsilon) < F_X(t + \varepsilon) \}.$$

- (4.19) Typy rozkÅ‚adow:
  - (a) CiÄ…g par  $(x_i, p_i)_i$  nazywamy dyskretnym rozkÅ‚adem prawdopodobnieÅ„stwa, jeÅ›li  $\sum_i p_i = 1, p_i > 0$  oraz  $x_i \neq x_j$ , gdy  $i \neq j$ .

 $\blacksquare$  Zmienna losowa X jest typu dyskretnego jeÅ›li istnieje ciÄ…g  $(x_i)_i$  taki, Å¼e  $(x_i, \mathbb{P}(X = x_i))_i$  jest dyskretnym rozkÅ‚adem prawdopodobnieÅ„stwa. Wtedy

$$\mathbb{P}_X(B) = \mathbb{P}(X \in B) = \sum_{i: x_i \in B} \mathbb{P}(X = x_i) \quad \text{oraz} \quad F_X(t) = \sum_{i: x_i \le t} \mathbb{P}(X = x_i).$$

Innymi sÅ‚owy,  $F_X$  jest funkcjÄ… schodkowÄ… o skokach w punktach  $x_i$  o wysokoÅ›ci  $\mathbb{P}(X=x_i)$ .

**A** supp $(X) := \{x_i : i = 1, 2, \ldots\}.$ 

(b) Zmienna losowa X ma rozkÅ‚ad <u>typu absolutnie ciÄ…gÅ‚ego</u> (wzglÄ™dem miary Lebesgue'a), jeÅ›li istnieje funkcja borelowska  $f_X$  taka, Å¼e

$$\forall B \in \mathcal{B}(\mathbb{R}) \quad \mathbb{P}_X(B) = \int_B f_X(x) dx.$$

â–² Po prawej mamy caÅ‚kÄ™ wzglÄ™dem miary Lebesgue'a, patrz kolejny temat.

Wtedy  $F_X(t) = \int_{(-\infty,t]} f_X(x) dx$  oraz  $F_X$  jest ciÄ…gÅ‚a,  $F_X' = f_X$  prawie wszÄ™dzie, tzn.  $\lambda(\{t \in \mathbb{R} : F_X'(t) \neq f_X(t)\}) = 0$ .

â— "Prawie wszÄ™dzie", to takie "prawie na pewno", tylko Å¼e wzglÄ™dem miary Lebesgue'a.

 $\blacksquare$ FunkcjÄ™  $f_X$ nazywamy gÄ™stoÅ›ciÄ… zmiennej losowej X.

LEM. WÅ‚asnoÅ›ci gestoÅ›ci:

- (i)  $f_X \ge 0$  prawie wszÄ™dzie, tzn.  $\lambda(\{t \in \mathbb{R}: f_X(t) < 0\}) = 0$ ,
- (ii)  $\int_{\mathbb{R}} f_X(t)dt = 1$  (caÅ‚ka wzglÄ™dem miary Lebesgue'a),
- (iii)  $f_X$  jest wyznaczona jednoznacznie z dokÅ‚adnoÅ›ciÄ… do zbiorÃ³w miary Lebesgue 0, tzn. jeÅ›li  $f_1, f_2$  gÄ™stoÅ›ci X, to  $\lambda(\{t \in \mathbb{R} : f_1(t) \neq f_2(t)\}) = 0$ .

 $\mathbf{A} \operatorname{supp}(X) := \overline{\operatorname{Int}\{t \in \mathbb{R} \colon f_X(t) > 0\}}.$ 

- (c) X ma rozkÅ‚ad singularny, jeÅ›li  $F_X$  jest ciÄ…gÅ‚a oraz  $F_X'(t) = 0$  dla prawie wszystkich  $t \in \mathbb{R}$ . PrzykÅ‚ady: funkcja Cantora, https://en.wikipedia.org/wiki/Cantor\_function, znak zapytania Minkowskiego, ?(x), https://en.wikipedia.org/wiki/Minkowski%27s\_question-mark\_function.
- (d) RozkÅ‚ady mieszane: rozkÅ‚ady o dystrybuancie

$$F = \alpha_1 F_d + \alpha_2 F_{ac} + \alpha_3 F_s$$

gdzie  $\alpha_i \geq 0$  oraz  $\alpha_1 + \alpha_2 + \alpha_3 = 1$  oraz  $F_d$  - dystrybuanta rozkÅ‚adu dyskretnego,  $F_{ac}$  - dystrybuanta rozkÅ‚adu absolutnie ciÄ…gÅ‚ego,  $F_s$  - dystrybuanta rozkÅ‚adu singularnego. Dowolna dystrybuanta ma takÄ… (jednoznacznÄ…) reprezentacjÄ™. Jest to Twierdzenie Lebesgue'a o rozkÅ‚adzie.

#### <span id="page-10-0"></span>CAÅKA WZGLEDEM MIARY

- Niech  $(\Omega, \mathcal{F})$  bÄ™dzie przestrzeniÄ… mierzalnÄ… oraz niech  $\mu$  bÄ™dzie miarÄ… skoÅ„czonÄ… na  $\mathcal{F}$  (czyli zakÅ‚adamy, Å¼e  $\mu(\Omega) < \infty, \, \mu(\cdot) \geq 0$  oraz przeliczalnÄ… addytywnoÅ›Ä‡ na sumach rozÅ‚Ä…cznych zbiorÃ³w z  $\mathcal{F}$ ). Funkcje  $\mathcal{F}$ -mierzalne bÄ™dziemy skrÃ³towo nazywaÄ‡ mierzalnymi.
- Konstrukcja caÅ‚ki wzglÄ™dem miary opiera siÄ™ o bardzo typowe (w teorii miary) podejÅ›cie zwane komplikacjÄ…. BÄ™dziemy rozwaÅ¼ali caÅ‚ki z coraz bardziej skomplikowanych funkcji.

MajÄ…c juÅ¼ jakieÅ› doÅ›wiadczenia z caÅ‚kÄ… Riemanna, wiemy jakie sÄ… poÅ¼Ä…dane wÅ‚asnoÅ›ci caÅ‚ek (np. liniowoÅ›Ä‡, czyli  $\int (\alpha f + \beta g) = \alpha \int f + \beta \int g$ ). Po zapostulowaniu takich wÅ‚asnoÅ›ci, definicja caÅ‚ki z ogÃ³lnej funkcji opiera siÄ™ na definicji caÅ‚ki z funkcji najprostszych, czyli indykatorach. Dla  $A \in \mathcal{F}$  definiujemy

$$\int_{\Omega} \mathbb{1}_{A}(\omega)\mu(d\omega) := \mu(A).$$

RÃ³wnowaÅ¼nym oznaczeniem na tÄ™ caÅ‚kÄ™ jest  $\int_\Omega \mathbbm{1}_A d\mu$ 

â€¢ FunkcjÄ™  $X \colon \Omega \to \mathbb{R}$  nazywamy prostÄ…, jeÅ›li przyjmuje skoÅ„czonie wiele wartoÅ›ci, tzn. moÅ¼na jÄ… zapisaÄ‡ w postaci

$$X(\omega) = \sum_{k=1}^{n} x_k \mathbb{1}_{A_k}(\omega), \qquad \omega \in \Omega.$$

Bez straty ogÃ³lnoÅ›ci moÅ¼emy zaÅ‚oÅ¼yÄ‡, Å¼e  $x_k \neq x_i$  dla  $k \neq i$ .

- $\blacktriangleleft$  Tak zdefiniowana funkcja jest mierzalna wtedy i tylko wtedy, gdy  $A_k \in \mathcal{F}, k = 1, \ldots, n$ .
- CaÅ‚kÄ™ wzglÄ™dem miary  $\mu$  funkcji prostej X definiujemy nastÄ™pujÄ…co: (rÃ³wnowaÅ¼nie mogliÅ›my zapostulowaÄ‡ skoÅ„czonÄ… addytywnoÅ›Ä‡ caÅ‚ki)

$$\int_{\Omega} X d\mu = \sum_{k=1}^{n} x_k \mu(A_k).$$

Å»eby podkreÅ›liÄ‡ zmiennÄ… wzglÄ™dem ktÃ³rej caÅ‚kujemy, bÄ™dziemy tÄ™ calkÄ™ oznaczali przez  $\int_{\Omega} X(\omega)\mu(d\omega)$ .

â€¢  $\P$  Kluczowy fakt dla konstrukcji caÅ‚ki z ogÃ³lnej funkcji X: JeÅ›li  $X: \Omega \to [0, \infty)$  oraz X jest mierzalna, to istnieje ciÄ…g mierzalnych funkcji prostych  $(Z_n)_{n\geq 1}$  taki, Å¼e  $Z_n(\omega) \uparrow X(\omega)$ , gdy  $n\to\infty$  dla wszystkich  $\omega\in\Omega$ . Taki ciÄ…g nazywamy ciÄ…giem podpierajÄ…cym X. Åatwo jest go skonstruowaÄ‡: niech np.

$$Z_n(\omega) = \sum_{k=1}^{n2^n} \frac{k-1}{2^n} \mathbb{1}_{\left[\frac{k-1}{2^n}, \frac{k}{2^n}\right)}(X(\omega)) + n \mathbb{1}_{[n,\infty)}(X(\omega)).$$

KaÅ¼dy  $Z_n$  jest mierzalny z mierzalnoÅ›ci X ( ). Z konstrukcji widaÄ‡, Å¼e dla kaÅ¼dej  $\omega$ , ciÄ…g  $(Z_n(\omega))_n$  jest niemalejÄ…cy. Ponadto, dla ustalonej  $\omega \in \Omega$  oraz n takich, Å¼e  $n > X(\omega)$  zachodzi

$$0 \le Z_n(\omega) - X(\omega) \le \frac{1}{2^n},$$

co daje zbieÅ¼nosÄ‡ punktowa.

 $\bullet$  CaÅ‚kÄ™ z dowolnej nieujemnej funkcji mierzalnej X definiujemy jako granicÄ™

$$\int_{\Omega} X d\mu = \lim_{n \to \infty} \int_{\Omega} Z_n d\mu,$$

gdzie ciÄ…g  $Z_n$  jest dowolnym ciÄ…giem funkcji prostych podpierajÄ…cym X.

â€¢ Na pierwszy rzut oka nie widaÄ‡, Å¼e definicja ta jest dobra, bo potencjalnie granica moÅ¼e zaleÅ¼eÄ‡ od wyboru ciÄ…gu funkcji prostych  $(Z_n)_{n\geq 1}$ . Å»eby pokazaÄ‡, Å¼e to nie problem rozwaÅ¼my dwa ciÄ…gi podpierajÄ…ce,  $(Z_n^{(1)})_{n\geq 1}$ oraz  $(Z_n^{(2)})_{n\geq 1}$  oraz zauwaÅ¼my, Å¼e  $Z_n^{(1)}(\omega)\uparrow X(\omega)\geq Z_k^{(2)}(\omega)$  dla  $\omega\in\Omega$ . Wynika stÄ…d, Å¼e wtedy dla kaÅ¼dego

$$\lim_{n\to\infty} \int_{\Omega} Z_n^{(1)} d\mu \ge \int_{\Omega} Z_k^{(2)} d\mu$$

co po wziÄ™ciu granicy  $k \to \infty$  daje nierÃ³wnoÅ›Ä‡ pomiÄ™dzy granicami. NierÃ³wnoÅ›Ä‡ w drugÄ… stronÄ™ otrzymujemy tak samo.

- Druga istotnÄ… kwestiÄ… jest tutaj pytanie czy granica w definicji w ogÃ³le istnieje. Jej istnienie wynika z faktu, Å¼e jeÅ›li X i Y sÄ… funkcjami prostymi oraz  $0 \le X(\omega) \le Y(\omega)$ , to  $\int_{\Omega} X d\mu \le \int_{\Omega} Y d\mu$  co z kolei Å‚atwo widaÄ‡ z definicji caÅ‚ki dla funkcji prostych (  $\clubsuit$  ). StÄ…d, ciÄ…g liczbowy  $(\int_{\Omega} Z_n d\mu)_{n \ge 1}$  jest niemalejÄ…cy, a zatem ma granicÄ™ ( byÄ‡ moÅ¼e nieskoÅ„czonÄ…).
- CaÅ‚kÄ™ wzglÄ™dem miary z nieujemnych funkcji mierzalnych moÅ¼na rÃ³wnowaÅ¼nie zdefiniowaÄ‡ poprzez

$$\int_{\Omega} X d\mu := \sup \left\{ \int_{\Omega} Y d\mu \colon Y \le X \text{ oraz } Y \text{ prosta} \right\}.$$

â€¢ JeÅ›li  $X: \Omega \to \mathbb{R}$ , to moÅ¼na jÄ… rozÅ‚oÅ¼yÄ‡ na rÃ³Å¼nicÄ™ jej czÄ™Å›ci dodatniej i ujemnej:

$$X(\omega) = X^{+}(\omega) - X^{-}(\omega) := \max\{X(\omega), 0\} - \max\{-X(\omega), 0\}$$

- $\blacktriangle X^-$  jest nieujemne.
- JeÅ›li X jest funkcjÄ… mierzalnÄ…, to  $X^+$  i  $X^-$  teÅ¼.
- $\blacksquare$  CaÅ‚kÄ™ wzglÄ™dem miary dowolnej funkcji mierzalnej  $X \colon \Omega \to \mathbb{R}$  definujemy wtedy jako

$$\int_{\Omega} X d\mu := \int_{\Omega} X^{+} d\mu - \int_{\Omega} X^{-} d\mu$$

o ile choÄ‡ jedna z caÅ‚ek  $\int_{\Omega}X^+d\mu$ ,  $\int_{\Omega}X^-d\mu$  jest skoÅ„czona. W takiej sytuacji powiemy, Å¼e caÅ‚ka istnieje

- $\blacksquare$  JeÅ›li obie te caÅ‚ki sÄ… skoÅ„czone, tzn.  $\int_{\Omega} |X| d\mu < \infty$ , to mÃ³wimy, Å¼e zmienna losowa  $\overline{X}$  jest <u>caÅ‚kowalna</u> wzgledem miary  $\mu$ .
- ullet CaÅ‚ka wzglÄ™dem miary ma wiele oczekiwanych wÅ‚asnoÅ›ci. PoniÅ¼ej zakÅ‚adamy, Å¼e X i Y sÄ… funkcjami mierzalnymi na  $(\Omega, \mathcal{F})$ .
  - (1)  $\int_{\Omega} (X+Y) d\mu = \int_{\Omega} X d\mu + \int_{\Omega} Y d\mu$  (o ile X i Y sÄ… caÅ‚kowalne wzglÄ™dem  $\mu$ ), (2)  $\int_{\Omega} cX d\mu = c \int_{\Omega} X d\mu$  dla kaÅ¼dego  $c \in \mathbb{R}$ ,

$$\mu(\{\omega \in \Omega \colon X(\omega) \le Y(\omega)) = \mu(\Omega),$$

to  $\int_{\Omega} X d\mu \leq \int_{\Omega} Y d\mu$  (o ile X i Y sÄ… caÅ‚kowalne wzglÄ™dem  $\mu).$ 

- (4)  $\left| \int_{\Omega} X d\mu \right| \leq \int_{\Omega} |X| d\mu$  (o ile X jest caÅ‚kowalny wzglÄ™dem  $\mu$ ).
- (5) JeÅ›li  $X \geq 0$ , to  $\int_{\Omega_2} \left[ \int_{\Omega_1} X(\omega_1, \omega_2) \mu_1(d\omega_1) \right] \mu_2(d\omega_2) = \int_{\Omega_1} \left[ \int_{\Omega_2} X(\omega_1, \omega_2) \mu_2(d\omega_2) \right] \mu_1(d\omega_1)$ .
- (6) JeÅ›li  $\mu(\{\omega \in \Omega : X(\omega) \ge 0\}) = \mu(\Omega)$  oraz  $\int_{\Omega} X d\mu = 0$ , to  $\mu(\{\omega \in \Omega : X(\omega) = 0\}) = \mu(\Omega)$ .

WÅ‚asnoÅ›ci najpierw dowodzimy dla funkcji prostych, kiedy zwykle to jest Å‚atwe. NastÄ™pnie ogÃ³lne funkcje mierzalne aproksymujemy funkcjami prostymi.

â€¢ Najprostszym przykÅ‚adem sÄ… caÅ‚ki wzglÄ™dem miar dyskretnych. Niech  $\delta_a, a \in \mathbb{R}$ , bÄ™dzie miarÄ… na  $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$ zdefiniowanÄ… wzorem  $\delta_a(B) = \mathbb{1}_B(a), B \in \mathcal{B}(\mathbb{R})$ . JeÅ›li  $(x_i, p_i)$  jest dyskretnym rozkÅ‚adem prawdopodobieÅ„stwa, a  $\mu$  odpowiadajÄ…cÄ… miarÄ… na  $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$ , czyli

$$\mu(B) := \sum_{i} p_i \delta_{x_i}(B), \qquad B \in \mathcal{B}(\mathbb{R}).$$

Wtedy

$$\int_{\mathbb{R}} f(x)\mu(dx) = \sum_{i} p_{i} \int_{\mathbb{R}} f(x)\delta_{x_{i}}(dx) = \sum_{i} p_{i}f(x_{i}).$$

â€¢ Drugim najwaÅ¼niejszym przykÅ‚adem miary wzglÄ™dem ktÃ³rej bÄ™dziemy czÄ™sto caÅ‚kowali jest miara Lebesgue'a  $\lambda$  na  $(\Omega, \mathcal{F}) = (\mathbb{R}, \mathcal{B}(\mathbb{R}))$ . Nie jest to miara skoÅ„czona  $(\lambda(\mathbb{R}) = \infty)$ , ale jest  $\sigma$ -skoÅ„czona, tzn.  $\mathbb{R}$  jest przeliczalnÄ… sumÄ… zbiorÃ³w mierzalnych z ktÃ³rych kaÅ¼dy ma skoÅ„czona miarÄ™ (np.  $\mathbb{R} = \bigcup_{n \in \mathbb{Z}} [n, n+1)$ ) co usprawiedliwia wczeÅ›niejszÄ… konstrukcjÄ™ caÅ‚ki dla miary Lebesgue.

Wprowadzimy teraz zwiÄ…zek caÅ‚ki wzglÄ™dem miary Lebesgue'a z tradycyjnÄ… caÅ‚kÄ… Riemanna. ZauwaÅ¼my, Å¼e

$$\int_{[a,b]} 1 \,\lambda(dx) = \lambda([a,b]) = b - a = \int_a^b 1 \, dx,$$

gdzie po prawej stronie mamy zwykÅ‚Ä… caÅ‚kÄ™ Riemanna. Prawdziwe jest nastÄ™pujÄ…ce twierdzenie:

**TW.** Niech  $f: [a, b] \to \mathbb{R}$  bÄ™dzie funkcjÄ… ograniczonÄ….

(1) JeÅ›li f jest caÅ‚kowalna w sensie Riemanna, to f jest caÅ‚kowalna w sensie Lebesgue'a oraz

$$\int_{[a,b]} f(x)\lambda(dx) = \int_a^b f(x)dx.$$

(2) Funkcja f jest caÅ‚kowalna w sensie Riemanna wtedy i tylko wtedy, gdy

$$\lambda(\{x: x \text{ jest punktem nieciÄ…gÅ‚oÅ›ci } f\}) = 0.$$

Z uwagi na rÃ³wnoÅ›Ä‡ caÅ‚ek z punktu (1), przyjeÅ‚o siÄ™ upraszczaÄ‡ oznaczenie: zamiast  $\lambda(dx)$  bÄ™dziemy pisali poprostu dx. PoniewaÅ¼  $\lambda(\{x\})=0$  do dowolnego  $x\in\mathbb{R}$ , to caÅ‚ki  $\int_{[a,b]}, \int_{(a,b)}, \int_{[a,b)}, \int_{(a,b)}$  sÄ… sobie rÃ³wne oraz mogÄ… byÄ‡ zastÄ…pione przez symbol  $\int_a^b$ . Oznacza to teÅ¼, Å¼e w przypadku miary Lebesgue'a dziaÅ‚ajÄ… zwykÅ‚e metody liczenia caÅ‚ek takie jak caÅ‚kowanie przez podstawienie czy przez czÄ™Å›ci.

â€¢ Wiemy juÅ¼, Å¼e jeÅ›li funkcja ograniczona jest caÅ‚kowalna w sensie Riemanna, to jest teÅ¼ caÅ‚kowalna w sensie Lebesgue'a. Odwrotne twierdzenie nie jest prawdziwe, tzn. moÅ¼emy caÅ‚kowaÄ‡ wiÄ™cej funkcji w sensie Lebesgue'a. Sztandarowym kontrprzykÅ‚adem jest funkcja Dirichleta zdefiniowana nastÄ™pujaco:

$$f(x) = \mathbb{1}_{\mathbb{Q}}(x) = \begin{cases} 1, & x \in \mathbb{Q}, \\ 0, & x \in \mathbb{R} \setminus \mathbb{Q}. \end{cases}$$

PoniewaÅ¼ miara Lebesgue pojedynczego punktu wynosi 0 oraz  $\mathbb{Q}$  jest przeliczalny, to  $\mathbb{Q} \in \mathcal{B}(\mathbb{R})$ ,  $\lambda(\mathbb{Q}) = 0$  oraz  $\int_{\mathbb{R}} f d\lambda = 1 \cdot \lambda(\mathbb{Q}) + 0 \cdot \lambda(\mathbb{R} \setminus \mathbb{Q}) = 0$ .

â€¢ JeÅ›li  $\mu = \lambda$ , to  $\mathcal{F}$  jest  $\sigma$ -ciaÅ‚em Lebesgue'a. PoniewaÅ¼  $\mathcal{B}(\mathbb{R}) \subset \mathcal{F}$ , to moÅ¼emy caÅ‚kowaÄ‡ wzglÄ™dem miary Lebesgue'a wszystkie funkcje borelowskie.

<span id="page-12-0"></span>(5.1) Niech  $(\Omega, \mathcal{F}, \mathbb{P})$  bÄ™dzie przestrzeniÄ… probabilistycznÄ…, a X zmiennÄ… losowÄ… na  $(\Omega, \mathcal{F})$ . WartoÅ›ciÄ… oczekiwanÄ… zmiennej losowej X nazywamy wartoÅ›Ä‡

$$\mathbb{E}[X] = \int_{\Omega} X d\mathbb{P} = \int_{\Omega} X(\omega) \mathbb{P}(d\omega),$$

o ile caÅ‚ka po prawej stronie istnieje.

- (5.2) **TW.** WÅ‚asnoÅ›ci wartoÅ›ci oczekiwanej:
  - (a) JeÅ›li X i Y sÄ… caÅ‚kowalne, to  $\mathbb{E}[X+Y] = \mathbb{E}[X] + \mathbb{E}[Y]$ .
  - (b)  $\mathbb{E}[cX] = c \mathbb{E}[X] \text{ dla } c \in \mathbb{R},$
  - (c)  $\mathbb{E}[c] = c \text{ dla } c \in \mathbb{R},$
  - (d) JeÅ›li  $\mathbb{P}(X \geq 0) = 1$ , to  $\mathbb{E}[X] \geq 0$ ,
  - (e) JeÅ›li  $\mathbb{P}(X \leq Y) = 1 \text{ oraz } \mathbb{E}[X] \text{ i } \mathbb{E}[Y] \text{ istnieja, to } \mathbb{E}[X] \leq \mathbb{E}[Y],$
  - (f) JeÅ›li  $\mathbb{E}[X]$  istnieje, to  $|\mathbb{E}[X]| \leq \mathbb{E}[|X|]$ ,
  - (g) JeÅ›li  $\mathbb{P}(X \geq 0) = 1$  oraz  $\mathbb{E}[X] = 0$ , to  $\mathbb{P}(X = 0) = 1$ .
- (5.3) **TW.** (Twierdzenie o zamianie zmiennych) Dla dowolnej funkcji borelowskiej g zachodzi

$$\mathbb{E}[g(X)] = \int_{\Omega} g(X(\omega)) \mathbb{P}(d\omega) = \int_{\mathbb{R}} g(t) \mathbb{P}_X(dt),$$

o ile jedna z caÅ‚ek powyÅ¼ej istnieje. W szczegÃ³lnoÅ›ci  $\mathbb{E}[X] = \int_{\mathbb{R}} t \, \mathbb{P}_X(dt)$ .

Szkic dowodu: Z uwagi na konstrukcjÄ™ caÅ‚ki wzglÄ™dem miary, wystarczy sprawdziÄ‡ dla  $g(t) = \mathbbm{1}_A(t)$  dla  $A \in \mathcal{B}(\mathbb{R})$ . Mamy

$$\int_{\Omega} \mathbb{1}_A(X(\omega)) \mathbb{P}(d\omega) = \int_{\Omega} \mathbb{1}_{X^{-1}(A)} \mathbb{P}(d\omega) = \mathbb{P}(X^{-1}(A)) = \mathbb{P}_X(A) = \int_{\mathbb{R}} \mathbb{1}_A(t) \mathbb{P}_X(dt).$$

(5.4) **LEM.** WartoÅ›Ä‡ oczekiwana dla rozkÅ‚adÃ³w dyskretnych. Niech  $\mathbb{P}(X = x_k) = p_k > 0$  oraz  $\sum_k p_k = 1$ . Wtedy

$$\mathbb{E}[g(X)] = \sum_{k} g(x_k) \, p_k.$$

 $X \sim \text{geo}(p)$ , jeÅ›li  $\mathbb{P}(X=k) = p(1-p)^{k-1}$  dla  $k=1,2,\ldots$  Wtedy  $\mathbb{E}[X] = 1/p$ .

(5.5) **LEM.** WartoÅ›Ä‡ oczekiwana dla rozkÅ‚adÃ³w absolutnie ciÄ…gÅ‚ych. Niech  $f_X$  bÄ™dzie gÄ™stoÅ›ciÄ… X. Wtedy

$$\mathbb{E}[g(X)] = \int_{\mathbb{R}} g(t) f_X(t) dt$$

 $X \sim \mathrm{U}([a,b])$ , jeÅ›li  $f_X(t) = \frac{1}{b-a}\mathbbm{1}[a,b](t)$ . Wtedy  $\mathbb{E}[X] = (b+a)/2$ .

(5.6) WartoÅ›Ä‡ oczekiwana dla rozkÅ‚adÃ³w mieszanych. Dwa sposoby:

â€¢ JeÅ›li  $\mathbb{P}(X \ge 0) = 1$ , to  $\mathbb{E}[X] = \int_0^\infty (1 - F_X(t)) dt$ . Szkic dowodu:

$$\int_{[0,\infty)} t \, \mathbb{P}_X(dt) = \int_{[0,\infty)} \int_0^t ds \, \mathbb{P}_X(dt) = \int_{[0,\infty)} \int_0^\infty \mathbb{1}(s < t) ds \, \mathbb{P}_X(dt) = \int_0^\infty \int_{[0,\infty)} \mathbb{1}(s < t) \mathbb{P}_X(dt) \, ds$$
$$= \int_0^\infty \mathbb{P}_X((s,\infty)) ds = \int_0^\infty (1 - F_X(s)) ds.$$

â€¢ RozwaÅ¼amy tylko przypadek, gdy  $F_X$  nie ma skÅ‚adowej singularnej. Niech  $NC(F_X)$  oznacza punkty nieciÄ…gÅ‚oÅ›ci  $F_X$ , tzn.  $t \in NC(F_X)$  wtedy i tylko wtedy, gdy  $\Delta F_X(t) := F_X(t) - F_X(t-) > 0$ . Wtedy

$$\mathbb{E}[X] = \sum_{t \in NC(F_X)} t \cdot \Delta F_X(t) + \int_{\mathbb{R}} t F_X'(t) dt.$$

 $\mathbf{A} \Delta F_X(t) = \mathbb{P}(X=t).$ 

ZbiÃ³r  $NC(F_X)$  jest co najwyÅ¼ej przeliczalny.

 $oldsymbol{A}$  Wiemy, Å¼e jeÅ›li  $\lambda(\{x\in\mathbb{R}:f(x)\neq g(x)\})=0$  (czyli f i g sÄ… sobie rÃ³wne z dokÅ‚adnoÅ›ciÄ… do zbioru miary Lebesgue'a zero), to  $\int_{\mathbb{R}} f(x)dx=\int_{\mathbb{R}} g(x)dx$ . Funkcja  $F_X$  jest nierÃ³Å¼niczkowalna w punktach skokÃ³w (i byÄ‡ moÅ¼e innych problematycznych punktach typu 'dziubki'), wiÄ™c generalnie napis  $F_X'(t)$  moÅ¼e nie mieÄ‡ sensu dla pewnych  $t\in\mathbb{R}$ . Jednak zbiÃ³r takich punktÃ³w ma miarÄ™ Lebesgue'a zero. Nie musimy siÄ™ zatem przejmowaÄ‡ punktami dla ktÃ³rych  $F_X'(t)$  jest niezdefiniowane.

 $\mbox{\bf$ 

$$\mathbb{E}[X] = p \,\mathbb{E}[X_d] + (1-p)\mathbb{E}[X_{ac}],$$

gdzie  $X_d$  jest zmiennÄ… losowÄ… o dystrybu<br/>ancie  $F_d$ , a  $X_{ac}$  jest zmiennÄ… losowÄ… o dystrybu<br/>ancie  $F_{ac}$ . Ponadto, mamy

$$\Delta F_X(t) = p\Delta F_d(t) = p\mathbb{P}(X_d = t) \text{ dla } t \in \mathbb{R}$$

oraz

$$F_X'(t) = (1-p)F_{ac}'(t) = (1-p)f_{ac}(t)$$
 dla prawie wszystkich  $t \in \mathbb{R}$ .

$$\bullet \ \, \boldsymbol{\mathfrak{C}}_{\boldsymbol{x}}^{\boldsymbol{g}} \text{ ObliczyÄ‡ } \mathbb{E}[X], \text{ gdy } F_X(t) = \begin{cases} 0, & t < 0, \\ t, & t \in [0, 1/2), \\ 1, & t \geq 1/2. \end{cases}$$

6. W6 - Wariancja, nierÃ³wnoÅ›ci i wektory losowe

- <span id="page-13-0"></span>(6.1)  $\blacksquare$  Momentem zwykÅ‚ym rzÄ™du  $n \in \mathbb{N}$  zmiennej losowej X nazywamy  $m_n := \mathbb{E}[X^n]$ .
  - $\blacksquare$  Momentem centralnym rzÄ™du  $n \in \mathbb{N}$  zmiennej losowej X nazywamy  $\mu_n := \mathbb{E}[(X \mathbb{E}[X])^n]$ .
  - $\blacksquare$  Moment centralny rzÄ™du 2 nazywamy wariancjÄ…. o Var[X].
  - $\blacksquare$  Odchyleniem standardowym zmiennej losowej X nazywamy  $\sigma_X := \sqrt{\operatorname{Var}[X]}$ .
- (6.2) **TW.** WÅ‚asnoÅ›ci wariancji:
  - (a)  $Var[X] = \mathbb{E}[X^2] \mathbb{E}[X]^2$ ,
  - (b)  $Var[X] \geq 0$ ,
  - (c)  $\operatorname{Var}[X] = 0 \iff \operatorname{rozkÅ‚ad} X$  jest jednopunktowy, tzn.  $\exists c \in \mathbb{R}$  takie, Å¼e  $\mathbb{P}(X = c) = 1$ ,
  - (d)  $Var[aX + b] = a^2 Var[X],$
  - (e)  $\operatorname{Var}[X] = \inf_{a \in \mathbb{R}} \mathbb{E}[(X a)^2].$

(6.3) **TW.** (NierÃ³wnoÅ›Ä‡ Cauchy'ego-Schwarza) JeÅ›li  $\mathbb{E}[X^2], \mathbb{E}[Y^2] < \infty$ , to

$$|\mathbb{E}[XY]| \leq \sqrt{\mathbb{E}[X^2]\mathbb{E}[Y^2]}.$$

Szkic dowodu: Dla dowolnego  $t \in \mathbb{R}$  mamy  $\mathbb{E}[(tX+Y)^2] \geq 0$ , rozpisaÄ‡, przeksztaÅ‚ciÄ‡  $\Delta \leq 0$ .

(6.4) **TW.** (NierÃ³wnoÅ›Ä‡ Jensena) JeÅ›li g jest funkcjÄ… wypukÅ‚Ä…, to

$$g(\mathbb{E}[X]) \le \mathbb{E}[g(X)].$$

Szkic dowodu: Z definicji wypukÅ‚oÅ›ci funkcji g mamy

$$\forall x \in \mathbb{R} \ \forall x_0 \in \mathbb{R} \ \exists m(x_0) \qquad g(x) \ge g(x_0) + m(x_0)(x - x_0).$$

WziÄ…Ä‡ x = X,  $x_0 = \mathbb{E}[X]$  oraz obÅ‚oÅ¼yÄ‡ obie strony nierÃ³wnoÅ›ci wartoÅ›ciÄ… oczekiwanÄ….

(6.5) **TW.** (NierÃ³wnoÅ›Ä‡ Markowa) JeÅ›li  $\mathbb{P}(X \geq 0) = 1$  oraz  $\mathbb{E}[X] < \infty$ , to dla kaÅ¼dego  $\varepsilon > 0$ 

$$\mathbb{P}(X \ge \varepsilon) \le \frac{\mathbb{E}[X]}{\varepsilon}.$$

Szkic dowodu:  $\varepsilon \mathbb{1}_{X(\omega) \geq \varepsilon} \leq X(\omega)$ .

(6.6) **TW.** (NierÃ³wnoÅ›Ä‡ Czebyszewa) JeÅ›li  $\mathbb{E}[X^2] < \infty$ , to dla kaÅ¼dego  $\varepsilon > 0$ 

$$\mathbb{P}(|X - \mathbb{E}[X]| \ge \varepsilon) \le \frac{\operatorname{Var}[X]}{\varepsilon^2}.$$

Szkic dowodu: szybki wniosek z NierÃ³wnoÅ›ci Markowa.

- (6.7) **LEM.** (ReguÅ‚a  $3\sigma$ ) JeÅ›li  $\mathbb{E}[X^2] < \infty$ , to  $\mathbb{P}(|X \mathbb{E}[X]| \ge 3\sigma_X) \le 1/9$ . W szczegÃ³lnoÅ›ci, jeÅ›li  $X \sim N(0,1)$ , to  $\sigma_X = 1$  oraz  $\mathbb{P}(|X \mathbb{E}[X]| \ge 3\sigma_X) \approx 0.0027$ .
- (6.8) Niech  $(\Omega, \mathcal{F})$  bÄ™dzie przestrzeniÄ… mierzalnÄ…. FunkcjÄ™  $\underline{X} \colon \Omega \to \mathbb{R}^n$  nazywamy wektorem losowym, jeÅ›li jest ona  $\mathcal{F}$ -mierzalna, tzn.

$$\forall B \in \mathcal{B}(\mathbb{R}^n) \quad \underline{X}^{-1}(B) := \{ \omega \in \Omega \colon \underline{X}(\omega) \in B \} \in \mathcal{F}.$$

**E** RozkÅ‚adem prawdopodobieÅ„stwa wektora <u>X</u> nazywamy funkcjÄ™

$$\mathbb{P}_X(B) := \mathbb{P}(\underline{X} \in B), \qquad B \in \mathcal{B}(\mathbb{R}^n).$$

 $\blacksquare$  <u>DystrybuantÄ… wektora losowego</u>  $\underline{X}=(X_1,\ldots,X_n)$  nazywamy funkcjÄ™  $F_{\underline{X}}\colon\mathbb{R}^n\to[0,1]$  zdefiniowanÄ… wzorem

$$F_{\underline{X}}(\underline{t}) = \mathbb{P}\left(\left\{\omega \in \Omega \colon X_i(\omega) \le t_i \text{ dla } i = 1, \dots, n\right\}\right),$$

gdzie  $\underline{t} = (t_1, \dots, t_n) \in \mathbb{R}^n$ .

**TW.** Podobnie jak w przypadku jednowymiarowym, dystrybuanta  $F_{\underline{X}}$  jednoznacznie wyznacza rozkÅ‚ad prawdopodobieÅ„stwa  $\mathbb{P}_X$ .

- ullet Z lenistwa, bÄ™dziemy pisali  $\{X \in A, Y \in B\}$  zamiast  $\{X \in A\} \cap \{Y \in B\} = \{\omega \in \Omega \colon X(\omega) \in A \land Y(\omega) \in B\}$ .
- $\blacksquare$  W szczegÃ³lnoÅ›ci dystrybuantÄ… wektora losowego (X,Y) nazywamy funkcjÄ™

$$\mathbb{R}^2\ni (s,t)\mapsto F_{(X,Y)}(s,t):=\mathbb{P}(X\leq s,Y\leq t)=\mathbb{P}_{(X,Y)}((-\infty,s]\times (-\infty,t]).$$

- (6.9) **TW.** WÅ‚asnoÅ›ci dystrybuanty dla n=2.
  - (a)  $F_{(X,Y)}$  jest prawostronnie ciÄ…gÅ‚a po wspÃ³Å‚rzÄ™dnych,
  - (b)  $\forall a_1 \leq b_1 \text{ oraz } \forall a_2 \leq b_2$ ,

$$\Delta_{(a,b)}^{(2)}F_{(X,Y)} := F_{(X,Y)}(b_1,b_2) - F_{(X,Y)}(a_1,b_2) - F_{(X,Y)}(b_1,a_2) + F_{(X,Y)}(a_1,a_2) \ge 0.$$

Ponadto 
$$\Delta_{(a,b)}^{(2)} F_{(X,Y)} = \mathbb{P}_{(X,Y)}((a_1,b_1] \times (a_2,b_2]).$$

- (c)  $\lim_{(s,t)\to(\infty,\infty)} F_{(X,Y)}(s,t) = 1$ ,
- (d) Dla kaÅ¼dego  $s,t\in\mathbb{R}$  zachodzi  $\lim_{x\to-\infty}F_{(X,Y)}(x,t)=0=\lim_{x\to-\infty}F_{(X,Y)}(s,x)$

lacktriangle Warunek (b) dla ogÃ³lnego n moÅ¼na rozumieÄ‡ w nastÄ™pujÄ…cy sposÃ³b: niech  $\mathbb{P}_{\underline{X}}$  bÄ™dzie miarÄ… wyznaczonÄ… przez dystrybuantÄ™  $F_X$ , wtedy wymagamy, by

$$\mathbb{P}_{\underline{X}}((a_1, b_1] \times \ldots \times (a_n, b_n]) \ge 0.$$

dla dowolnych  $\underline{a}, \underline{b} \in \mathbb{R}^n$  takich, Å¼e  $a_i < b_i$ , i = 1, ..., n. LewÄ… stronÄ™ powyÅ¼ej oznaczmy przez  $\Delta_{(\underline{a},\underline{b})}^{(n)} F$ . MoÅ¼na napisaÄ‡ ten warunek jawnie w terminach  $F_{\underline{X}}$ . Definiujemy najpierw operatory rÃ³Å¼nicowe: dla k = 1, ..., n oraz a < b niech

$$\Delta_{(a,b)}^{(k)} F(\underline{x}) := F(x_1, \dots, x_{k-1}, b, x_{k+1}, \dots, x_n) - F(x_1, \dots, x_{k-1}, a, x_{k+1}, \dots, x_n).$$

Wtedy

$$\mathbb{P}_{\underline{X}}((a_1,b_1]\times\ldots\times(a_n,b_n])=\Delta_{(a_1,b_1)}^{(1)}\ldots\Delta_{(a_n,b_n)}^{(n)}F_{\underline{X}}(\underline{x})=:\Delta_{(\underline{a},\underline{b})}^{(n)}F_{\underline{X}}(\underline{x})$$

(6.10)  $\overset{\bullet}{\mathbf{x}}$  Miary produktowe. Niech  $F_1, \ldots, F_n$  bÄ™dÄ… jednowymiarowymi dystrybuantami. Wtedy

$$F(t_1,\ldots,t_n):=\prod_{k=1}^n F_k(t_k)$$

jest n-wymiarowÄ… dystrybuantÄ… oraz  $\Delta_{(a,b)}^{(n)} F = \prod_{k=1}^n \left( F_k(b_k) - F_k(a_k) \right)$  (  $\clubsuit$  ).

- (6.11)  $\triangle$  Podobnie jak w przypadku rozkÅ‚adÃ³w zmiennych losowych, definiujemy noÅ›nik rozkÅ‚adu wektora. Niech  $X: \Omega \to \mathbb{R}^n$ .
  - NoÅ›nikiem (rozkÅ‚adu) wektora losowego  $\underline{X}$  ( $\bigcirc$  supp( $\underline{X}$ )) nazywamy najmniejszy taki zbiÃ³r domkniÄ™ty  $D \subset \mathbb{R}^n$  dla ktÃ³rego

$$\mathbb{P}(\underline{X} \in D) = 1.$$

#### 7. W7 - Wektory Losowe CiÄ…g dalszy

- <span id="page-15-0"></span>(7.1) PrzykÅ‚ady rozkÅ‚adÃ³w wielowymiarowych.
  - (a) Wielowymiarowe rozkÅ‚ady dyskretne. CiÄ…g par  $((\underline{x}^{(k)}, p_k))_k$  nazywamy  $\underline{n}$ -wymiarowym dyskretnym rozkÅ‚adem prawdopodobieÅ„stwa, jesli  $\underline{x}^{(k)} \in \mathbb{R}^n$ ,  $\underline{x}^{(k)} \neq \underline{x}^{(j)}$  dla  $k \neq j$ ,  $p_k > 0$  oraz  $\sum_k p_k = 1$ .

**A** JeÅ›li  $\mathbb{P}(\underline{X} = \underline{x}^{(k)}) = p_k$  dla wszystkich k, to  $\operatorname{supp}(\underline{X}) := \{\underline{x}^{(k)} : k = 1, 2, \ldots\}.$ 

RozkÅ‚ad wielomianowy. Przeprowadzamy n niezaleÅ¼nych prÃ³b eksperymentu, przy czym kaÅ¼da prÃ³ba moÅ¼e skoÅ„czyÄ‡ siÄ™ jednym z  $r \in \mathbb{N}$  rodzajÃ³w sukcesÃ³w (i-ty rodzaj sukcesu zachodzi z p-stwem  $p_i$ ) lub poraÅ¼kÄ…. Niech  $\underline{X} = (X_1, \dots, X_r)$ , gdzie  $X_i$  jest zmiennÄ… losowÄ… reprezentujÄ…cÄ… liczbÄ™ sukcesÃ³w i-tego rodzaju,  $i = 1, \dots, r$ . Wtedy

$$\mathbb{P}(X_1 = k_1, \dots, X_r = k_r) = \binom{n}{k_1, \dots, k_r} p_1^{k_1} \dots p_r^{k_r} (1 - \sum_{i=1}^r p_i)^{n - \sum_{i=1}^r k_i}, \qquad k_i \ge 0, \ \sum_{i=1}^r k_i \le n,$$

gdzie

$$\binom{n}{k_1, \dots, k_r} := \frac{n!}{k_1! \dots k_n! (n - \sum_{i=1}^r k_i)!}.$$

 $\operatorname{supp}(\underline{X}) = \{(k_1, \dots, k_r) \in (\mathbb{N} \cup \{0\})^r \colon \sum_{i=1}^r k_i \le n\}.$ 

 $\bullet$   $X \sim m_r(n, p)$ .

(b) Miary absolutnie ciÄ…gÅ‚e wzglÄ™dem miary Lebesgue  $\lambda_n$ . JeÅ›li  $f: \mathbb{R}^n \to \mathbb{R}$  jest borelowska, prawie wszÄ™dzie nieujemna oraz caÅ‚kuje siÄ™ (wzglÄ™dem  $\lambda_n$ ) do 1, to

$$F(s_1,\ldots,s_n) = \int_{(-\infty,s_1]} \ldots \int_{(-\infty,s_n]} f(t_1,\ldots,t_n) dt_n \ldots dt_1$$

jest n-wymiarowÄ… dystrybuantÄ… oraz  $\Delta_{(a,\underline{b})}^{(n)}F=\int_{(a_1,b_1]}\ldots\int_{(a_n,b_n]}f(\underline{t})dt_n\ldots dt_1$  (  $\clubsuit$  ).

**A** JeÅ›li wektor losowy  $\underline{X}$  ma gÄ™stoÅ›Ä‡  $f_{\underline{X}}$ , to supp $(\underline{X}) := \inf\{\underline{t} \in \mathbb{R}^n : f_{\underline{X}}(\underline{t}) > 0\}.$ 

Wektor losowy  $(X_1, \ldots, X_n)$  ma wielowymiarowy rozkÅ‚ad normalny  $N_n(\underline{\mu}, \Sigma)$ , z parametrami  $\mu \in \mathbb{R}^n$  i  $\Sigma \in \operatorname{Sym}_+(n)$ , jeÅ›li

$$f_{\underline{X}}(\underline{x}) = \frac{1}{(\sqrt{2\pi})^n \sqrt{\det \Sigma}} e^{-\frac{1}{2}(\underline{x} - \underline{\mu})^\top \cdot \Sigma^{-1} \cdot (\underline{x} - \underline{\mu})}, \qquad \underline{x} \in \mathbb{R}^n.$$

 $\triangle$  Sym<sub>+</sub>(n) oznacza zbiÃ³r macierzy symetrycznych dodatnio okreÅ›lonych wymiaru  $n \times n$ .

- (7.2) Niech  $\underline{X}: \Omega \to \mathbb{R}^n$  bÄ™dzie wektorem losowym. Podwektory wektora  $\underline{X}$ , tzn.  $(X_{i_1}, \dots, X_{i_k})$  dla k < n rÃ³wnieÅ¼ sÄ… wektorami losowymi, a ich rozkÅ‚ady nazywamy rozkÅ‚adami brzegowymi wektora  $\underline{X}$ .
  - Wektor  $\underline{X} = (X_1, X_2, X_3)$  ma 6 podwektorÃ³w  $(X_1, X_2), (X_1, X_3), (X_2, X_3), (X_1), (X_2), (X_3).$
- (7.3) **LEM.** JeÅ›li  $F_{\underline{X}}$  jest dystrybuantÄ… wektora  $\underline{X} = (X_1, \dots, X_n)$ , to

$$F_{\underline{X}^{(-j)}}(t_1,\ldots,t_{j-1},t_{j+1},\ldots,t_n) = \lim_{t_i \to \infty} F_{\underline{X}}(t_1,\ldots,t_{j-1},t_j,t_{j+1},\ldots,t_n).$$

jest dystrybuantÄ… wektora  $\underline{X}^{(-j)} = (X_1, \dots, X_{j-1}, X_{j+1}, \dots, X_n).$ 

Szkic dowodu: Wykorzystujemy ciÄ…gÅ‚oÅ›Ä‡ z gÃ³ry prawdopodobieÅ„stwa, tak samo jak w przypadku wÅ‚asnoÅ›ci dystrybuanty jednowymiarowej.

(7.4) **LEM.** JeÅ›li wektor  $\underline{X} = (X_1, \dots, X_n)$  ma gÄ™stoÅ›Ä‡  $f_{\underline{X}}$ , to dowolny rozkÅ‚ad brzegowy rÃ³wnieÅ¼ posiada gÄ™stoÅ›Ä‡. Ponadto

$$f_{\underline{X}^{(-j)}}(t_1,\ldots,t_{j-1},t_{j+1},\ldots,t_n) = \int_{\mathbb{R}} f_{\underline{X}}(t_1,\ldots,t_{j-1},t_j,t_{j+1},\ldots,t_n) dt_j.$$

jest gÄ™stoÅ›ciÄ… wektora  $\underline{X}^{(-j)} = (X_1, \dots, X_{j-1}, X_{j+1}, \dots, X_n).$ 

(7.5) **LEM.** JeÅ›li wektor  $\underline{X} = (X_1, \dots, X_n)$  ma rozkÅ‚ad dyskretny, to dowolny rozkÅ‚ad brzegowy rÃ³wnieÅ¼ jest dyskretny. Ponadto

$$\mathbb{P}(\underline{X}^{(-j)} = \underline{t}^{(-j)}) = \sum_{t,i} \mathbb{P}(\underline{X} = \underline{t}),$$

gdzie jak wczeÅ›niej  $\underline{X}^{(-j)} = (X_1, \dots, X_{j-1}, X_{j+1}, \dots, X_n)$  oraz  $\underline{t}^{(-j)} = (t_1, \dots, t_{j-1}, t_{j+1}, \dots, t_n)$ .

RozkÅ‚ad wielomianowy dla  $r=2, (X,Y) \sim m_2(n,(p_1,p_2))$ . Mamy

$$\mathbb{P}(X_1 = k_1, X_2 = k_2) = \frac{n!}{k_1! k_2! (n - k_1 - k_2)!} p_1^{k_1} p_2^{k_2} (1 - p_1 - p_2)^{n - k_1 - k_2}, \qquad k_1, k_2 \ge 0, \ k_1 + k_2 \le n.$$

Wtedy  $\mathbb{P}(X_1 = k_1) = \sum_{k_2=0}^{n-k_1} \mathbb{P}(X_1 = k_1, X_2 = k_2) = \binom{n}{k_1} p_1^{k_1} (1-p_1)^{n-k_1}$  dla  $k_1 = 0, \dots, n$ , czyli  $X_1$  ma rozkÅ‚ad dwumianowy b $(n, p_1)$ .

(7.6)  $\blacksquare$  Zmienne losowe  $X_1, \ldots, X_n$  (okreÅ›lone na tej samej przestrzeni  $(\Omega, \mathcal{F})$ ) sÄ… <u>niezaleÅ¼ne</u>, jeÅ›li

$$\forall B_i \in \mathcal{B}(\mathbb{R}), i = 1, \dots, n, \qquad \mathbb{P}(X_1 \in B_1, \dots, X_n \in B_n) = \mathbb{P}(X_1 \in B_1) \dots \mathbb{P}(X_n \in B_n).$$

f A Tak naprawdÄ™ powinniÅ›my mÃ³wiÄ‡ o  $\Bbb P$ -niezaleÅ¼noÅ›ci, poniewaÅ¼ wÅ‚asnoÅ›Ä‡ ta zaleÅ¼y od prawdopodobieÅ„stwa  $\Bbb P$  na  $(\Omega, \mathcal F)$ . MoÅ¼e zdarzyÄ‡ siÄ™ tak, Å¼e X i Y sÄ…  $\Bbb P$ -niezaleÅ¼ne ale juÅ¼ nie  $\H P$ -niezaleÅ¼ne, gdzie  $\H P$  jest innym prawdopodobieÅ„stwem na  $(\Omega, \mathcal F)$ . Zwykle jednak mamy jedno prawdopodobieÅ„stwo i dlatego mÃ³wienie o samej niezaleÅ¼noÅ›ci nie wprowadza zamieszania.

(7.7) **LEM.** JeÅ›li zmienne losowe  $X_1, \ldots, X_n$  sÄ… niezaleÅ¼ne oraz  $f_i$  sÄ… funkcjami borelowskimi dla  $i = 1, \ldots, n$ , to zmienne losowe  $f_1(X_1), \ldots, f_n(X_n)$  rÃ³wnieÅ¼ sÄ… niezaleÅ¼ne.

**LEM.** JeÅ›li zmienne losowe  $X_1, \ldots, X_n$  sÄ… niezaleÅ¼ne oraz oraz  $\phi \colon \mathbb{R}^k \to \mathbb{R}$  i  $\psi \colon \mathbb{R}^{n-k} \to \mathbb{R}$  sÄ… borelowskie, to zmienne losowe  $\phi(X_1, \ldots, X_k)$  oraz  $\psi(X_{k+1}, \ldots, X_n)$  sÄ… niezaleÅ¼ne.

(7.8) **TW.** Zmienne losowe  $X_1, \ldots, X_n$  sÄ… niezaleÅ¼ne wtedy i tylko wtedy, gdy

$$\forall (t_1, \dots, t_n) \in \mathbb{R}^n \qquad F_{\underline{X}}(t_1, \dots, t_n) = F_{X_1}(t_1) \dots F_{X_n}(t_n).$$

Szkic dowodu: W prawÄ… stronÄ™ oczywiste. W lewÄ…: trzeba siÄ™ dobrze zastanowiÄ‡, by zrozumieÄ‡, Å¼e to wynika z faktu, Å¼e dystrybuanta wyznacza rozkÅ‚ad jednoznacznie.

(7.9) **LEM.** Niech  $\underline{X} = (X_1, \dots, X_n)$  ma rozkÅ‚ad dyskretny. Zmienne losowe  $X_1, \dots, X_n$  sÄ… niezaleÅ¼ne wtedy i tylko wtedy, gdy

$$\forall (k_1,\ldots,k_n) \in \operatorname{supp}(\underline{X}) \qquad \mathbb{P}(X_1 = k_1,\ldots,X_n = k_n) = \mathbb{P}(X_1 = k_1)\ldots\mathbb{P}(X_n = k_n).$$

(7.10) **LEM.** Niech  $\underline{X} = (X_1, \dots, X_n)$  ma rozkÅ‚ad o gÄ™stoÅ›ci  $f_{\underline{X}}$ . Zmienne losowe  $X_1, \dots, X_n$  sÄ… niezaleÅ¼ne wtedy i tylko wtedy, gdy

$$\forall (t_1,\ldots,t_n) \in \mathbb{R}^n \qquad f_{\underline{X}}(t_1,\ldots,t_n) = f_{X_1}(t_1)\ldots f_{X_n}(t_n).$$

 $\mathbf{A}$  JeÅ›li istniejÄ… funkcje  $g_1, \ldots, g_n$  (niekoniecznie gÄ™stoÅ›ci) takie, Å¼e dla dowolnego  $(t_1, \ldots, t_n) \in \mathbb{R}^n$  gÄ™stoÅ›Ä‡  $f_{\underline{X}}$  siÄ™ faktoryzuje

$$f_X(t_1, \dots, t_n) = g_1(t_1) \dots g_n(t_n),$$

to zmienne losowe  $X_1, \ldots, X_n$  sÄ… niezaleÅ¼ne.

(7.11)  $(X_1, \dots, X_n)$  Niech zmienne losowe  $X_1, \dots, X_n$  bÄ™dÄ… niezaleÅ¼ne oraz zdefiniujmy  $M = \max\{X_1, \dots, X_n\}$  oraz  $m = \min\{X_1, \dots, X_n\}$ . Wtedy

$$F_M(t) = \prod_{k=1}^n F_{X_k}(t), \qquad F_m(t) = 1 - \prod_{k=1}^n (1 - F_{X_k}(t)).$$

- (7.12) Powiemy, Å¼e zmienne losowe  $X_1, \ldots, X_n$  sÄ… <u>i.i.d.</u> (independent and identically distributed), jeÅ›li sÄ… niezaleÅ¼ne oraz majÄ… takie same rozkÅ‚ady.
- (7.13)  $(x_1, \dots, x_n)$  bÄ™dÄ… zmiennymi i.i.d. o dystrybuancie F. Niech  $X_{k:n}(\omega)$  bÄ™dzie k-tÄ… co do wielkoÅ›ci wartoÅ›ciÄ… spoÅ›rÃ³d  $X_1(\omega), \dots, X_n(\omega)$ .  $[X_{k:n}]$  jest tzw. k-tÄ… statystykÄ… pozycyjnÄ….] Zdefiniujmy  $A_j(t)$  zdarzenie, Å¼e dokÅ‚adnie j spoÅ›rÃ³d X'Ã³w jest mniejszych lub rÃ³wnych t. Wtedy

$$\mathbb{P}(X_{k:n} \le t) = \mathbb{P}(\bigcup_{j=k}^{n} A_j(t)) = \sum_{j=k}^{n} \mathbb{P}(A_j(t)) = \sum_{j=k}^{n} \binom{n}{j} F(t)^j (1 - F(t))^{n-j}.$$

(7.14) **LEM.** JeÅ›li  $\operatorname{supp}(\underline{X}) \neq \operatorname{supp}(X_1) \times \ldots \times \operatorname{supp}(X_n)$ , to zmienne losowe  $X_1, \ldots, X_n$  nie sÄ… niezaleÅ¼ne. Szkic dowodu: Zawsze mamy  $\operatorname{supp}(\underline{X}) \subset \operatorname{supp}(X_1) \times \ldots \times \operatorname{supp}(X_n)$ . JeÅ›li  $\operatorname{supp}(\underline{X}) \neq \operatorname{supp}(X_1) \times \ldots \times \operatorname{supp}(X_n)$ , to istnieja niepuste zbiory  $B_1, \ldots, B_n \in \mathcal{B}(\mathbb{R})$  takie, Å¼e

$$B_1 \times \ldots \times B_n \subset (\operatorname{supp}(X_1) \times \ldots \times \operatorname{supp}(X_n)) \setminus \operatorname{supp}(\underline{X})$$

oraz  $\mathbb{P}(X_i \in B_i) > 0$  dla  $i = 1, \dots, n$  (poniewaÅ¼  $B_i \subset \text{supp}(X_i)$ ). PoniewaÅ¼

$$(B_1 \times \ldots \times B_n) \cap \operatorname{supp}(\underline{X}) = \emptyset,$$

to mamy  $\mathbb{P}(\underline{X} \in B_1 \times ... \times B_n) = 0$ , co przeczy niezaleÅ¼noÅ›ci.

#### 8. W8 - Wektory Losowe Dalszy CiÄ…g Dalszy

- <span id="page-17-0"></span>(8.1) Transformacje wektorÃ³w losowych.
  - $\bullet$  Dodawanie zmiennych losowych. Niech (X,Y) bÄ™dzie wektorem losowym o znanym rozkÅ‚adzie oraz zdefiniujmy Z = X + Y.
    - (a) â™  NoÅ›nik zmiennej losowej Z jest zadany przez

$$\operatorname{supp}(Z) = \{x + y \colon (x, y) \in \operatorname{supp}(X, Y)\}.$$

W szczegÃ³lnoÅ›ci, jeÅ›li X i Y sÄ… niezaleÅ¼ne, to  $supp(X,Y) = supp(X) \times supp(Y)$ , a wiÄ™c wtedy

$$\operatorname{supp}(Z) = \{x + y \colon x \in \operatorname{supp}(X), y \in \operatorname{supp}(Y)\} =: \operatorname{supp}(X) + \operatorname{supp}(Y).$$

(b) JeÅ›li (X,Y) ma rozkÅ‚ad dyskretny, to Z ma rozkÅ‚ad dyskretny oraz

$$\mathbb{P}(Z=z_k) = \sum_{j} \mathbb{P}(X=x_j, Y=z_k - x_j).$$

 $\mathbf{x}_{\mathbf{x}}^{\mathbf{x}}$  Niech  $(X,Y) \sim \mathrm{m}_2(n,(p_1,p_2))$ . Wtedy

$$\mathbb{P}(Z=k) = \sum_{l=0}^{k} \mathbb{P}(X=l, Y=k-l) = \binom{n}{k} (p_1 + p_2)^k (1 - p_1 - p_2)^{n-k}, \qquad k = 0, 1, \dots, n,$$

czyli  $Z \sim b(n, p_1 + p_2)$ .

Niech  $X \sim \mathrm{b}(n_1,p)$  oraz  $Y \sim \mathrm{b}(n_2,p), X$  i Y niezaleÅ¼ne. Wtedy

$$\mathbb{P}(Z=k) = \sum_{l=\max\{0,k-n_2\}}^{\min\{n_1,k\}} \mathbb{P}(X=l)\mathbb{P}(Y=k-l) = \binom{n_1+n_2}{k} p^k (1-p)^{n_1+n_2-k}, \qquad k=0,1,\ldots,n_1+n_2,$$

czyli  $Z \sim b(n_1 + n_2, p)$ .

Inaczej:  $X \stackrel{d}{=} \sum_{k=1}^{n_1} I_k$ , gdzie  $(I_k)_k$  sÄ… i.i.d. z rozkÅ‚adu b(1,p). (c) OgÃ³lnie, dystrybuanta zmiennej losowej Z = X + Y dana jest przez

$$F_Z(t) = \mathbb{P}(X + Y \le t) = \mathbb{P}_{(X,Y)}(\{(x,y) \in \mathbb{R}^2 : x + y \le t\}) = \iint_{\{(x,y) \in \mathbb{R}^2 : x + y \le t\}} \mathbb{P}_{(X,Y)}(dx, dy).$$

**A** Zgodnie z wprowadzonymi wczeÅ›niej oznaczeniami powinniÅ›my raczej pisaÄ‡  $\mathbb{P}_{(X,Y)}(d(x,y))$ , a nie  $\mathbb{P}_{(X,Y)}(dx,dy)$ , ale d(x,y) dziwnie wyglÄ…da.

JeÅ›li X i Y sÄ… niezaleÅ¼ne, to  $\mathbb{P}_{(X,Y)}(dx,dy) = \mathbb{P}_X(dx)\mathbb{P}_Y(dy)$  oraz moÅ¼emy rozwaÅ¼aÄ‡ caÅ‚ki iterowane:

$$F_Z(t) = \int_{-\infty}^{\infty} \int_{-\infty}^{t-y} \mathbb{P}_X(dx) \mathbb{P}_Y(dy) = \int_{-\infty}^{\infty} F_X(t-y) \mathbb{P}_Y(dy)$$
$$= \int_{-\infty}^{\infty} \int_{-\infty}^{t-x} \mathbb{P}_Y(dy) \mathbb{P}_X(dx) = \int_{-\infty}^{\infty} F_Y(t-x) \mathbb{P}_X(dx)$$

(a) JeÅ›li (X,Y) ma gÄ™stoÅ›Ä‡, to Z rÃ³wnieÅ¼ ma gÄ™stoÅ›Ä‡ oraz

$$f_Z(t) = \int_{\mathbb{R}} f_{(X,Y)}(t-y,y) dy = \int_{\mathbb{R}} f_{(X,Y)}(x,t-x) dx.$$

Szkic dowodu: PoniewaÅ¼ (X,Y) ma gÄ™stoÅ›Ä‡, to  $\mathbb{P}_{(X,Y)}(dx,dy)=f_{(X,Y)}(x,y)dx\,dy$ . Zatem,

$$F_{Z}(t) = \iint_{\{(x,y) \in \mathbb{R}^{2} : x+y \le t\}} f_{(X,Y)}(x,y) dx dy = \int_{-\infty}^{\infty} \int_{-\infty}^{t-y} f_{(X,Y)}(x,y) dx dy$$
$$= \int_{-\infty}^{\infty} \int_{-\infty}^{t} f_{(X,Y)}(z-y,y) dz dy = \int_{-\infty}^{t} \int_{-\infty}^{\infty} f_{(X,Y)}(z-y,y) dy dz = \int_{-\infty}^{t} f_{Z}(z) dz.$$

Inaczej: RÃ³Å¼niczkujemy pod znakiem caÅ‚ki po prawej stronie rÃ³wnoÅ›ci:

$$F_Z(t) = \int_{-\infty}^{\infty} \int_{-\infty}^{t-y} f_{(X,Y)}(x,y) dx \, dy.$$

Korzystamy z wÅ‚asnoÅ›ci typu:

 $\triangle$  JeÅ›li funkcja h jest ciÄ…gÅ‚a w punkcie t, to

$$\frac{d}{dt} \int_{t}^{t} h(s)ds = h(t),$$

gdzie \* jest dowolne, byleby nie zaleÅ¼aÅ‚o od t.

lacktriangle JeÅ›li funkcja  $H: \mathbb{R}^2 \to \mathbb{R}$  jest Å‚adna (np.  $\left| \frac{d}{dx} H(x,y) \right| \leq g(y)$  dla pewnej caÅ‚kowalnej funkcji g), to

$$\frac{d}{dx} \int_{\mathbb{R}} H(x, y) dy = \int_{\mathbb{R}} \frac{d}{dx} H(x, y) dy.$$

Niech  $X \sim G(p_1, a)$  oraz  $Y \sim G(p_2, a)$  i niech X i Y bÄ™dÄ… niezaleÅ¼ne. Wtedy dla t > 0,

$$f_Z(t) = \int_{\mathbb{R}} f_X(t-y) f_Y(y) dy = \frac{a^{p_1 + p_2} e^{-at}}{\Gamma(p_1) \Gamma(p_2)} \int_0^t y^{p_2 - 1} (t-y)^{p_1 - 1} dy = \frac{a^{p_1 + p_2}}{\Gamma(p_1 + p_2)} t^{p_1 + p_2 - 1} e^{-at},$$

czyli  $Z \sim G(p_1 + p_2, a)$ .

â€¢ Dzielenie zmiennych losowych. Niech (X,Y) ma gÄ™stoÅ›Ä‡. Wtedy  $\mathbb{P}(Y=0)=0$  oraz  $Q=\frac{X}{Y}$  jest dobrze zdefiniowanÄ… zmiennÄ… losowÄ…. Wtedy

$$F_{Q}(t) = \mathbb{P}(X \le tY, Y > 0) + \mathbb{P}(X \ge tY, Y < 0)$$
  
=  $\int_{0}^{\infty} \int_{-\infty}^{ty} f_{(X,Y)}(x, y) dx dy + \int_{-\infty}^{0} \int_{ty}^{\infty} f_{(X,Y)}(x, y) dx dy.$ 

RÃ³Å¼niczkujac otrzymujemy

$$f_Q(t) = \int_{\mathbb{R}} |y| f_{(X,Y)}(ty,y) dy.$$

Niech X, Y bÄ™da i.i.d. z rozkÅ‚adu N(0, 1). Wtedy

$$f_{\frac{X}{Y}}(t) = \frac{1}{\pi(1+t^2)}, \quad t \in \mathbb{R},$$

czyli  $\frac{X}{Y} \sim C(1)$ .

(8.2)  $\blacksquare$  WartoÅ›ciÄ… oczekiwanÄ… wektora losowego  $\underline{X} = (X_1, \dots, X_n)$  nazywamy wektor

$$\mathbb{E}[\underline{X}] = (\mathbb{E}[X_1], \dots, \mathbb{E}[X_n]),$$

o ile wszystkie  $\mathbb{E}[X_i]$ ,  $i = 1, \ldots, n$ , istniejÄ….

(8.3) **LEM.** JeÅ›li  $\underline{X}$  ma gÄ™stoÅ›Ä‡ oraz  $\phi \colon \mathbb{R}^n \to \mathbb{R}^k$  jest borelowska, to

$$\mathbb{E}[\phi(\underline{X})] = \int \cdots \int_{\mathbb{R}^n} \phi(\underline{t}) f_{\underline{X}}(\underline{t}) dt_1 \dots dt_n.$$

W szczegÃ³lnoÅ›ci, jeÅ›li  $g \colon \mathbb{R}^2 \to \mathbb{R}$ , to

$$\mathbb{E}[g(X,Y)] = \iint\limits_{\mathbb{R}^2} g(x,y) f_{(X,Y)}(x,y) dx \, dy.$$

(8.4) **TW.** JeÅ›li  $X_1, \ldots, X_n$  sÄ… niezaleÅ¼nymi zmiennymi losowymi, to

$$\mathbb{E}[X_1 \dots X_n] = \mathbb{E}[X_1] \dots \mathbb{E}[X_n],$$

o ile  $\mathbb{E}[X_i] < \infty, i = 1, \dots, n$ .

Szkic dowodu: Wystarczy udowodniÄ‡ dla n=2, dla dowolnego n indukcja. RÃ³wnoÅ›Ä‡ zachodzi dla zmiennych indykatorowych, tzn. gdy  $X_1=\mathbbm{1}_A, X_2=\mathbbm{1}_B,$  gdzie  $A,B\in\mathcal{F}$  sÄ… zdarzeniami niezaleÅ¼nymi. Z liniowoÅ›ci wartoÅ›ci oczekiwanej, mamy tezÄ™, gdy  $X_1$  i  $X_2$  sÄ… funkcjami prostymi. Dowolne nieujemne  $X_1$  i  $X_2$  aproksymujemy funkcjami prostymi. Znakowane  $X_1$  i  $X_2$  rozkÅ‚adamy na czÄ™Å›ci dodatnie i ujemne.

A Twierdzenie w odwrotnÄ… stronÄ™ nie zachodzi.

(8.5) Niech X, Y beda zmiennymi losowymi na tej samej przestrzeni takimi, Å¼e  $\mathbb{E}[X^2], \mathbb{E}[Y^2] < \infty$ . KowariancjÄ… wektora (X,Y) nazywamy wielkoÅ›Ä‡

$$Cov[X, Y] = \mathbb{E}[(X - \mathbb{E}[X])(Y - \mathbb{E}[Y])].$$

- (8.6) **TW.** WÅ‚asnoÅ›ci kowariancji.
  - (a) Cov[X, Y] = Cov[Y, X],
  - (b) Cov[X, X] = Var[X],
  - (c)  $\operatorname{Cov}[X, Y] = \mathbb{E}[XY] \mathbb{E}[X]\mathbb{E}[Y],$
  - (d)  $|Cov[X, Y]| \le \sqrt{Var[X]Var[Y]}$ ,
  - (e) JeÅ›li X i Y sÄ… niezaleÅ¼ne, to Cov[X, Y] = 0,
  - (f)  $\operatorname{Cov}[aX + bY + c, dX + eY + f] = \operatorname{ad} \operatorname{Var}[X] + (ae + bd)\operatorname{Cov}[X, Y] + \operatorname{be} \operatorname{Var}[Y],$ (g)  $\operatorname{Var}[\sum_{i=1}^{n} X_i] = \sum_{i=1}^{n} \operatorname{Var}[X_i] + 2\sum_{1 \leq i < j \leq n} \operatorname{Cov}[X_i, X_j],$ (h) JeÅ›li zmienne losowe  $X_1, \dots, X_n$  sÄ… i.i.d., to

$$\operatorname{Var}\left[\frac{1}{n}\sum_{k=1}^{n}X_{k}\right] = \frac{1}{n}\operatorname{Var}[X_{1}].$$

Szkic dowodu: (c) NaleÅ¼y po prostu rozpisaÄ‡ definicje. (d) NierÃ³wnoÅ›Ä‡ Cauchy'ego-Schwarza. (e) Poprzednie Twierdzenie. (f) Kowariancja jest liniowa ze wzglÄ™du na kaÅ¼dy z argumentÃ³w. (g) Wynika z (f). (h) Wynika z

**A** Warunek Cov[X,Y] = 0 w ogÃ³lnoÅ›ci nie implikuje niezaleÅ¼noÅ›ci Xi Y.

- 9. W9 KOWARIANCJA, ZBIEÅ»NOÅšÄ† WEDÅUG PRAWDOPODOBIEÅƒSTWA I SPWL
- <span id="page-19-0"></span>(9.1)  $\blacksquare$  WspÃ³Å‚czynnikiem korelacji wektora (X,Y) (dla ktÃ³rego  $\mathbb{E}[X^2], \mathbb{E}[Y^2] < \infty$ ) nazywamy wielkoÅ›Ä‡

$$\rho(X,Y) = \frac{\operatorname{Cov}[X,Y]}{\sqrt{\operatorname{Var}[X]\operatorname{Var}[Y]}}.$$

- (9.2) **TW.** WÅ‚asnoÅ›ci korelacji.
  - (a)  $|\rho(X,Y)| < 1$ ,
  - (b)  $|\rho(X,Y)| = 1 \iff \mathbb{P}(X = aY + b) = 1$  dla pewnych staÅ‚ych  $a, b \in \mathbb{R}$ ,
  - (c) JeÅ›li X i Y sa niezaleÅ¼ne, to  $\rho(X,Y)=0$ .

Szkic dowodu: (a) i (c) wynikajÄ… z wÅ‚asnoÅ›ci kowariancji. (b) RÃ³wnoÅ›Ä‡ w nierÃ³wnoÅ›ci Cauchy'ego-Schwarza zachodzi wtedy i tylko wtedy, gdy funkcje sÄ… liniowo zaleÅ¼ne (Y jest funkcjÄ… liniowÄ… X).

A Z uwagi na drugÄ… i trzeciÄ… wÅ‚asnoÅ›Ä‡, wspÃ³Å‚czynnik korelacji jest interpretowany jako miara zaleÅ¼noÅ›ci liniowej.

(9.3)  $\blacksquare$  JeÅ›li Cov[X,Y] = 0, to powiemy, Å¼e zmienne losowe X i Y sÄ… nieskorelowane.

 $\Delta$  Zmienne niezaleÅ¼ne sÄ… nieskorelowane, ale nieskorelowane nie sÄ… niezaleÅ¼ne. Np. jeÅ›li  $X \sim N(0,1)$  to X i  $Y := X^2 - 1$  sÄ… nieskorelowane, ale oczywiÅ›cie sÄ… zaleÅ¼ne.

(9.4)  $\blacksquare$  MacierzÄ… kowariancji wektora  $\underline{X} = (X_1, \dots, X_n)$  nazywa

$$\Sigma(\underline{X}) = (\operatorname{Cov}[X_i, X_j])_{1 \le i, j \le n} = \begin{pmatrix} \operatorname{Var}[X_1] & \operatorname{Cov}[X_1, X_2] & \cdots & \operatorname{Cov}[X_1, X_n] \\ \operatorname{Cov}[X_1, X_2] & \operatorname{Var}[X_2] & \cdots & \operatorname{Cov}[X_2, X_n] \\ \vdots & & \ddots & \vdots \\ \operatorname{Cov}[X_1, X_n] & \operatorname{Cov}[X_2, X_n] & \cdots & \operatorname{Var}[X_n] \end{pmatrix}.$$

RÃ³wnowaÅ¼nie:  $\Sigma(\underline{X}) = \mathbb{E}\left[(\underline{X} - \mathbb{E}[\underline{X}]) \cdot (\underline{X} - \mathbb{E}[X])^{\top}\right]$ 

- (9.5) **TW.** WÅ‚asnoÅ›ci macierzy kowariancji.
  - (a)  $\Sigma(X)$  jest macierza symetryczna,
  - (b)  $\Sigma(\underline{X})$  jest macierzÄ… nieujemnie okreÅ›lonÄ….

Szkic dowodu: Macierz K jest nieujemnie okreÅ›lona, jeÅ›li dla kaÅ¼dego  $\underline{t} \in \mathbb{R}^n$  zachodzi

$$t^{\top} \cdot K \cdot t \ge 0.$$

Mamy

$$\underline{t}^{\top} \Sigma(\underline{X}) \underline{t} = \sum_{i=1}^{n} \sum_{j=1}^{n} t_i t_j \operatorname{Cov}[X_i, X_j] = \mathbb{E} \left[ \left( \sum_{i=1}^{n} t_i (X_i - \mathbb{E}[X_i]) \right)^2 \right].$$

(9.6)  $\mathbf{\Phi}_{\mathbf{a}}^{\mathbf{x}}$  JeÅ›li  $\underline{X} \sim \mathcal{N}_n(\underline{\mu}, \Sigma)$  dla  $\underline{\mu} \in \mathbb{R}^n$  oraz  $\Sigma \in \mathrm{Sym}_+(n)$ , to  $\mathbb{E}[\underline{X}] = \mu$  oraz  $\Sigma(\underline{X}) = \Sigma$ . Innymi sÅ‚owy, dla

$$f_{\underline{X}}(\underline{x}) = \frac{1}{(\sqrt{2\pi})^n \sqrt{\det(\Sigma)}} e^{-\frac{1}{2}(\underline{x} - \underline{\mu})^\top \cdot \Sigma^{-1} \cdot (\underline{x} - \underline{\mu})}, \qquad \underline{x} \in \mathbb{R}^n$$

mamy

$$\mathbb{E}[X_i] = \int_{\mathbb{R}^n} x_i f_{\underline{X}}(\underline{x}) d\underline{x} = \mu_i, \qquad i \in \{1, \dots, n\},$$

oraz

$$\Sigma(\underline{X})_{ij} = \operatorname{Cov}[X_i, X_j] = \int_{\mathbb{R}^n} (x_i - \mu_i)(x_j - \mu_j) f_{\underline{X}}(\underline{x}) d\underline{x} = \Sigma_{ij}, \quad i, j \in \{1, \dots, n\}.$$

Ponadto, rozkÅ‚ady brzegowe wektorÃ³w normalnych sÄ… normalne:

$$X_i \sim N(\mu_i, \Sigma_{ii}), \qquad i \in \{1, \dots, n\}$$

oraz ogÃ³lniej, dla  $A \subset \{1, \dots, n\},\$ 

$$\underline{X}_A := (X_i : i \in A) \sim \mathcal{N}_{|A|}(\mu_A, \Sigma_{AA})$$

gdzie  $\underline{\mu}_A = (\mu_i \colon i \in A)$  oraz  $\Sigma_{AA} = (\Sigma_{ij})_{i,j \in A}$ .

(9.7) Niech  $(X_n)_{n \geq 1}$  bÄ™dzie ciÄ…giem zmiennych losowych na  $(\Omega, \mathcal{F}, \mathbb{P})$ . Niech X bÄ™dzie zmiennÄ… losowÄ… na  $(\Omega, \mathcal{F}, \mathbb{P})$ . Powiemy, Å¼e  $(X_n)_{n\geq 1}$  jest zbieÅ¼ny wedÅ‚ug prawdopodobieÅ„stwa do zmiennej losowej X ( $\textcircled{\bullet}$   $X_n \stackrel{\mathbb{P}}{\longrightarrow} X$ ), jeÅ›li

$$\forall \ \varepsilon > 0$$
  $\lim_{n \to \infty} \mathbb{P}(|X_n - X| > \varepsilon) = 0.$ 

- (9.8)  $\triangle$  BezpoÅ›rednio z definicji wynika, Å¼e  $X_n \stackrel{\mathbb{P}}{\longrightarrow} X \iff |X_n X| \stackrel{\mathbb{P}}{\longrightarrow} 0 \iff X_n X \stackrel{\mathbb{P}}{\longrightarrow} 0.$
- (9.9)  $\overset{\bullet}{\bullet}$  JeÅ›li  $X_n \sim \mathrm{b}(1,1-\frac{1}{n}), \ n=1,2,\ldots,$  to  $X_n \stackrel{\mathbb{P}}{\longrightarrow} 1.$
- (9.10) **4** JeÅ›li  $X_n \sim b(n, p)$ , to

$$\mathbb{P}\left(\left|\frac{X_n}{n} - p\right| > \varepsilon\right) \le \frac{\operatorname{Var}[X_n]}{n^2 \varepsilon^2} = \frac{p(1-p)}{n \varepsilon^2} \to 0,$$

czyli  $\xrightarrow{X_n} \xrightarrow{\mathbb{P}} p$ .

(9.11) **LEM.** Granica wedÅ‚ug prawdopodobieÅ„stwa wyznaczona jest jednoznacznie, tzn. jeÅ›li  $X_n \stackrel{\mathbb{P}}{\longrightarrow} X$  oraz  $X_n \stackrel{\mathbb{P}}{\longrightarrow} Y$ , to  $\mathbb{P}(X=Y)=1$ .

Szkic dowodu:

$$\begin{split} \mathbb{P}(|X-Y|>\varepsilon) &\leq \mathbb{P}(|X_n-X|+|X_n-Y|>\varepsilon) \leq \mathbb{P}(\{|X_n-X|\geq \varepsilon/2\} \cup \{|X_n-Y|>\varepsilon/2\}) \\ &\leq \mathbb{P}(|X_n-X|\geq \varepsilon/2) + \mathbb{P}(|X_n-Y|>\varepsilon/2). \end{split}$$

(9.12) **LEM.** JeÅ›li  $X_n \stackrel{\mathbb{P}}{\longrightarrow} X$  oraz  $Y_n \stackrel{\mathbb{P}}{\longrightarrow} Y$ , to  $X_n + Y_n \stackrel{\mathbb{P}}{\longrightarrow} X + Y$ . Szkic dowodu:

$$\mathbb{P}(|X_n + Y_n - X - Y| > \varepsilon) \le \mathbb{P}(|X_n - X| + |Y_n - Y| > \varepsilon) \le \mathbb{P}(\{|X_n - X| > \varepsilon/2\} \cup \{|Y_n - Y| > \varepsilon/2\})$$
  
$$\le \mathbb{P}(|X_n - X| \ge \varepsilon/2) + \mathbb{P}(|Y_n - Y| > \varepsilon/2).$$

Powiemy, Å¼e ciÄ…g  $(X_n)_{n\geq 1}$  speÅ‚nia <u>SÅ‚abe Prawo Wielkich Liczb</u> (SPWL), jeÅ›li

$$\frac{\sum_{k=1}^{n} (X_k - \mathbb{E}[X_k])}{n} \stackrel{\mathbb{P}}{\longrightarrow} 0.$$

 $oldsymbol{\Delta}$  JeÅ›li granica  $\lim_{n\to\infty} \frac{\sum_{k=1}^n \mathbb{E}[X_k]}{n}$  istnieje i jest skoÅ„czona, to SPWL mÃ³wi nam, Å¼e

$$\frac{\sum_{k=1}^{n} X_k}{n} \xrightarrow[n \to \infty]{\mathbb{P}} \lim_{n \to \infty} \frac{\sum_{k=1}^{n} \mathbb{E}[X_k]}{n}.$$

W szczegÃ³lnoÅ›ci, jeÅ›li  $\mathbb{E}[X_k] = \mu$ dla  $k = 1, 2, \ldots,$  to SPWL implikuje

$$\frac{\sum_{k=1}^{n} X_k}{n} \stackrel{\mathbb{P}}{\longrightarrow} \mu.$$

(9.14) TW. (SPWL Markowa) JeÅ›li speÅ‚niony jest warunek Markowa, tzn.

$$\lim_{n\to\infty}\frac{1}{n^2}\mathrm{Var}\left[\sum_{k=1}^n X_k\right]=0,$$

to dla  $(X_n)_{n\geq 1}$  zachodzi SPWL.

Szkic dowodu: NierÃ³wnoÅ›Ä‡ Czebyszewa.

**A** PowyÅ¼sze twierdzenie stosuje siÄ™ tylko do zmiennych losowych, dla ktÃ³rych drugi moment jest skoÅ„czony  $(\mathbb{E}[X_k^2] < \infty, k = 1, 2, \ldots)$ .

(9.15) **TW.** (SPWL Chinczyna) JeÅ›li  $(X_n)_{n\geq 1}$  majÄ… takie same rozkÅ‚ady, sÄ… parami niezaleÅ¼ne oraz  $\mathbb{E}[|X_1|] < \infty$ , to

$$\frac{\sum_{k=1}^{n} X_k}{n} \stackrel{\mathbb{P}}{\longrightarrow} \mathbb{E}[X_1].$$

Szkic dowodu: Dla  $n \in \mathbb{N}$  zdefiniujmy  $Y_n = X_n \mathbb{1}_{|X_n| \leq n}$ . Wtedy

$$\sum_{n=1}^{\infty} \mathbb{P}(X_n \neq Y_n) = \sum_{n=1}^{\infty} \mathbb{P}(|X_n| > n) = \sum_{n=1}^{\infty} \mathbb{P}(|X_n| > n) = \sum_{n=1}^{\infty} \mathbb{P}(|X_1| > n) \leq \int_0^{\infty} \mathbb{P}(|X_1| > t) dt = \mathbb{E}[|X_1|] < \infty.$$

Zatem, z lematu Borela-Cantelliego,  $\mathbb{P}(\limsup_n \{X_n \neq Y_n\}) = 0$ , czyli  $\mathbb{P}(\liminf_n \{X_n = Y_n\}) = 1$ . StÄ…d wynika, Å¼e (wystarczy zauwaÅ¼yÄ‡, Å¼e licznik jest ograniczony)

$$\frac{\sum_{k=1}^{n} (X_k - Y_k)}{n} \stackrel{\mathbb{P}}{\longrightarrow} 0.$$

Wystarczy zatem pokazaÄ‡, Å¼e zachodzi SPWL dla ciÄ…gu  $(Y_n)_n$ . Zastosujemy SPWL Markowa, sprawdzamy warunek Markowa:

$$\frac{\operatorname{Var}[\sum_{k=1}^{n} Y_{k}]}{n^{2}} \stackrel{\text{nzl}}{=} \frac{\sum_{k=1}^{n} \operatorname{Var}[Y_{k}]}{n^{2}} \leq \frac{\sum_{k=1}^{n} \mathbb{E}[Y_{k}^{2}]}{n^{2}} = \frac{\sum_{k=1}^{n} \mathbb{E}[X_{k}^{2} \mathbb{1}_{|X_{k}| \leq k}]}{n^{2}} \leq \frac{n \mathbb{E}[X_{1}^{2} \mathbb{1}_{|X_{1}| \leq n}]}{n^{2}}$$

$$= \frac{1}{n} \left( \mathbb{E}[X_{1}^{2} \mathbb{1}_{|X_{1}| < n^{1/3}}] + \mathbb{E}[X_{1}^{2} \mathbb{1}_{|X_{1}| \in [n^{1/3}, n]}] \right) \leq \frac{1}{n} \left( n^{2/3} + n \mathbb{E}[|X_{1}| \mathbb{1}_{|X_{1}| > n^{1/3}}] \right) \stackrel{n \to \infty}{\longrightarrow} 0.$$

Ostatecznie,

$$\lim_{n \to \infty} \frac{\sum_{k=1}^{n} \mathbb{E}[Y_k]}{n} = \mathbb{E}[X_1].$$

10. W10 - ZbieÅ¼noÅ›Ä‡ z prawdopodobieÅ„stwem 1 (MPWL), w  $L_p$  i wedÅ‚ug rozkÅ‚adu

<span id="page-21-0"></span>(10.1) Niech  $(X_n)_{n\geq 1}$  bÄ™dzie ciÄ…giem zmiennych losowych na  $(\Omega, \mathcal{F}, \mathbb{P})$ . Niech X bÄ™dzie zmiennÄ… losowÄ… na  $(\Omega, \mathcal{F}, \mathbb{P})$ . Powiemy, Å¼e  $(X_n)_{n\geq 1}$  jest zbieÅ¼ny z prawdopodobieÅ„stwem 1 do zmiennej losowej X ( $\textcircled{\bullet}$   $X_n \stackrel{1}{\longrightarrow} X$ ), jeÅ›li

$$\mathbb{P}\left(\left\{\omega \in \Omega \colon \lim_{n \to \infty} X_n(\omega) = X(\omega)\right\}\right) = \mathbb{P}\left(\lim_{n \to \infty} X_n = X\right) = 1.$$

â–² ZbieÅ¼noÅ›Ä‡ z prawdopodobieÅ„stwem 1 bywa nazywana zbieÅ¼noÅ›ciÄ… prawie na pewno.

(10.2) **LEM.** Warunki rÃ³wnowaÅ¼ne zbieÅ¼noÅ›ci z prawdopodobieÅ„stwem 1.

$$X_{n} \xrightarrow{1} X \iff \mathbb{P}\left(\left\{\omega \colon \forall \varepsilon > 0 \; \exists N > 0 \; \forall n > N \; | X_{n}(\omega) - X(\omega)| \leq \varepsilon\right\}\right) = 1$$

$$\iff \mathbb{P}\left(\cap_{\varepsilon > 0} \cup_{N > 0} \cap_{n > N} \left\{|X_{n} - X| \leq \varepsilon\right\}\right) = 1$$

$$\iff \forall \varepsilon > 0 \; \mathbb{P}\left(\bigcup_{N > 0} \cap_{n > N} \left\{|X_{n} - X| \leq \varepsilon\right\}\right) = 1$$

$$\iff \forall \varepsilon > 0 \; \mathbb{P}\left(\liminf_{n} \left\{|X_{n} - X| \leq \varepsilon\right\}\right) = 1$$

$$\iff \forall \varepsilon > 0 \; \mathbb{P}\left(\limsup_{n} \left\{|X_{n} - X| > \varepsilon\right\}\right) = 0$$

$$\iff \forall \varepsilon > 0 \; \lim_{N \to \infty} \mathbb{P}\left(\cup_{n > N} \left\{|X_{n} - X| > \varepsilon\right\}\right) = 0$$

$$\iff \forall \varepsilon > 0 \; \lim_{N \to \infty} \mathbb{P}\left(\sup_{n > N} |X_{n} - X| > \varepsilon\right) = 0$$

$$\iff \forall \varepsilon > 0 \; \lim_{N \to \infty} \mathbb{P}\left(\sup_{n > N} |X_{n} - X| > \varepsilon\right) = 0$$

$$\iff \sup_{n > N} |X_{n} - X| \xrightarrow{\mathbb{P}} 0, \qquad (N \to \infty).$$

(10.3) **TW.** Niech  $(X_n)_n$  bÄ™dzie ciÄ…giem zmiennych losowych na  $(\Omega, \mathcal{F}, \mathbb{P})$ . Wtedy

$$X_n \xrightarrow{1} X \implies X_n \xrightarrow{\mathbb{P}} X.$$

Szkic dowodu: Wniosek z warunkÃ³w rÃ³wnowaÅ¼nych zbieÅ¼noÅ›ci z prawdopodobieÅ„stwem 1.

- (10.4) A Odwrotna implikacja nie jest prawdziwa.
  - Niech  $(A_n)_{n\in\mathbb{N}}$  bÄ™dzie ciÄ…giem niezaleÅ¼nych zdarzeÅ„ takich, Å¼e  $\lim_{n\to\infty}\mathbb{P}(A_n)=0$  oraz  $\sum_{n=1}^{\infty}\mathbb{P}(A_n)=\infty$ . Zdefiniujmy  $X_n(\omega) := \mathbb{1}_{A_n}(\omega)$ . CiÄ…g  $X_n$  zbiega wedÅ‚ug prawdopodobieÅ„stwa do 0, ale nie z prawdopodobieÅ„stwem 1. Faktycznie dla  $\varepsilon \in (0,1), \mathbb{P}(|X_n-0|>\varepsilon)=\mathbb{P}(A_n)\to 0.$  Z drugiej strony, z zaÅ‚oÅ¼eÅ„ o ciÄ…gu  $(A_n)_n$  oraz Lematu Borela-Cantelli'ego II wynika, Å¼e  $\mathbb{P}(\limsup_n A_n) = 1$ . Ponadto, dla  $\varepsilon \in (0,1)$ ,  $\mathbb{P}\left(\limsup_{n}\{|X_n-0|>\varepsilon\}\right)=\mathbb{P}\left(\limsup_{n}A_n\right)=1$ , co przeczy zbieÅ¼noÅ›ci z prawdopodobieÅ„stwem 1.  $\mathbb{P}$ -prawie na pewno,  $X_n(\omega)$  jest niezbieÅ¼nym ciÄ…giem zer i jedynek.
- (10.5) **LEM.** Warunki dostateczne zbieÅ¼noci z prawdopodobieÅ„stwem 1.

  - (a) JeÅ›li  $\sum_{n=1}^{\infty} \mathbb{P}(|X_n X| > \varepsilon) < \infty$  dla kaÅ¼dego  $\varepsilon > 0$ , to  $X_n \xrightarrow{1} X$ . (b) JeÅ›li  $\sum_{n=1}^{\infty} \mathbb{E}[|X_n X|^p] < \infty$  dla pewnego p > 0, to  $X_n \xrightarrow{1} X$ .

Szkic dowodu: (a) z podaddytywnoÅ›ci mamy

$$\forall \varepsilon > 0 \lim_{N \to \infty} \mathbb{P}\left(\bigcup_{n > N} \{|X_n - X| > \varepsilon\}\right) \le \lim_{N \to \infty} \sum_{n > N} \mathbb{P}\left(\{|X_n - X| > \varepsilon\}\right) = 0.$$

- (b) Z nierÃ³wnoÅ›ci Markowa mamy  $\mathbb{P}(|X_n X| > \varepsilon) \leq \mathbb{E}[|X_n X|^p]/\varepsilon^p$ .
- (10.6)  $\blacksquare$  Powiemy, Å¼e ciÄ…g  $(X_n)_{n\geq 1}$  speÅ‚nia Mocne Prawo Wielkich Liczb (MPWL), jeÅ›li

$$\frac{\sum_{k=1}^{n} (X_k - \mathbb{E}[X_k])}{n} \xrightarrow{1} 0.$$

(10.7) **TW.** (MPWL KoÅ‚mogorowa I) Niech  $(X_n)_{n>1}$  bÄ™dzie ciÄ…giem niezaleÅ¼nych zmiennych losowych dla ktÃ³rego  $\mathbb{E}[X_n^2] < \infty$ ,  $n \in \mathbb{N}$ . JeÅ›li speÅ‚niony jest warunek KoÅ‚mogorowa, tzn.

$$\sum_{n=1}^{\infty} \frac{\operatorname{Var}[X_n]}{n^2} < \infty$$

to dla ciÄ…gu  $(X_n)_{n>1}$  zachodzi MPWL.

(10.8) **TW.** (MPWL KoÅ‚mogorowa II) Niech  $(X_n)_{n>1}$  bÄ™dzie ciÄ…giem i.i.d. JeÅ›li  $\mathbb{E}[|X_1|] < \infty$ , to

$$\frac{\sum_{k=1}^{n} X_k}{n} \stackrel{1}{\longrightarrow} \mathbb{E}[X_1].$$

(10.9)  $\overset{\bullet}{\mathbf{x}}$  Niech  $(X_n)_{n\geq 1}$  bÄ™dzie ciÄ…giem i.i.d. o dystrybuancie F. Niech  $F_n$  bÄ™dzie dystrybuantÄ… empirycznÄ… zbudowanÄ… w oparciu o  $(X_k)_{k=1}^n$ , tzn.  $\hat{F}_n(t) := \frac{1}{n} \sum_{k=1}^n \mathbb{1}_{(-\infty,t]}(X_k)$ . Dla ciÄ…gu  $(\mathbb{1}_{(-\infty,t]}(X_k))_{k>1}$  zachodzi MPWL, bo jest to ciÄ…g i.i.d. o skoÅ„czonym pierwszym momencie. Zatem,

$$\hat{F}_n(t) \xrightarrow{1} \mathbb{E}[\mathbb{1}_{(-\infty,t]}(X_1)] = \mathbb{P}(X_1 \le t) = F(t), \qquad t \in \mathbb{R}.$$

A Zachodzi znacznie mocniejszy wynik, znany jako Twierdzenie Gliwienki-Cantellego. Przy zaÅ‚oÅ¼eniach jak powyÅ¼ej zachodzi

$$\sup_{t \in \mathbb{R}} |\hat{F}_n(t) - F(t)| \stackrel{1}{\longrightarrow} 0.$$

(10.10)  $\blacksquare$  Niech  $(X_n)_{n\geq 1}$  bÄ™dzie ciÄ…giem zmiennych losowych na  $(\Omega, \mathcal{F}, \mathbb{P})$ . Niech X bÄ™dzie zmiennÄ… losowÄ… na  $(\Omega, \mathcal{F}, \mathbb{P})$ . Powiemy, Å¼e  $(X_n)_{n\geq 1}$  jest zbieÅ¼ny w (przestrzeni)  $L_p$ , p>0, do zmiennej losowej X (a  $X_n \xrightarrow{L_p} X$ ), jeÅ›li  $\mathbb{E}[|X_n|^p] < \infty, \, \mathbb{E}[|X|^p] < \infty \text{ oraz}$ 

$$\lim_{n \to \infty} \mathbb{E}[|X_n - X|^p] = 0.$$

 $\begin{array}{cccccccccccccccccccccccccccccccccccc$ 

Szkic dowodu: Obie zbieÅ¼noÅ›ci implikujÄ… zbieÅ¼noÅ›Ä‡ wedÅ‚ug prawdopodobieÅ„stwa. Granica wedÅ‚ug prawdopodobieÅ„stwa jest z kolei wyznaczona jednoznacznie.

(10.13)  $\triangle$  ZbieÅ¼noÅ›Ä‡ z prawdopodobieÅ„stwem 1 w ogÃ³lnoÅ›ci nie implikuje zbieÅ¼noÅ›ci w  $L_p$ . (  $\clubsuit$  )

**TW.** (Twierdzenie Lebesgue'a o zbieÅ¼noÅ›ci zdominowanej) Niech  $X_n \xrightarrow{1} X$  oraz  $|X_n(\omega)| \leq Y(\omega)$ , gdzie Y jest caÅ‚kowalnÄ… zmiennÄ… losowÄ… (czyli  $\mathbb{E}[Y] < \infty$ ). Wtedy

$$\lim_{n \to \infty} \mathbb{E}[X_n] = \mathbb{E}[\lim_{n \to \infty} X_n] = \mathbb{E}[X].$$

(10.14) Wniosek: Niech  $X_n \stackrel{1}{\longrightarrow} X$  oraz niech f bÄ™dzie funkcjÄ… ciÄ…gÅ‚Ä… i ograniczonÄ…. Wtedy z ograniczonoÅ›ci f oraz Twierdzenia Lebesgue'a o zbieÅ¼noÅ›ci zdominowanej mamy

$$\lim_{n \to \infty} \mathbb{E}[f(X_n)] = \mathbb{E}[\lim_{n \to \infty} f(X_n)].$$

Z kolei z ciÄ…gÅ‚oÅ›ci funkcji f,

$$\mathbb{E}[\lim_{n \to \infty} f(X_n)] = \mathbb{E}[f(\lim_{n \to \infty} X_n)] = \mathbb{E}[f(X)].$$

(10.15) Powiemy, Å¼e ciÄ…g zmiennych losowych  $(X_n)_n$  zbiega wedÅ‚ug rozkÅ‚adu do zmiennej losowej X ( $\textcircled{\bullet}$   $X_n \stackrel{d}{\longrightarrow} X$ ),

$$\forall f \in C_b(\mathbb{R}) \quad \lim_{n \to \infty} \mathbb{E}[f(X_n)] = \mathbb{E}[f(X)],$$

gdzie  $C_b(\mathbb{R})$  oznacza zbiÃ³r funkcji ciÄ…gÅ‚ych i ograniczonych na  $\mathbb{R}$ .

 $\triangle$  Co do zasady, kaÅ¼da ze zmiennych  $X_n$  moÅ¼e byÄ‡ okreÅ›lona na innej przestrzeni probabilistycznej  $(\Omega, \mathcal{F}, \mathbb{P})$ . PowyÅ¼szy warunek zaleÅ¼y wyÅ‚Ä…cznie od rozkÅ‚adÃ³w X'Ã³w: mamy  $\mathbb{E}[f(X_n)] = \int_{\mathbb{R}} f(t) \mathbb{P}_{X_n}(dt)$ .

- Odpowiednikiem powyÅ¼szej zbieÅ¼noÅ›ci w analizie funkcjonalnej jest tzw. sÅ‚aba zbieÅ¼noÅ›Ä‡ z \*.
- (10.16)  $\mathbf{A}_{n}^{*}$  Niech  $X_{n} \sim \mathrm{U}(\{0,1,\ldots,n-1\})$ . Dla  $f \in C_{b}(\mathbb{R})$  mamy

$$\lim_{n \to \infty} \mathbb{E}\left[f\left(\frac{X_n}{n}\right)\right] = \lim_{n \to \infty} \sum_{k=1}^{n-1} f\left(\frac{k}{n}\right) \frac{1}{n} = \int_0^1 f(x) dx,$$

gdzie po prawej stronie mamy caÅ‚kÄ™ Riemanna. Z drugiej strony, zauwaÅ¼my, Å¼e jeÅ›li  $X \sim \mathrm{U}([0,1])$ , to  $\mathbb{E}[f(X)] =$  $\int_0^1 f(x)dx$ , gdzie mamy caÅ‚kÄ™ Lebesgue'a. PoniewaÅ¼ dla Å‚adnych funkcji, caÅ‚ka Riemanna i Lebesgue'a siÄ™ pokrywajÄ…, to z definicji mamy

$$\frac{X_n}{n} \xrightarrow{d} U \sim \mathrm{U}([0,1].$$

 $\blacktriangle$  Zapis  $\frac{X_n}{n} \stackrel{d}{\longrightarrow} U([0,1])$  nie ma sensu.

<span id="page-23-0"></span>

RozwaÅ¼my ciÄ…g niezaleÅ¼nych zmiennych  $(X_n)_{n\geq 2}$  o rozkÅ‚adach

$$\mathbb{P}(X_n = \pm n) = \frac{1}{2}p_n, \qquad \mathbb{P}(X_n = 0) = 1 - p_n.$$

Wtedy mamy  $\mathbb{E}[X_n] = 0$  oraz  $\operatorname{Var}(X_n) = n^2 p_n$ .

RozwaÅ¼my 3 konkretne wyboru ciÄ…gu  $(p_n)_n$ .

I 
$$p_n = \frac{1}{n^{\alpha}}$$
 dla pewnego  $\alpha > 1$ ,  
II  $p_n = \frac{1}{n \log(n)}$ ,

II 
$$p_n = \frac{n}{n \log(n)}$$
,

III 
$$p_n = \frac{1}{n}$$
.

PokaÅ¼emy, Å¼e

- a) dla ciÄ…gu I zachodzi MPWL, a wiÄ™c rÃ³wnieÅ¼ zachodzi SPWL
- b) dla ciagu II zachodzi SPWL, ale nie zachodzi MPWL,
- c) dla ciÄ…gu III nie zachodzi SPWL, a wiÄ™c teÅ¼ nie zachodzi MPWL.

Tym samym, definiujÄ…c $Y_n=\frac{\sum_{k=1}^n(X_k-\mathbb{E}[X_k])}{n}=\frac{\sum_{k=1}^nX_k}{n},$ mamy

- a)  $Y_n \stackrel{1}{\longrightarrow} 0$ ,
- b)  $Y_n \stackrel{\mathbb{P}}{\longrightarrow} 0 \text{ oraz } Y_n \not\stackrel{1}{\longrightarrow} 0$ ,
- c)  $Y_n \not\stackrel{\mathbb{P}}{\longleftrightarrow} 0$ .
- a) Dla ciÄ…gu I zachodzi MPWL: rzeczywiÅ›cie, speÅ‚niony jest wtedy warunek KoÅ‚mogorowa:

$$\sum_{n=1}^{\infty} \frac{\text{Var}(X_n)}{n^2} = \sum_{n=1}^{\infty} \frac{n^2 p_n}{n^2} = \sum_{n=1}^{\infty} \frac{1}{n^{\alpha}} < \infty,$$

poniewaÅ¼  $\alpha > 1$ .

b) Dla ciÄ…gu II zachodzi SPWL, ale nie zachodzi MPWL: sprawdzamy najpierw warunek Markowa:

$$\lim_{n \to \infty} \frac{1}{n^2} \text{Var}(X_1 + \ldots + X_n) = \lim_{n \to \infty} \frac{\sum_{k=1}^n k^2 p_k}{n^2}.$$

ZauwaÅ¼my, Å¼e

$$\frac{n^2 p_n}{n^2 - (n-1)^2} = \frac{n^2 \frac{1}{n \log(n)}}{2n - 1} \to 0, \qquad n \to \infty,$$

wiÄ™c z Twierdzenia Stoltza mamy rÃ³wnieÅ¼  $\frac{\sum_{k=1}^{n} k^2 p_k}{n^2} \to 0$ , czyli warunek Markowa jest speÅ‚niony.

Dla tego ciÄ…gu nie jest speÅ‚nione MPWL: przeprowadzamy rozumowanie nie wprost. Gdyby MPWL zachodziÅ‚o, to definiujÄ…c  $S_n := \sum_{k=1}^n X_k$ , mamy

$$\frac{X_n}{n} = \frac{S_n - S_{n-1}}{n} = \frac{S_n}{n} + \frac{n-1}{n} \frac{S_{n-1}}{n-1} \xrightarrow{1} 0,$$

poniewaÅ¼ oba skÅ‚adniki po prawej stronie zbiegajÄ… do 0 z prawdopodobieÅ„stwem 1. Oznacza to, Å¼e zbieÅ¼noÅ›Ä‡ z p-stwem 1 ciÄ…gu  $(X_n/n)_n$  do 0 jest warunkiem koniecznym MPWL. PokaÅ¼emy, Å¼e ciÄ…g  $(X_n/n)_n$  nie zbiega z prawdopodobnieÅ„stwem 1, co bÄ™dzie przeczyÅ‚o zachodzeniu MPWL. W tym celu udowodnimy nastÄ™pujÄ…cy lemat.

**LEM.** Niech  $(Y_n)_{n\geq 1}$  bÄ™dzie ciÄ…giem niezaleÅ¼nych zmiennych losowych. Wtedy

$$Y_n \xrightarrow{1} 0 \qquad \Longleftrightarrow \qquad \forall \varepsilon > 0 \quad \sum_{n=1}^{\infty} \mathbb{P}(|Y_n| > \varepsilon) < \infty.$$

DowÃ³d. DostatecznoÅ›Ä‡ powyÅ¼szego warunku wynika z **LEM.** (1.1) a). PokaÅ¼emy teraz koniecznoÅ›Ä‡. Ustalmy  $\varepsilon > 0$  oraz zauwaÅ¼my, Å¼e z niezaleÅ¼noÅ›ci elementÃ³w ciÄ…gu  $(Y_n)_n$  wynika, Å¼e zdarzenia  $A_n := \{|Y_n| > \varepsilon\}$  sÄ… niezaleÅ¼ne. Zatem, z lematÃ³w Borela-Cantellego, wynika, Å¼e

$$\sum_{k=1}^{\infty} \mathbb{P}(A_n) < \infty \qquad \iff \qquad \mathbb{P}(\limsup_{n} A_n) = 0.$$

Ale warunek  $\mathbb{P}(\limsup_n\{|Y_n|>\varepsilon\})=0$  jest rÃ³wnowaÅ¼ny (patrz poprzedni wykÅ‚ad) stwierdzeniu  $Y_n\stackrel{1}{\longrightarrow}0.$ 

Wracamy do (b): chcemy pokazaÄ‡, Å¼e ciÄ…g  $(X_n/n)_n$  nie zbiega do 0 z p-stwem 1. Mamy dla  $\varepsilon \in (0,1)$ ,

$$\sum_{n=1}^{\infty} \mathbb{P}\left(\left|\frac{X_n}{n}\right| > \varepsilon\right) = \sum_{n=1}^{\infty} (1 - \mathbb{P}(X_n = 0)) = \sum_{n=1}^{\infty} p_n = \sum_{n=1}^{\infty} \frac{1}{n \log(n)} = \infty.$$

gdzie ostatniÄ… rÃ³wnoÅ›Ä‡ Å‚atwo widaÄ‡ z caÅ‚kowego kryterium zbieÅ¼noÅ›ci szeregÃ³w. Z wczeÅ›niejszego lematu wnioskujemy, Å¼e  $\frac{X_n}{n} \not \longrightarrow 0$ , a wiÄ™c MPWL nie zachodzi.

c) Dla ciÄ…gu III nie zachodzi SPWL, wiÄ™c tym bardziej MPWL. Z rachunku poczynionego w b), jasne jest Å¼e nie zachodzi MPWL. Argument dla niezachodzenia SPWL nie jest zbyt prosty, wiÄ™c go nie podajÄ™ (naleÅ¼y oszacowaÄ‡ z doÅ‚u  $\mathbb{P}(|Y_n| > \varepsilon)$  - moÅ¼na w tym celu skorzystaÄ‡ z "dolnej" nierÃ³wnoÅ›ci Czebyszewa (ktÃ³rej nie znamy)).

Dla ciÄ…gÃ³w I-III przeprowadzamy symulacje: generujemy 10<sup>3</sup> niezaleÅ¼nych trajektorii (czyli wykresÃ³w [10<sup>4</sup> ] 3 n 7â†’ X1+...+X<sup>n</sup> n ) i rysujemy na wspÃ³lnym wykresie. W I bierzemy Î± = 3/2 > 1.

![](_page_25_Figure_3.jpeg)

#### Wnioski:

(1) Z definicji zbieÅ¼noÅ›ci <sup>1</sup> âˆ’â†’ wiemy Å¼e jeÅ›li Y<sup>n</sup> 1 âˆ’â†’ 0, to dla P prawie kaÅ¼dej Ï‰ i dowolnego Îµ > 0 istnieje N = N(Ï‰, Îµ), Å¼e |Yn(Ï‰)| â‰¤ Îµ dla n â‰¥ N. Na wykresie I rzeczywiÅ›cie widzimy, Å¼e kaÅ¼da z trajektorii osobno zdaje siÄ™ zbiegaÄ‡ do 0.

- (2) Z definicji <sup>P</sup> âˆ’â†’ wiemy, Å¼e P(|Yn| > Îµ) musi maleÄ‡ do 0 gdy n â†’ âˆ. Nie znaczy to jednak, Å¼e wszystkie trajektorie muszÄ… zbiegaÄ‡ do 0. Na wykresie II widzimy, Å¼e wraz ze wzrostem n, coraz mniej trajektorii skacze.
- (3) TrochÄ™ nie widaÄ‡ by coÅ› siÄ™ zmieniaÅ‚o z n na wykresie III.

#### 11. W11 - ZbieÅ¼noÅ›Ä‡ wedÅ‚ug rozkÅ‚adu ciÄ…g dalszy

<span id="page-26-0"></span>(11.1) TW. Niech (Xn)nâ‰¥<sup>1</sup> bÄ™dzie ciÄ…giem zmiennych losowych oraz niech (Fn)nâ‰¥<sup>1</sup> bÄ™dzie ciÄ…giem odpowiadajÄ…cych im dystrybuant.

$$X_n \xrightarrow{d} X \qquad \Longleftrightarrow \qquad \lim_{n \to \infty} F_n(t) = F_X(t) \quad \forall t \in C(F_X),$$

gdzie C(FX) oznacza zbiÃ³r punktÃ³w ciÄ…gÅ‚oÅ›ci dystrybuanty FX.

Szkic dowodu: Najpierw =â‡’ .

Ustalmy 
$$\varepsilon > 0, t \in \mathbb{R}$$
 oraz zdefiniujmy  $f_+(x) = \begin{cases} 1, & x < t \\ 1 + \frac{t-x}{\varepsilon}, & x \in [t, t+\varepsilon] \text{ (rysunek jest pomocny). OczywiÅ›cie} \\ 0, & x > t + \varepsilon \end{cases}$ 

f<sup>+</sup> âˆˆ Cb(R) oraz

$$\mathbb{1}_{(-\infty,t]}(x) \le f_+(x) \le \mathbb{1}_{(-\infty,t+\varepsilon]}(x).$$

Zatem,

$$\limsup_{n \to \infty} F_n(t) = \limsup_{n \to \infty} \int_{\mathbb{R}} \mathbb{1}_{(-\infty, t]}(x) \mathbb{P}_{X_n}(dx) \le \limsup_{n \to \infty} \int_{\mathbb{R}} f_+(x) \mathbb{P}_{X_n}(dx)$$
$$= \int_{\mathbb{R}} f_+(x) \mathbb{P}_X(dx) \le \int_{\mathbb{R}} \mathbb{1}_{(-\infty, t+\varepsilon]}(x) \mathbb{P}_X(dx) = F_X(t+\varepsilon)$$

Z dowolnoÅ›ci Îµ > 0 oraz prawostronnej ciÄ…gÅ‚oÅ›ci F<sup>X</sup> mamy lim supnâ†’âˆ Fn(t) â‰¤ FX(t) dla kaÅ¼dego t âˆˆ R. Niech fâˆ’(x) := f+(x + Îµ). Ponownie f<sup>âˆ’</sup> âˆˆ Cb(R) oraz

$$\mathbb{1}_{(-\infty,t-\varepsilon]}(x) \le f_{-}(x) \le \mathbb{1}_{(-\infty,t]}(x).$$

Wtedy

$$\begin{aligned} & \liminf_{n \to \infty} F_n(t) = \liminf_{n \to \infty} \int_{\mathbb{R}} \mathbbm{1}_{(-\infty,t]}(x) \mathbb{P}_{X_n}(dx) \geq \liminf_{n \to \infty} \int_{\mathbb{R}} f_-(x) \mathbb{P}_{X_n}(dx) \\ & = \int_{\mathbb{R}} f_-(x) \mathbb{P}_X(dx) \geq \int_{\mathbb{R}} \mathbbm{1}_{(-\infty,t-\varepsilon]}(x) \mathbb{P}_X(dx) = F_X(t-\varepsilon). \end{aligned}$$

Z dowolnoÅ›ci Îµ > 0, mamy lim infnâ†’âˆ Fn(t) â‰¥ FX(tâˆ’) dla kaÅ¼dego t âˆˆ R. PodsumowujÄ…c, dla kaÅ¼dego x âˆˆ R mamy

$$F_X(x-) \le \liminf_{n \to \infty} F_n(x) \le \limsup_{n \to \infty} F_n(x) \le F_X(x).$$

JeÅ›li x âˆˆ C(Fx), to FX(xâˆ’) = FX(x) oraz otrzymujemy implikacjÄ™ w prawÄ… stronÄ™. Teraz â‡= . ZauwaÅ¼my, Å¼e dla f âˆˆ Cb(R) mamy

$$\int_{\mathbb{R}} f(x) \mathbb{P}_{X_n}(dx) = \int_{(-\infty, -M) \cup (M, \infty)} f(x) \mathbb{P}_{X_n}(dx) + \int_{[-M, M]} f(x) \mathbb{P}_{X_n}(dx)$$

oraz pierwsza caÅ‚ka dla duÅ¼ych n moÅ¼e byÄ‡ ograniczona przez c P(|X| > M) dla pewnej staÅ‚ej c (zaleÅ¼nej tylko od funkcji f). DobierajÄ…c M dostatecznie duÅ¼e, widzimy, Å¼e pierwsza caÅ‚ka jest dowolnie maÅ‚a. Z kolei, funkcje ciÄ…gÅ‚e na przedziale zwartym sÄ… jednostajnie ciÄ…gÅ‚e i moÅ¼na jest jednostajnie aproksymowaÄ‡ funkcjami prostymi, ktÃ³rych zbieÅ¼noÅ›Ä‡ szybko wynika ze zbieÅ¼noÅ›ci dystrybuant.

- (11.2) 3 Przyjmijmy, Å¼e limnâ†’âˆ P(X<sup>n</sup> â‰¤ t) = 1(0,âˆ)(t) dla t âˆˆ R. Czy ciÄ…g (Xn)<sup>n</sup> zbiega wedÅ‚ug rozkÅ‚adu? JeÅ›li tak, to do jakiej granicy?
- (11.3) 3 Niech X<sup>n</sup> âˆ¼ U({0, 1, . . . , n âˆ’ 1}). Wtedy dla t âˆˆ [0, 1) z twierdzenia o 3 ciÄ…gach mamy

$$F_{X_n/n}(t) = \frac{\lfloor nt \rfloor + 1}{n} \xrightarrow{n \to \infty} t = F_{\mathrm{U}([0,1])}(t),$$

czyli <sup>X</sup><sup>n</sup> n d âˆ’â†’ U âˆ¼ U([0, 1].

(11.4) 3 (Twierdzenie Poissona) Niech X<sup>n</sup> âˆ¼ b(n, pn), gdzie limnâ†’âˆ np<sup>n</sup> = Î» > 0. Wtedy X<sup>n</sup> d âˆ’â†’ X âˆ¼ Pois(Î»). (11.5) **LEM.** JeÅ›li  $X_n \stackrel{\mathbb{P}}{\longrightarrow} X$ , to  $X_n \stackrel{d}{\longrightarrow} X$ .

â–² Implikacja odwrotna nie jest (w ogÃ³lnoÅ›ci) prawdziwa.

Szkic dowodu: WeÅºmy  $t \in C(F_X)$  i  $\varepsilon > 0$ . Mamy

$$F_{X_n}(t) = \mathbb{P}(X_n \le t, |X_n - X| \le \varepsilon) + \mathbb{P}(X_n \le t, |X_n - X| > \varepsilon).$$

StÄ…d,

$$F_{X_n}(t) \le \mathbb{P}(X - \varepsilon \le t, |X_n - X| \le \varepsilon) + \mathbb{P}(|X_n - X| > \varepsilon) \le F_X(t + \varepsilon) + \mathbb{P}(|X_n - X| > \varepsilon).$$

Zatem,  $\limsup_{n\to\infty} F_{X_n}(t) \leq F_X(t+\varepsilon)$  dla dowolnego  $\varepsilon > 0$ , a stÄ…d  $\limsup_{n\to\infty} F_{X_n}(t) \leq F_X(t+\varepsilon) = F_X(t)$  (z prawostronnej ciÄ…gÅ‚oÅ›ci  $F_X$ ).

Podobnie od doÅ‚u,

$$F_{X_n}(t) \ge \mathbb{P}(X + \varepsilon \le t, |X_n - X| \le \varepsilon) \ge F_X(t - \varepsilon) - \mathbb{P}(|X_n - X| > \varepsilon).$$

StÄ…d,  $\liminf_{n\to\infty} F_{X_n}(t) \geq F_X(t-\varepsilon)$  dla  $\varepsilon > 0$ . PrzechodzÄ…c z  $\varepsilon \to 0$  oraz korzystajÄ…c z faktu, Å¼e  $t \in C(F_X)$  otrzymujemy, Å¼e  $\liminf_{n\to\infty} F_{X_n}(t) \geq F_X(t-) = F_X(t)$ . PokazaliÅ›my, Å¼e dla  $t \in C(F_X)$ ,

$$F_X(t) \le \liminf_{n \to \infty} F_{X_n}(t) \le \limsup_{n \to \infty} F_{X_n}(t) \le F_X(t),$$

co koÅ„czy dowÃ³d.

(11.6)  $\blacksquare$  FunkcjÄ… generujÄ…cÄ… momenty zmiennej losowej X nazywamy funkcjÄ™  $M_X : \Theta \to \mathbb{R}$  zadanÄ… przez

$$M_X(\theta) = \mathbb{E}[e^{\theta X}], \quad \theta \in \Theta.$$

gdzie  $\Theta = \{ \theta \in \mathbb{R} \colon \mathbb{E}[e^{\theta X}] < \infty \}.$ 

 $\triangle$  Zawsze mamy  $0 \in \Theta$ .

(11.7)  $\bullet$  JeÅ›li  $X \sim \text{EXP}(\lambda)$ , to

$$\mathbb{E}[e^{\theta X}] = \begin{cases} \frac{\lambda}{\lambda - \theta}, & \theta < \lambda, \\ \infty, & \theta \ge \lambda. \end{cases}$$

Tutaj  $\Theta = (-\infty, \lambda)$ .

(11.8)  $\mathbf{Q}_{\mathbf{a}}^{\mathbf{a}}$  JeÅ›li  $X \sim N(\mu, \sigma^2)$ , to

$$\mathbb{E}[e^{\theta X}] = e^{\theta \mu + \frac{\theta^2}{2}\sigma^2}, \qquad \theta \in \Theta = \mathbb{R}.$$

(11.9)  $\bullet$  JeÅ›li  $X \sim \text{Pois}(\lambda)$ , to

$$\mathbb{E}[e^{\theta X}] = e^{\lambda(e^{\theta} - 1)}, \qquad \theta \in \Theta = \mathbb{R}.$$

- (11.10) **TW.** (WÅ‚asnoÅ›ci funkcji generujÄ…cej momenty) Niech  $(-\theta_0, \theta_0) \subset \Theta$  dla pewnego  $\theta_0 > 0$  (innymi sÅ‚owy, niech  $M_X$  bÄ™dzie okreÅ›lona w otoczeniu zera). Wtedy
  - (a)  $\mathbb{E}[|X|^k] < \infty \text{ dla } k \in \mathbb{N},$
  - (b)  $M_X(t) = \sum_{n=0}^{\infty} \frac{t^n}{n!} \mathbb{E}[X^n]$  dla  $t \in (-\theta_0, \theta_0),$
  - (c)  $M_X^{(k)}(0) = \mathbb{E}[X^k] \operatorname{dla} k \in \mathbb{N}.$

Szkic dowodu: Mamy  $e^{|t|} \le e^t + e^{-t}$ , zatem  $\mathbb{E}[e^{t|X|}] < \infty$  dla  $t < \theta_0$ . Ponadto,  $\frac{t^k}{k!} |X|^k \le e^{t|X|}$  dla t > 0, wiec mamy (a).

Å»eby uzasadniÄ‡ zamianÄ™ kolejnoÅ›ci  $\mathbb{E}[\cdot]$  oraz  $\sum_{n=1}^{\infty}$  w (b) skorzystamy z Twierdzenia Lebesgue'a o zbieÅ¼noÅ›ci zdominowanej (patrz W10). Zdefiniujmy  $S_n = \sum_{k=0}^n \frac{t^k}{k!} X^k$  oraz zauwaÅ¼my, Å¼e  $S_n \xrightarrow{1} e^{tX}$ . Ponadto,

$$\mathbb{E}[\lim_{n \to \infty} S_n] = M_X(t) \quad \text{oraz} \quad \lim_{n \to \infty} \mathbb{E}[S_n] = \sum_{n=0}^{\infty} \frac{t^k}{k} \mathbb{E}[X^k].$$

PoniewaÅ¼  $|S_n| \leq Y := e^{|tX|}$  oraz  $\mathbb{E}[Y] < \infty$ , Twierdzenie Lebesgue'a daje nam (b).

Punkt (b) mÃ³wi nam, Å¼e  $M_X$  jest szeregiem potÄ™gowym. Z ogolnej teorii wiemy, Å¼e szeregi potÄ™gowe moÅ¼emy rÃ³Å¼niczkowaÄ‡ wyraz po wyrazie wewnÄ…trz ich promienia zbieÅ¼noÅ›ci (ktÃ³ry tutaj wynosi co najmniej  $\theta_0 > 0$ ). W ten sposÃ³b otrzymujemy (c).

(11.11) **TW.** Niech X i Y bÄ™dÄ… zmiennymi losowymi takimi, Å¼e  $M_X(t) = M_Y(t)$  dla  $t \in (-\varepsilon, \varepsilon)$  dla pewnego  $\varepsilon > 0$ . Wtedy X i Y majÄ… takie same rozkÅ‚ady. Innymi sÅ‚owy, funkcja generujÄ…ca momenty, jesli jest okreÅ›lona w otoczeniu zera, jednoznacznie wyznacza rozkÅ‚ad.

 $oldsymbol{\Delta}$  DowÃ³d powyÅ¼szego twierdzenia opiera siÄ™ zwykle na wykorzystaniu zwiÄ…zku FGM z transformatÄ… Laplace'a.  $oldsymbol{\Delta}$  PoniewaÅ¼ FGM jest "generowana" przez momenty, powyÅ¼szy wynik oznacza, Å¼e jeÅ›li FGM istnieje w otoczeniu 0, to ciÄ…g momentow  $(\mathbb{E}[X^n])_{n=1}^{\infty}$  jednoznacznie wyznacza rozkÅ‚ad X.

OgÃ³lnie, jeÅ›li X ma wszystkie momenty skoÅ„czone, ale jego FGM nie istnieje (czyli poza 0 jest nieskoÅ„czona), to mogÄ… istnieÄ‡ roÅ¼ne rozkÅ‚ady posiadajÄ…ce te same momenty. PrzykÅ‚adem rozkÅ‚adu, ktÃ³ry nie jest wyznaczony jednoznacznie przez momenty jest tzw. rozkÅ‚ad log-normalny (rozkÅ‚ad  $X = e^N$ , gdzie  $N \sim N(\mu, \sigma^2)$ ).

(11.12)

$$\mathbb{E}[e^{\theta(X+Y)}] = \mathbb{E}[e^{\theta X}]\mathbb{E}[e^{\theta Y}] = e^{\theta(\mu_1 + \mu_2) + \frac{\theta^2}{2}(\sigma_1^2 + \sigma_2^2)},$$

czyli  $X + Y \sim N(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2)$ .

(11.13) **TW.** (Zasada Helly'ego) Niech  $(F_n)_{n\geq 1}$  bÄ™dzie ciÄ…giem dystrybuant. Istnieje jego podciÄ…g  $(F_{n_k})_{k\geq 1}$  oraz funkcja F takie, Å¼e

$$\lim_{k \to \infty} F_{n_k}(t) = F(t) \qquad \forall t \in C(F),$$

gdzie F jest niemalejÄ…ca, prawostronnie ciÄ…gÅ‚a oraz  $0 \le F \le 1$  (ale F nie musi byÄ‡ dystrybuantÄ…). Szkic dowodu:

- Ponumerujmy wszystkie liczy wymierne  $\mathbb{Q} = (q_1, q_2, \ldots)$ .
- PoniewaÅ¼ ciÄ…g liczbowy  $(F_n(q_1))_{n\geq 1}$  jest ograniczony, wiÄ™c z twierdzenia Bolzano-Weierstrassa istnieje podciÄ…g  $(l_k^{(1)})_{k\geq 1}\subset \mathbb{N}$  taki, Å¼e

$$\lim_{k \to \infty} F_{l_k^{(1)}}(q_1) = F(q_1).$$

Na tym etapie  $F(q_1)$  jest po prostu oznaczeniem granicy, nic nie wiemy jeszcze o funkcji F.

â€¢ RozwaÅ¼my teraz ciÄ…g  $(F_{l_k^{(1)}}(q_2))_{n\geq 1}$ , z ktÃ³rego ograniczonoÅ›ci znowu wnioskujemy istnienie podciÄ…gu  $(l_k^{(2)})_{k\geq 1}$  takiego, Å¼e

$$\lim_{k \to \infty} F_{l_k^{(2)}}(q_2) = F(q_2).$$

â€¢ IterujÄ…c takie postÄ™powanie, konstruujemy podciÄ…gi  $\ell^{(m)} := (l_k^{(m)})_{k \geq 1}$  dla ktÃ³rych

$$\lim_{k \to \infty} F_{l_k^{(m)}}(q_m) = F(q_m).$$

â€¢  $\P$ Kluczowa obserwacja jest nastÄ™pujÄ…ca. PoniewaÅ¼  $\mathbb{N} \supset \ell^{(1)} \supset \ell^{(2)} \supset \ell^{(m)}$ , to w rzeczywistoÅ›ci pokazaliÅ›my, Å¼e

$$\lim_{k \to \infty} F_{l_k^{(m)}}(q_i) = F(q_i) \qquad \text{dla } i = 1, 2, \dots, m.$$

â€¢

$$\lim_{k \to \infty} F_{n_k}(q_i) = F(q_i) \qquad \text{dla } i = 1, 2, \dots,$$

czyli mamy zbieÅ¼noÅ›Ä‡ dla wszystkich liczb wymiernych.

- PowyÅ¼ej okreÅ›liliÅ›my funkcjÄ™ F na wszystkich liczbach wymiernych. Dla dowolnego  $x \in \mathbb{R}$  definiujemy  $F(x) := \inf\{F(q) \colon q \in \mathbb{Q}, q > x\}.$
- Prawostronna ciÄ…gÅ‚oÅ›Ä‡ (monotonicznoÅ›Ä‡, ograniczonoÅ›Ä‡)  $F_n$  daje prawostronnÄ… ciÄ…gÅ‚oÅ›Ä‡ (monotonicznoÅ›Ä‡, ograniczonoÅ›Ä‡) F.

#### 12. W12 - Centralne Twierdzenie Graniczne

<span id="page-28-0"></span>(12.1) **TW.** (Twierdzenie o ciÄ…gÅ‚oÅ›ci dla funkcji generujÄ…cych momenty) Niech  $M_{X_n}$  bÄ™dzie funkcjÄ… generujÄ…cÄ… momenty zmiennej losowej  $X_n,\,n=1,2,\ldots$  JeÅ›li dla pewnego  $\varepsilon>0$  zachodzi  $M_{X_n}(s),M_X(s)<\infty$  dla  $s\in(-\varepsilon,\varepsilon)$  oraz

$$\lim_{n \to \infty} M_{X_n}(s) = M_X(s) \qquad \text{dla } s \in (-\varepsilon, \varepsilon),$$

to  $X_n \stackrel{d}{\longrightarrow} X$ .

Szkic dowodu:

Oznaczmy  $F_n=F_{X_n}$ . Z Zasady Helly'ego, z ciÄ…gu  $(F_n)_{n\geq 1}$  moÅ¼na wybraÄ‡ podciÄ…g  $(F_{n_k})_k$  dla ktÃ³rego mamy

$$\lim_{k \to \infty} F_{n_k}(t) = F(t) \qquad \forall t \in C(F).$$

Plan dowodu: pokaÅ¼emy kolejno, Å¼e

- F jest dystrybuanta
- $F = F_X$ ,
- caÅ‚y ciÄ…g  $(F_n)_{n>1}$  teÅ¼ zbiega do F.

Dla dowolnego x > 0 oraz  $\beta \in (0, \varepsilon)$ ,

$$F_n(-x) + 1 - F_n(x) = \int_{(-\infty, -x]} e^{\beta t} e^{-\beta t} \mathbb{P}_{X_n}(dt) + \int_{(x, \infty)} e^{-\beta t} e^{\beta t} \mathbb{P}_{X_n}(dt)$$

$$\leq e^{-\beta x} \int_{(-\infty, -x]} e^{-\beta t} \mathbb{P}_{X_n}(dt) + e^{-\beta x} \int_{(x, \infty)} e^{\beta t} \mathbb{P}_{X_n}(dt)$$

$$\leq e^{-\beta x} (M_{X_n}(-\beta) + M_{X_n}(\beta)).$$

Stad dla  $n = n_k$ ,

$$F_{n_k}(-x) + 1 - F_{n_k}(x) \le e^{-\beta x} (M_{X_{n_k}}(-\beta) + M_{X_{n_k}}(\beta)).$$

PrzechodzÄ…c z  $k \to \infty$  otrzymujemy

$$F(-x) + 1 - F(x) \le e^{-\beta x} (M_X(-\beta) + M_X(\beta)),$$

a stÄ…d  $\lim_{x\to\infty} (F(-x) + 1 - F(x)) = 0$ . Zatem

$$0 \le \lim_{x \to \infty} F(-x) \le \lim_{x \to \infty} (F(-x) + 1 - F(x)) = 0,$$

$$0 \le 1 - \lim_{x \to \infty} F(x) \le \lim_{x \to \infty} (F(-x) + 1 - F(x)) = 0,$$

czyli F jest dystrybuantÄ…. PokazaliÅ›my juÅ¼, Å¼e ciÄ…g  $(X_{n_k})_k$  zbiega wedÅ‚ug rozkÅ‚adu, ale jeszcze nie wiemy Å¼e granicÄ… jest X, a takÅ¼e nie wiemy czy caÅ‚y ciÄ…g  $(X_n)_n$  teÅ¼ zbiega. PokaÅ¼emy teraz, Å¼e F jest dystrybuantÄ… zmiennej losowej X. Niech  $\mu$  bÄ™dzie miarÄ… generowanÄ… przez dystrybuantÄ™ F. Z definicji zbieÅ¼noÅ›ci wedÅ‚ug rozkÅ‚adu wiemy, Å¼e dla kaÅ¼dej funkcji ciÄ…gÅ‚ej i ograniczonej f mamy

$$\lim_{k \to \infty} \int_{\mathbb{R}} f(x) \mathbb{P}_{X_{n_k}}(dx) = \int_{\mathbb{R}} f(x) \mu(dx).$$

Dla  $s \in (-\varepsilon, \varepsilon)$  oraz N > 0 zdefiniujmy  $f_s^{(N)}(x) := \begin{cases} e^{sx}, & |x| \leq N \\ 0, & |x| > N \end{cases}$ . Co prawda  $f_s \notin C_b(\mathbb{R})$ , bo nie jest ciÄ…gÅ‚a, ale zbieÅ¼noÅ›Ä‡ (\*\*) nadal zachodzi o ile  $N \in C(F)$ . Zatem

$$\lim_{k \to \infty} \int_{[-N,N]} e^{sx} \mathbb{P}_{X_{n_k}}(dx) = \int_{[-N,N]} e^{sx} \mu(dx).$$

Z drugiej strony, z zaÅ‚oÅ¼enia (\*) mamy

$$\lim_{k \to \infty} M_{X_{n_k}}(s) = \lim_{k \to \infty} \int_{\mathbb{P}} e^{sx} \mathbb{P}_{X_{n_k}}(dx) = \int_{\mathbb{P}} e^{sx} \mathbb{P}_X(dx).$$

PrzechodzÄ…c w (\*\*\*) z  $N \to \infty$  oraz porÃ³wnujÄ…c z powyÅ¼szÄ… linijkÄ… otrzymujemy dla  $s \in (-\varepsilon, \varepsilon)$ ,

$$\int_{\mathbb{D}} e^{sx} \mu(dx) = \int_{\mathbb{D}} e^{sx} \mathbb{P}_X(dx).$$

Z jednoznacznoÅ›ci funkcji generujÄ…cej momenty otrzymujemy, Å¼e  $\mu = \mathbb{P}_X$ , czyli  $F = F_X$ . Wiemy juÅ¼, Å¼e  $X_{n_k} \stackrel{d}{\longrightarrow} X$ . PokaÅ¼emy teraz, Å¼e  $X_n \stackrel{d}{\longrightarrow} X$ . Wiemy, Å¼e  $X_n \stackrel{d}{\longrightarrow} X$  wtedy i tylko wtedy, gdy

$$\forall x \in C(F) \ \forall \varepsilon > 0 \ \exists N > 0 \ \forall n > N \qquad |F_n(x) - F(x)| < \varepsilon.$$

Zaprzeczeniem tego warunku jest

$$\exists x_0 \in C(F) \ \exists \varepsilon_0 > 0 \ \forall N > 0 \ \exists n_N > N \qquad |F_{n_N}(x) - F(x)| > \varepsilon.$$

Dla ciÄ…gu  $(F_{n_N})_N$  moÅ¼na jednak powtÃ³rzyÄ‡ wszystkie wczeÅ›niejsze kroki oraz znaleÅºÄ‡ podciÄ…g zbieÅ¼ny punktowo do F. SprzecznoÅ›Ä‡.

(12.2) **TW.** (Centralne Twierdzenie Graniczne) Niech  $(X_i)_{i\geq 1}$  - ciÄ…g i.i.d. oraz  $\mathbb{E}[X_1^2] < \infty$ . Oznaczmy  $\mu = \mathbb{E}[X_1]$  oraz  $\sigma^2 = \operatorname{Var}[X_1] > 0$ . Wtedy

$$\frac{X_1 + \dots X_n - n\mu}{\sqrt{n\sigma^2}} \xrightarrow{d} Z \sim N(0,1).$$

Szkic dowodu gdy  $M_X(t) < \infty$  dla  $t \in \mathbb{R}$ 

- Dla  $Y_k := \frac{X_k \mu}{\sigma}$  mamy  $\mathbb{E}[Y_k] = 0$  oraz  $\text{Var}[Y_k] = 1$ . CiÄ…g  $(Y_k)_k$  jest i.i.d.
- $M_{Y_1}(s) = 1 + \frac{s^2}{2} + r(s)$ , gdzie  $r(s)/s^2 \to 0$ , gdy  $s \to 0$ .
- $M_{\frac{Y_1 + \dots + Y_n}{\sqrt{n}}}(s) = (M_{Y_1}(\frac{s}{\sqrt{n}}))^n = \left(1 + \frac{s^2/2 + nr(s/\sqrt{n})}{n}\right)^n \to e^{s^2/2}, \text{ gdy } n \to \infty.$

Szkic dowodu gdy wiemy tylko, Å¼e  $\mathbb{E}[X^2] < \infty$ :

â€¢ Zamiast funkcji generujÄ…cej momenty  $M_Y$  definiujemy tzw. <u>funkcjÄ™ charakterystycznÄ…</u> (w innym kontekÅ›cie jest zwana transformatÄ… Fouriera)

$$\phi_Y(s) := \mathbb{E}[e^{isY}] = \mathbb{E}[\cos(sY)] + i \mathbb{E}[\sin(sY)], \quad s \in \mathbb{R}$$

Funkcja charakterystyczna, w odrÃ³Å¼nieniu od funkcji generujÄ…cej momenty, przyjmuje wartoÅ›ci zespolone oraz zawsze istnieje: mamy  $|\mathbb{E}[e^{isY}]| \leq \mathbb{E}[|e^{isY}|] = 1$ . Ponadto, funkcja charakterystyczna jednoznacznie wyznacza rozkÅ‚ad oraz zachodzi twierdzenie o ciÄ…gÅ‚oÅ›ci dla funkcji charakterystycznych  $(X_n \stackrel{d}{\longrightarrow} X$  wtedy i tylko wtedy, gdy  $\phi_{X_n}(s) \to \phi_X(s)$  dla kaÅ¼dego  $s \in \mathbb{R}$ ).

â€¢ JeÅ›li istniejÄ… odpowiednie momenty zmiennej losowej, to funkcjÄ™ charaktertystycznÄ… moÅ¼na rozwijaÄ‡. W szczegÃ³lnoÅ›ci, jeÅ›li  $\mathbb{E}[Y^2] < \infty$ , to

$$\phi_Y(s) = 1 + is\mathbb{E}[Y] - \frac{s^2}{2}\mathbb{E}[Y^2] + r(s),$$

gdzie  $r(s)/s^2 \to 0$ , gdy  $s \to 0$ .

 $\bullet$  Podobnie jak dla funkcji generujÄ…cej momenty, mamy zatem dla  $s \in \mathbb{R}$ 

$$\phi_{\frac{Y_1 + \dots + Y_n}{\sqrt{n}}}(s) = \left(1 + \frac{-s^2/2 + nr(s/\sqrt{n})}{n}\right)^n \to e^{-s^2/2}$$

- JeÅ›li funkcja generujÄ…ca momenty istnieje, to zwykle zachodzi  $\phi_Y(s) = M_Y(is)$ . JeÅ›li  $Z \sim N(0,1)$ , to  $\phi_Z(s) = M_Z(is) = e^{-s^2/2}$ . Zatem, twierdzenie o ciÄ…gÅ‚oÅ›ci dla funkcji charakterystycznych koÅ„czy dowÃ³d.
- (12.3) **A** W CTG nie mamy zbieÅ¼noÅ›ci wedÅ‚ug prawdopodobieÅ„stwa, a wiÄ™c tym bardziej z prawdopodobienstwem 1. Å»eby to zobaczyÄ‡, zaÅ‚Ã³Å¼my nie wprost, Å¼e

$$\frac{S_n}{\sqrt{n}} := \frac{X_1 + \dots X_n - n\mu}{\sqrt{n\sigma^2}} \xrightarrow{\mathbb{P}} Z.$$

Zatem.

$$\frac{S_{2n} - S_n}{\sqrt{n}} = \sqrt{2} \frac{S_{2n}}{\sqrt{2n}} - \frac{S_n}{\sqrt{n}} \stackrel{\mathbb{P}}{\longrightarrow} \left(\sqrt{2} - 1\right) Z.$$

PoniewaÅ¼ zbieÅ¼noÅ›Ä‡ wedÅ‚ug prawdopodobieÅ„stwa implikuje zbieÅ¼noÅ›Ä‡ wedÅ‚ug rozkÅ‚adu, mamy stad

$$\frac{S_{2n} - S_n}{\sqrt{n}} \stackrel{d}{\longrightarrow} \left(\sqrt{2} - 1\right) Z.$$

Ale dla kaÅ¼dego  $n,\,\frac{S_{2n}-S_n}{\sqrt{n}}$ ma taki sam rozkÅ‚ad jak  $\frac{S_n}{\sqrt{n}},$  wiÄ™c z CTG wiemy, Å¼e

$$\frac{S_{2n} - S_n}{\sqrt{n}} \stackrel{d}{\longrightarrow} Z.$$

Otrzymujemy stÄ…d i z  $(\P)$ , Å¼e  $F_{(\sqrt{2}-1)Z}(t) = F_Z(t)$  dla  $t \in \mathbb{R}$ , co jest niemoÅ¼liwe jeÅ›li  $\mathbb{P}(Z \neq 0) > 0$ . SprzecznoÅ›Ä‡.

#### 13. W13 - Warunkowa wartoÅ›Ä‡ oczekiwana

- <span id="page-30-0"></span>(13.1) JeÅ›li  $\mathbb{P}(B) > 0$  dla pewnego  $B \in \mathcal{F}$ , to  $\mathbb{P}_B(\cdot) := \mathbb{P}(\cdot|B)$  jest prawdopodobieÅ„stwem na  $(\Omega, \mathcal{F})$ . MoÅ¼emy wiÄ™c liczyÄ‡ caÅ‚ki wzglÄ™dem  $\mathbb{P}_B$ . RozwaÅ¼my zmiennÄ… losowÄ… X takÄ…, Å¼e  $\mathbb{E}[|X|] < \infty$ .
  - ğŸ—¸ Definiujemy warunkowÄ… wartoÅ›Ä‡ oczekiwanÄ… (WWO) pod warunkiem zdarzenia

$$\mathbb{E}[X|B] := \int_{\Omega} X(\omega) \mathbb{P}_B(d\omega).$$

 $\blacksquare$  Niech X bÄ™dzie zmiennÄ… losowÄ… na  $(\Omega, \mathcal{F})$ . RozkÅ‚adem warunkowym X pod warunkiem zdarzenia B nazywamy funkcjÄ™  $\mathbb{P}_{X|B}$  zadanÄ… przez

$$\mathbb{P}_{X|B}(C) := \mathbb{P}(X \in C|B) = \frac{\mathbb{P}(\{X \in C\} \cap B)}{\mathbb{P}(B)}, \qquad C \in \mathcal{B}(\mathbb{R}).$$

Dystrybuanta rozkÅ‚adu warunkowego X pod warunkiem zdarzenia B definiowana jest wzorem

$$F_{X|B}(t) := \mathbb{P}_{X|B}((-\infty, t]) = \mathbb{P}(X \le t|B).$$

(13.2) **LEM.** JeÅ›li  $\mathbb{P}(B) > 0$  oraz X jest caÅ‚kowalnÄ… zmiennÄ… losowÄ…, to  $\mathbb{E}[X|B] = \frac{\mathbb{E}[X \mathbbm{1}_B]}{\mathbb{P}(B)}$ . Szkic dowodu: PoniewaÅ¼ obie strony sÄ… liniowe w X, wystarczy sprawdziÄ‡ dla  $X = \mathbbm{1}_A$  dla  $A \in \mathcal{F}$ . Mamy

$$\int_{\Omega} \mathbb{1}_A(\omega) \mathbb{P}_B(d\omega) = \mathbb{P}_B(A) = \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)} = \frac{\mathbb{E}[\mathbb{1}_A \mathbb{1}_B]}{\mathbb{P}(B)}.$$

DowolnÄ… zmiennÄ… losowÄ… X aproksymujemy przez ciÄ…g funkcji prostych.

(13.3) **LEM.** JeÅ›li  $(B_n)_n$  jest nietrywialnym przeliczalnym rozbiciem  $\Omega$  oraz X jest caÅ‚kowalnÄ… zmiennÄ… losowÄ…, to

$$\mathbb{E}[X] = \sum_{n} \mathbb{E}[X|B_n]\mathbb{P}(B_n).$$

Szkic dowodu:  $1 = \mathbb{1}_{\Omega}(\omega) = \sum_{n} \mathbb{1}_{B_n}(\omega)$ .

(13.4)  $(X_n)_n$  bÄ™dzie ciÄ…giem zmiennych losowych o takiej samej wartoÅ›ci oczekiwanej oraz niech N bÄ™dzie zmiennÄ… losowÄ… niezaleÅ¼nÄ… od  $(X_n)_n$  takÄ…, Å¼Ä™  $\mathrm{supp}(N) = \{0,1,\ldots\}$ . Niech  $S_0 = 0$ ,  $S_n = X_1 + \ldots + X_n$  dla  $n \in \mathbb{N}$ . Wtedy  $\mathbb{E}[S_n] = n \, \mathbb{E}[X_1]$  oraz

$$\mathbb{E}[S_N] = \sum_{n=0}^{\infty} \mathbb{E}[S_N | N = n] \mathbb{P}(N = n) = \sum_{n=0}^{\infty} \frac{\mathbb{E}[S_N \mathbb{1}_{N=n}]}{\mathbb{P}(N = n)} \mathbb{P}(N = n) = \sum_{n=0}^{\infty} \mathbb{E}[S_n \mathbb{1}_{N=n}]$$

$$\stackrel{\text{nzl}}{=} \sum_{n=0}^{\infty} \mathbb{E}[S_n] \mathbb{E}[\mathbb{1}_{N=n}] = \mathbb{E}[X] \sum_{n=0}^{\infty} n \, \mathbb{P}(N = n) = \mathbb{E}[X] \mathbb{E}[N].$$

(13.5)  $\mathbf{Q}_{\bullet}^{\bullet}$  Niech  $(X,Y) \sim m_2(m,(p_1,p_2))$ . Wtedy  $\mathbb{P}(Y=l) = \binom{m}{l} p_2^l (1-p_2)^{m-l}$  dla  $l=0,1,\ldots,m$  oraz

$$\mathbb{P}(X = k | Y = l) = {m - l \choose k} \left(\frac{p_1}{1 - p_2}\right)^k \left(1 - \frac{p_1}{1 - p_2}\right)^{m - l - k}, \qquad k = 0, 1, \dots, m - l.$$

Widzimy, Å¼e rozkÅ‚ad warunkowy X pod warunkiem zdarzenia  $\{Y=l\}$  to  $\mathbf{b}(m-l,\frac{p_1}{1-p_2})$ . BÄ™dziemy pisali

$$X|Y=l \sim \mathrm{b}\left(m-l, \frac{p_1}{1-p_2}\right)$$
 lub nawet  $X|Y \sim \mathrm{b}\left(m-Y, \frac{p_1}{1-p_2}\right)$ .

Wnioskujemy teÅ¼ stÄ…d, Å¼e  $\mathbb{E}[X|Y=l] = (m-l)\frac{p_1}{1-p_2}$  oraz  $\text{Var}[X|Y=l] = (m-l)\frac{p_1}{1-p_2}(1-\frac{p_1}{1-p_2})$ .

lack A  $\mathbb{E}[X|Y=l]$  jest po prostu wartoÅ›ciÄ… oczekiwanÄ… liczonÄ… wzglÄ™dem rozkÅ‚adu warunkowego X|Y=l.

**A** A Skoro znamy funkcjÄ™  $m(l) := \mathbb{E}[X|Y=l]$ , to moÅ¼emy rÃ³wnie dobrze rozwaÅ¼yÄ‡  $m(Y(\omega)) = \mathbb{E}[X|Y=l]$ , zwykle oznaczane przez  $\mathbb{E}[X|Y](\omega)$ . ZauwaÅ¼my, Å¼e jest to zmienna losowa!

- <span id="page-31-0"></span>(13.6) Poprzedni przykÅ‚ad byÅ‚ prosty, bo dotyczyÅ‚ rozkÅ‚adÃ³w dyskretnych.
  - Niech (X,Y) ma rozkÅ‚ad jednostajny na  $T=\{(x,y)\in\mathbb{R}^2\colon 0\leq y\leq x\leq 2\}$ , tzn.  $f_{(X,Y)}(x,y)=\frac{1}{2}\mathbbm{1}_T(x,y)$ . ChcielibyÅ›my znaleÅºÄ‡ rozkÅ‚ad X|Y=1. Intuicyjnie powinno to byÄ‡  $\mathrm{U}([1,2])$ , ale  $\mathbb{P}(Y=1)=0$ , wiÄ™c Å¼eby rozwaÅ¼aÄ‡ to formalnie, do problemu trzeba podejÅ›Ä‡ inaczej. Najpierw powinnismy lepiej zrozumieÄ‡ przypadek dyskretny.
- (13.7) Niech N bÄ™dzie zmiennÄ… losowÄ… o rozkÅ‚adzie typu dyskretnego. JeÅ›li  $\mathbb{E}[|X|] < \infty$ , to warunkowÄ… wartoÅ›ciÄ… oczekiwanÄ… X pod warunkiem zmiennej losowej N nazywamy zmiennÄ… losowÄ…  $\mathbb{E}[X|N]$  zdefiniowanÄ… przez

$$\mathbb{E}[X|N](\omega) = \sum_{n \in \text{supp}(N)} \mathbb{E}[X|N=n] \mathbb{1}_{N(\omega)=n},$$

tzn. jeÅ›li  $N(\omega) = n$ , to  $\mathbb{E}[X|N](\omega) = \mathbb{E}[X|N = n]$ .

- (13.8) **LEM.** WÅ‚asnoÅ›ci WWO pod warunkiem dyskretnej zmiennej losowej.
  - (a)  $\mathbb{E}[X|N](\omega) = m(N(\omega))$  dla pewnej borelowskiej funkcji m,
  - (b)  $\mathbb{E}[X\mathbbm{1}_{N\in B}] = \mathbb{E}[\mathbb{E}[X|N]\mathbbm{1}_{N\in B}]$  dla kaÅ¼dego  $B\in\mathcal{B}(\mathbb{R})$ .

Szkic dowodu:

- (a) Oczywiste z definicji.
- (b) Niech  $B \in \mathcal{B}(\mathbb{R})$  oraz  $B \cap \text{supp}(N) = \{n_1, \dots, n_k\}$ .

$$\mathbb{E}\left[\mathbb{E}[X|N]\mathbb{1}_{N \in B}\right] = \sum_{n} \mathbb{E}[X|N = n]\mathbb{E}[\mathbb{1}_{N = n}\mathbb{1}_{N \in B}] = \sum_{i = 1}^{k} \mathbb{E}[X|N = n_{i}]\mathbb{P}(N = n_{i}) = \sum_{i = 1}^{k} \mathbb{E}[X\mathbb{1}_{N = n_{i}}] = \mathbb{E}[X\mathbb{1}_{N \in B}].$$

- (13.9) Niech Y bÄ™dzie zmiennÄ… losowÄ…. JeÅ›li  $\mathbb{E}[|X|] < \infty$ , to warunkowÄ… wartoÅ›ciÄ… oczekiwanÄ… X pod warunkiem zmiennej losowej Y nazywamy zmiennÄ… losowÄ…  $\mathbb{E}[X|Y]$  speÅ‚niajÄ…cÄ… dwa warunki:
  - $\overline{I \mathbb{E}[X|Y](\omega)} = m(Y(\omega))$  dla pewnej borelowskiej funkcji m,
  - II  $\mathbb{E}[X \mathbb{1}_{Y \in B}] = \mathbb{E}[\mathbb{E}[X|Y] \mathbb{1}_{Y \in B}]$  dla kaÅ¼dego  $B \in \mathcal{B}(\mathbb{R})$ .
  - lacktriangled Dla  $A \in \mathcal{F}$  oznaczmy  $\mathbb{P}(A|Y) = \mathbb{E}[\mathbb{1}_A|Y]$ .
- (13.10) **TW.** JeÅ›li  $\mathbb{E}[|X|] < \infty$ , to  $\mathbb{E}[X|Y]$  istnieje. Ponadto, jest ona wyznaczona jednoznacznie z dokÅ‚adnoÅ›cia do zbiorÃ³w miary  $\mathbb{P}$  0, tzn. jeÅ›li Z rÃ³wnieÅ¼ speÅ‚nia warunki definicji, czyli:
  - $Z(\omega) = m(Y(\omega)),$
  - $\mathbb{E}[X\mathbb{1}_{Y\in B}] = \mathbb{E}[Z\mathbb{1}_{Y\in B}]$  dla kaÅ¼dego  $B\in\mathcal{B}(\mathbb{R})$ ,

to  $\mathbb{P}(Z \neq \mathbb{E}[X|Y]) = 0$ .

- (13.11) Niech X bÄ™dzie caÅ‚kowalnÄ… zmiennÄ… losowÄ….
  - WarunkowÄ… wartoÅ›ciÄ… oczekiwanÄ… zmiennej losowej X pod warunkiem zdarzenia  $\{Y = y\}$  dla  $y \in \text{supp}(X)$ , nazywamy wielkoÅ›Ä‡

$$\mathbb{E}[X|Y=y] = m(y),$$

gdzie funkcja m jest funkcja z definicji  $\mathbb{E}[X|Y]$ , tzn.  $\mathbb{E}[X|Y] = m(Y)$ .

lacktriangle PoniewaÅ¼  $\mathbb{E}[X|Y]$  zawsze istnieje (o ile  $\mathbb{E}[|X|] < \infty$ ), to funkcja  $y \mapsto \mathbb{E}[X|Y=y]$  jest dobrze okreÅ›lona. Nawet wtedy, gdy  $\mathbb{P}(Y=y)=0$ !

**A** JeÅ›li  $\mathbb{P}(Y=y) > 0$ , to powyÅ¼sza definicja pokrywa siÄ™ z Definicja (13.1).

 $\blacksquare$  Warunkowym prawdopodobieÅ„stwem zdarzenia  $A \in \mathcal{F}$  pod warunkiem zdarzenia  $\{Y = y\}$  nazywamy

$$\mathbb{P}(A|Y=y) := \mathbb{E}[\mathbb{1}_A|Y=y].$$

(13.12) Kontynuacja przykÅ‚adu (13.6). Szukamy rozkÅ‚adu warunkowego X pod warunkiem  $\{Y = y\}$ . Spodziewamy siÄ™, Å¼e X|Y = y powinien mieÄ‡ rozkÅ‚ad jednostajny  $U([y, 2]), y \in [0, 2]$ . PokaÅ¼emy najpierw, Å¼e

$$\mathbb{E}[\mathbb{1}_{X \le t} | Y] = \begin{cases} 0, & t < Y, \\ \frac{t - Y}{2 - Y}, & Y \le t < 2, \\ 1, & t \ge 2. \end{cases}$$

Warunek I definicji  $\mathbb{E}[\mathbbm{1}_{X < t} | Y]$  jest oczywiÅ›cie speÅ‚niony. Warunek II jest speÅ‚niony jeÅ›li

$$\mathbb{E}[\mathbbm{1}_{X \leq t} \mathbbm{1}_{Y \in B}] = \mathbb{E}\left[\frac{t-Y}{2-Y} \mathbbm{1}_{Y \leq t < 2} \mathbbm{1}_{Y \in B}\right] + \mathbb{E}[\mathbbm{1}_{t \geq 2} \mathbbm{1}_{Y \in B}].$$

Lewa strona wynosi dla  $t \in [0, 2)$  wynosi

$$\begin{split} \int_{B} \int_{-\infty}^{t} f_{(X,Y)}(x,y) dx \, dy &= \frac{1}{2} \int_{B} \int_{-\infty}^{t} \mathbb{1}_{0 \le y \le x \le 2} dx \, dy = \frac{1}{2} \int_{B \cap [0,t]} \int_{y}^{t} dx \, dy \\ &= \frac{1}{2} \int_{B \cap [0,t]} (t-y) dy. \end{split}$$

Z kolei z prawej strony mamy dla  $t \in [0, 2)$ ,

$$\mathbb{E}\left[\frac{t-Y}{2-Y}\mathbbm{1}_{Y \leq t}\mathbbm{1}_{Y \in B}\right] = \int_{B \cap (-\infty,t]} \frac{t-y}{2-y} f_Y(y) dy = \int_{B \cap (-\infty,t]} \frac{t-y}{2-y} \frac{2-y}{2} \mathbbm{1}_{[0,2]}(y) dy = \frac{1}{2} \int_{B \cap [0,t]} (t-y) dy.$$

Podobnie postÄ™pujemy dla t>2 i otrzymujemy toÅ¼samoÅ›Ä‡  $\mathbb{E}[\mathbbm{1}_{Y\in B}]=\mathbb{E}[\mathbbm{1}_{Y\in B}]$ . Z kolei dla t<0 mamy 0=0. Ale  $\mathbb{E}[\mathbbm{1}_{X\leq t}|Y]=\mathbb{P}(X\leq t|Y)$ . Oznacza to, Å¼e dystrybuanta warunkowa X pod warunkiem zdarzenia  $\{Y=y\}$  dana jest przez

$$F_{X|Y=y}(t) := \mathbb{P}(X \le t | Y = y) = \begin{cases} 0, & t < y, \\ \frac{t-y}{2-y}, & y \le t < 2, \\ 1, & t \ge 2. \end{cases}$$

czyli rzeczywiÅ›cie  $X|Y=y\sim \mathrm{U}([y,2]),\,y\in[0,2].$ 

- 14. W14 Warunkowa wartoÅ›Ä‡ oczekiwana ciÄ…g dalszy
- <span id="page-32-0"></span>(14.1) Przypomnienie:
  - $\blacksquare$  Niech Y bÄ™dzie zmiennÄ… losowÄ…. JeÅ›li  $\mathbb{E}[|X|] < \infty$ , to warunkowÄ… wartoÅ›ciÄ… oczekiwanÄ… X pod warunkiem zmiennej losowej Y nazywamy zmiennÄ… losowÄ…  $\mathbb{E}[X|Y]$  speÅ‚niajÄ…cÄ… dwa warunki:
    - I  $\mathbb{E}[X|Y](\omega) = m(Y(\omega))$  dla pewnej borelowskiej funkcji m,

II  $\mathbb{E}[X\mathbb{1}_{Y\in B}] = \mathbb{E}[\mathbb{E}[X|Y]\mathbb{1}_{Y\in B}]$  dla kaÅ¼dego  $B\in\mathcal{B}(\mathbb{R})$ .

f A ZmiennÄ… losowÄ…  $\mathbb{E}[X|Y]$  interpretujemy jako Å›redniÄ… wartoÅ›Ä‡ X pod warunkiem znajomoÅ›ci (losowej) wartoÅ›ci Y.

- (14.2)  $\triangle$  PojÄ™cie WWO pod warunkiem Y naturalnie uogÃ³lnia sie na przypadek, gdy Y jest wektorem losowym (nwymiarowym,  $n \in \mathbb{N}$ ). W warunku II wystarczy zastÄ…piÄ‡  $B \in \mathcal{B}(R)$  przez  $B \in \mathcal{B}(R^n)$ .
  - lacktriangle JeÅ›li  $Y = (Y_1, \dots, Y_n)$ , to  $\mathbb{E}[X|Y_1, \dots, Y_n] := \mathbb{E}[X|Y]$ .
- (14.3) **TW.** WÅ‚asnoÅ›ci WWO. Niech  $\mathbb{E}[|X|] < \infty$ .
  - (a) JeÅ›li X = f(Y) dla pewnej funkcji borelowskiej f, to  $\mathbb{E}[X|Y] = X$ .
  - (b) JeÅ›li  $\mathbb{P}(Y=c)=1$  dla pewnego  $c\in\mathbb{R}$ , to  $\mathbb{E}[X|Y]=\mathbb{E}[X]$ .
  - (c) JeÅ›li f jest borelowska i rÃ³Å¼nowartoÅ›ciowa (na supp(Y)), to  $\mathbb{E}[X|f(Y)] = \mathbb{E}[X|Y]$ .
  - (d) JeÅ›li f jest funkcjÄ… borelowskÄ…, to  $\mathbb{E}[\mathbb{E}[X|Y, f(X,Y,Z)]|Y] = \mathbb{E}[X|Y]$ .
  - (e) JeÅ›li f jest funkcjÄ… borelowskÄ…, to  $\mathbb{E}[\mathbb{E}[X|f(Y)]|Y] = \mathbb{E}[X|f(Y)]$ .
  - (f)  $\mathbb{E}[\mathbb{E}[X|Y]] = \mathbb{E}[X]$ .
  - (g) JeÅ›li Y = f(Z) dla pewnej borelowskiej funkcji f oraz  $\mathbb{E}[|XY|] < \infty$ , to  $\mathbb{E}[XY|Z] = Y\mathbb{E}[X|Z]$ .
  - (h) JeÅ›li X oraz Y sÄ… niezaleÅ¼ne, to  $\mathbb{E}[X|Y] = \mathbb{E}[X]$ .

Szkic dowodu:

- (a) X speÅ‚nia warunki I i II definicji WWO.
- (b) Z warunku I,  $\mathbb{E}[X|Y]$  jest staÅ‚Ä….
- (c) Z rÃ³Å¼nowartoÅ›ciwoÅ›ci mamy  $\{y \colon y \in B\} = \{y \colon f(y) \in f(B)\}$ . Zdefiniujmy  $Z(\omega) = \mathbb{E}[X|f(Y)](\omega)$ . Warunek I jest trywialnie speÅ‚niony. Sprawdzamy warunek II: dla  $B \in \mathcal{B}(\mathbb{R})$ ,

$$\mathbb{E}[Z\mathbb{1}_{Y\in B}] = \mathbb{E}[Z\mathbb{1}_{f(Y)\in f(B)}] = \mathbb{E}[X\mathbb{1}_{f(Y)\in f(B)}] = \mathbb{E}[X\mathbb{1}_{Y\in B}].$$

(d) Dla kaÅ¼dego  $B \in \mathcal{B}(\mathbb{R})$  mamy

$$\begin{split} \mathbb{E}[\mathbb{E}[X|Y]\mathbb{1}_{Y\in B}] &= \mathbb{E}[X\mathbb{1}_{Y\in B}] = \mathbb{E}[X\mathbb{1}_{(Y,f(X,Y,Z)\in B\times \mathbb{R}]} \\ &= \mathbb{E}[\mathbb{E}[X|Y,f(X,Y,Z)]\mathbb{1}_{Y\in B}] = \mathbb{E}\left[\mathbb{E}[\mathbb{E}[X|Y,f(X,Y,Z)]|Y]\mathbb{1}_{Y\in B}\right], \end{split}$$

gdzie kaÅ¼da z nierÃ³wnoÅ›ci wynika z II.

- (e) Wynika z (a), poniewaÅ¼  $\mathbb{E}[X|f(Y)]$  jest funkcjÄ… Y.
- (f) WeÅºmy  $B = \mathbb{R}$  w II.
- (g) Wystarczy sprawdziÄ‡ dla  $Y = \mathbb{1}_{Z \in B}$ ,  $B \in \mathcal{B}(\mathbb{R})$ . DowolnÄ… zmiennÄ… losowÄ… Y aproksymujemy przez funkcje proste. Dla  $A \in \mathcal{B}(\mathbb{R})$  mamy

$$\mathbb{E}[\mathbb{E}[XY|Z]\mathbbm{1}_{Z\in A}] \stackrel{\text{II}}{=} \mathbb{E}[XY\mathbbm{1}_{Z\in A}] = \mathbb{E}[X\mathbbm{1}_{Z\in B}\mathbbm{1}_{Z\in A}] = \mathbb{E}[X\mathbbm{1}_{Z\in A\cap B}] \stackrel{\text{II}}{=} \mathbb{E}[\mathbb{E}[X|Z]\mathbbm{1}_{Z\in A\cap B}] = \mathbb{E}[Y\mathbb{E}[X|Z]\mathbbm{1}_{Z\in A}],$$
poniewaÅ¼  $A\cap B\in \mathcal{B}(\mathbb{R}).$ 

(h) Dla kaÅ¼dego  $B \in \mathcal{B}(\mathbb{R})$  mamy

$$\mathbb{E}[\mathbb{E}[X|Y]\mathbbm{1}_{Y\in B}] \stackrel{\text{II}}{=} \mathbb{E}[X\mathbbm{1}_{Y\in B}] \stackrel{\text{nzl}}{=} \mathbb{E}[X]\mathbb{E}[\mathbbm{1}_{Y\in B}] = \mathbb{E}[\mathbb{E}[X]\mathbbm{1}_{Y\in B}].$$

- (14.4)  $\mathfrak{A}^{\sharp}$  Niech  $\Omega = [-1,1], \, \mathcal{F} = \mathcal{B}([-1,1]), \, \mathbb{P} = \lambda_1/2$  oraz  $Y(\omega) = |\omega|$ . ZnajdÅº  $\mathbb{E}[X|Y]$ . OczywiÅ›cie z warunku I mamy  $\mathbb{E}[X|Y](\omega) = m(Y(\omega)) = m(|\omega|)$ .
- (14.5) **TW.** RozwaÅ¼my tzw. zagadnienie prognozy. Przewidujemy nieobserwowany Y na podstawie obserwowanego X. ZaÅ‚Ã³Å¼my, Å¼e  $\mathbb{E}[Y^2] < \infty$ . Szukamy takiej funkcji borelowskiej  $h^*$  dla ktÃ³rej

$$\mathbb{E}[(Y - h^*(X))^2] = \inf_{h \text{-borelowska}} \mathbb{E}[(Y - h(X))^2].$$

Okazuje siÄ™, Å¼e  $h^*(x) = \mathbb{E}[Y|X=x]$ .

Szkic dowodu: Niech  $h_0(x) = \mathbb{E}[Y|X=x]$ . Wtedy

$$\mathbb{E}[(Y - h(X))^2] = \mathbb{E}[(Y - h_0(X) + h_0(X) - h(X))^2]$$
  
=  $\mathbb{E}[(Y - h_0(X))^2] + \mathbb{E}[(h_0(X) - h(X))^2] + 2\mathbb{E}[(Y - h_0(X))(h_0(X) - h(X))].$ 

Ale z wÅ‚asnoÅ›ci (a), (f) i (g) z poprzedniego Twierdzenia mamy

$$\mathbb{E}[(Y - h_0(X))(h_0(X) - h(X))] = \mathbb{E}[\mathbb{E}[(Y - h_0(X))(h_0(X) - h(X))|X]]$$
$$= \mathbb{E}[(\mathbb{E}[Y|X] - h_0(X))(h_0(X) - h(X))] = 0.$$

Zatem  $\mathbb{E}[(Y - h(X))^2] = \mathbb{E}[(Y - h_0(X))^2] + \mathbb{E}[(h_0(X) - h(X))^2]$  oraz infimum po funkcjach borelowskich h jest osiÄ…gane dla  $h^* = h_0$ .

(14.6)  $\triangle$  PowyÅ¼sze Twierdzenie moÅ¼na traktowaÄ‡ jako definicjÄ™  $\mathbb{E}[Y|X]$  w sytuacji, gdy wiemy Å¼e  $\mathbb{E}[Y^2] < \infty$ .

(14.7) **LEM.** (UÅ¼yteczny sposÃ³b liczenia WWO dla rozkÅ‚adÃ³w absolutnie ciÄ…gÅ‚ych) JeÅ›li (X, Y) ma rozkÅ‚ad o gÄ™stoÅ›ci  $f_{(X,Y)}$ , to warunkowy rozkÅ‚ad X pod warunkiem  $\{Y=y\}$  rÃ³wnieÅ¼ ma gÄ™stoÅ›Ä‡. Jest ona dana wzorem

$$f_{X|Y=y}(x) = \begin{cases} \frac{f_{(X,Y)}(x,y)}{f_Y(y)}, & f_Y(y) > 0, \\ 0, & f_Y(y) = 0. \end{cases}$$

Wtedy dla  $y \in \text{supp}(Y)$  mamy

$$\mathbb{P}(X \in A|Y = y) = \int_{A} f_{X|Y=y}(x)dx$$

lub ogÃ³lniej dla dowolnej funkcji borelowskiej h,

$$\mathbb{E}[h(X)|Y=y] = \int_{\mathbb{R}} h(x) f_{X|Y=y}(x) dx.$$

Szkic dowodu: Musimy pokazaÄ‡, Å¼e dla

$$m(y) = \int_{\mathbb{R}} h(x) f_{X|Y=y}(x) dx,$$

zachodzi warunek II, czyli

(\*) 
$$\mathbb{E}[h(X)\mathbb{1}_{Y\in B}] = \mathbb{E}[m(Y)\mathbb{1}_{Y\in B}], \qquad \forall B \in \mathcal{B}(\mathbb{R}).$$

PoniewaÅ¼ wektor (X,Y) ma gÄ™stoÅ›Ä‡, to rÃ³wnoÅ›Ä‡ (\*) jest rÃ³wnowaÅ¼na

$$\int_{B} \int_{\mathbb{R}} h(x) f_{(X,Y)}(x,y) dx dy = \int_{B} m(y) f_{Y}(y) dy.$$

Ale  $f_{X|Y=y}(x)f_Y(y) = f_{X,Y}(x,y)$  oraz

$$\int_B m(y)f_Y(y)dy = \int_B \int_{\mathbb{R}} h(x)f_{X|Y=y}(x)dx f_Y(y)dy = \int_B \int_{\mathbb{R}} h(x)f_{(X,Y)}(x,y)dx dy.$$

- (14.8)  $\triangle$  JeÅ›li znajdziemy  $\mathbb{E}[h(X)|Y=y]$  z powyÅ¼szego wzoru oraz wiemy, Å¼e  $\mathbb{E}[|h(X)|]<\infty$ , to E[h(X)|Y] dostajemy poprzez podstawienie Y w miejsce y.
- (14.9) Which  $f_{(X,Y)}(x,y) = \frac{1}{y^3} \mathbb{1}_{x>0,y\geq \max\{1,x\}}$ . Which  $f_{Y}(y) = \frac{1}{y^2} \mathbb{1}_{y\geq 1}$  orazidla  $y \in \text{supp}(Y) = [1,\infty), X|Y = y \sim U([0,y])$  oraz  $\mathbb{E}[X|Y = y] = y/2$ . Zatem  $\mathbb{E}[X|Y] = Y/2$ .
- (14.10) Niech  $(X,Y) \sim N_2(\underline{m},\Sigma)$ , gdzie  $\underline{m} = (m_1,m_2)^\top = (\mathbb{E}[X],\mathbb{E}[Y])^\top$  oraz

$$\Sigma = \begin{pmatrix} \operatorname{Var}[X] & \operatorname{Cov}[X,Y] \\ \operatorname{Cov}[X,Y] & \operatorname{Var}[Y] \end{pmatrix} = \begin{pmatrix} \sigma_X^2 & \rho \, \sigma_X \sigma_Y \\ \rho \, \sigma_X \sigma_Y & \sigma_Y^2 \end{pmatrix}.$$

Wtedy dla  $y \in \mathbb{R}$ ,

$$X|Y = y \sim N\left(m_1 + \rho \frac{\sigma_X}{\sigma_Y}(y - m_2), (1 - \rho^2)\sigma_X^2\right),$$

tzn. warunkowe rozkÅ‚ady wektora normalnego rÃ³wnieÅ¼ sÄ… normalne.

- (14.11) **Â©**\*OgÃ³lniejsza definicja WWO.
  - B RozwaÅ¼my przestrzeÅ„ probabilistycznÄ…  $(\Omega, \mathcal{F}, \mathbb{P})$  oraz  $\sigma$ -ciaÅ‚o  $\mathcal{G} \subset \mathcal{F}$ . JeÅ›li  $\mathbb{E}[|X|] < \infty$ , to warunkowÄ… wartoÅ›ciÄ… oczekiwanÄ… X pod warunkiem  $\sigma$ -ciaÅ‚a  $\mathcal{G}$  nazywamy zmiennÄ… losowÄ…  $\mathbb{E}[X|\mathcal{G}]$  speÅ‚niajÄ…cÄ… dwa warunki:
    - I  $\mathbb{E}[X|\mathcal{G}]$  jest  $\mathcal{G}$ -mierzalna,
    - II  $\mathbb{E}[X\mathbb{1}_B] = \mathbb{E}[\mathbb{E}[X|\mathcal{G}]\mathbb{1}_B]$  dla kaÅ¼dego  $B \in \mathcal{G}$ .
    - $\blacksquare$   $\sigma$ -ciaÅ‚em generowanym przez zmiennÄ… losowÄ… Y nazywamy rodzinÄ™  $\sigma(Y) = \{Y^{-1}(B) : B \in \mathcal{B}(\mathbb{R})\}$ .  $\Theta$  PokazaÄ‡, Å¼e rodzina  $\{Y^{-1}(B) : B \in \mathcal{B}(\mathbb{R})\}$  jest  $\sigma$ -ciaÅ‚em.
    - MoÅ¼na pokazaÄ‡, Å¼e zmienna losowa Z jest  $\sigma(Y)$ -mierzalna wtedy i tylko wtedy, gdy  $Z(\omega) = m(Y(\omega))$  dla pewnej borelowskiej funkcji m.
    - Zatem, WWO pod warunkiem zmiennej losowej definiowana wczeÅ›niej to po prostu  $\mathbb{E}[X|Y] = \mathbb{E}[X|\sigma(Y)]$ .
    - $\mathbf{A}$  PoniewaÅ¼ nie kaÅ¼de  $\sigma$ -ciaÅ‚o  $\mathcal{G}$  jest  $\sigma$ -ciaÅ‚em generowanym przez jakÄ…Å› zmiennÄ… losowÄ…, to powyÅ¼sza definicja jest ogÃ³lniejsza.

#### 15. W15 - Co warto pamietaÄ‡ + uzupeÅ‚nienia

- <span id="page-35-0"></span>(15.1) ÅšwiÄ™ta czwÃ³rka:  $\sigma$ -ciaÅ‚o, prawdopodobieÅ„stwo  $\mathbb{P}$ , zmienna losowa X, rozkÅ‚ad  $\mathbb{P}_X$ .
- (15.2) WzÃ³r wÅ‚Ä…czeÅ„ i wyÅ‚Ä…czeÅ„ (W1), WzÃ³r na prawdopodobienstwo caÅ‚kowite (W2), WzÃ³r Bayesa (W2).
- (15.3) NiezaleÅ¼noÅ›Ä‡ zdarzeÅ„ i zmiennych losowych, Lematy Borela-Cantellego (W3).
- (15.4) WartoÅ›Ä‡ oczekiwana:
  - dla rozkÅ‚adÃ³w dyskretnych.

Niech S bÄ™dzie zbiorem przeliczalnym dla ktÃ³rego  $\sum_{k \in S} \mathbb{P}(X = k) = 1$  oraz  $\mathbb{P}(X = k) > 0$  dla kaÅ¼dego

- X ma rozkÅ‚ad typu dyskretnego,
- $-S = \operatorname{supp}(X),$
- $\begin{array}{l} \ \mathbb{E}[h(X)] = \sum_{k \in \mathrm{supp}(X)} h(k) \mathbb{P}(X=k). \\ \ \mathrm{Te \ same \ wzory \ zachodza, \ gdy} \ X \ \mathrm{jest \ wektorem \ losowym.} \end{array}$
- dla rozkÅ‚adÃ³w absolutnie ciÄ…gÅ‚ych.

Niech  $F_X$  bÄ™dzie dystrybuantÄ… zmiennej losowej X. JeÅ›li  $\int_{\mathbb{R}} F_X'(x) dx = 1$ , to

- -X ma rozkÅ‚ad typu absolutnie ciaglego,
- gÄ™stoÅ›Ä‡ X to  $f_X = F_X'$ ,
- $-\mathbb{E}[h(X)] = \int_{\mathbb{R}} h(t) f_X(t) dt.$
- Dla wektorÃ³w losowych wymiaru n zamieniamy  $F_X'$  na  $\frac{\partial^n F}{\partial x_1...\partial x_n}$  i powyÅ¼sze trzy punkty nadal sÄ… prawdziwe.
- dla rozkÅ‚adow mieszanych dyskretno-absolutnie ciÄ…gÅ‚ych: Niech  $NC(F_X) = \{t \in \mathbb{R} : \Delta F_X(t) > 0\}$ . Wtedy

$$\mathbb{E}[h(X)] = \sum_{t \in NC(F_X)} h(t) \cdot \Delta F_X(t) + \int_{\mathbb{R}} h(t) F_X'(t) dt,$$

gdzie  $\Delta F_X(t) := F_X(t) - F_X(t-) = \mathbb{P}(X=t)$ . Elementy  $NC(F_X)$  nazywane sÄ… czasem <u>atomami</u> rozkÅ‚adu

â€¢ Dla ogolnych rozkÅ‚adÃ³w: JeÅ›li  $h(t) = \int_{-\infty}^{t} h'(s)ds$ , to

$$\mathbb{E}[h(X)] = \int_{\mathbb{R}} h(x) \mathbb{P}_X(dx) = \int_{\mathbb{R}} h'(t) (1 - F_X(t)) dt.$$

Szkic dowodu:

$$\int_{\mathbb{R}} \int_{\mathbb{R}} \mathbbm{1}_{s < x} h'(s) \, ds \, \mathbb{P}_X(dx) = \int_{\mathbb{R}} h'(s) \int_{\mathbb{R}} \mathbbm{1}_{s < x} \, \mathbb{P}_X(dx) \, ds = \int_{\mathbb{R}} h'(s) \mathbb{P}_X((s, \infty)) \, ds.$$

(15.5) Warunkowa wartoÅ›Ä‡ oczekiwana:

JeÅ›li znamy rozkÅ‚ad warunkowy X pod warunkiem Y = y, to dla dowolnej funkcji borelowskiej h

$$\mathbb{E}[h(X)|Y=y] = \int_{\mathbb{D}} h(x) \mathbb{P}_{X|Y=y}(dx),$$

gdzie w zaleÅ¼noÅ›ci od typu rozkÅ‚adu X|Y=y stosujemy jeden ze wzorÃ³w z poprzedniego punktu.

(15.6) Warunkowe rozkÅ‚ady:

Å»eby stosowaÄ‡ poprzedni punkt, powinniÅ›my umieÄ‡ znajdowaÄ‡ rozkÅ‚ad warunkowy X|Y=y.

f A ZnajomoÅ›Ä‡ rozkÅ‚adu warunkowego Y|X oraz rozkÅ‚adu X daje nam peÅ‚nÄ… informacjÄ™ odnoÅ›nie rozkÅ‚adu Å‚Ä…cznego: dla borelowskich zbiorÃ³w A i B mamy

$$\mathbb{P}(X \in A, Y \in B) = \mathbb{E}[\mathbb{1}_{X \in A} \mathbb{P}(Y \in B|X)].$$

MoÅ¼emy wtedy teÅ¼ znaleÅºÄ‡ rozkÅ‚ad warunkowy X|Y. PoniÅ¼sze wzory moÅ¼na traktowac jako wersje wzoru Bayesa.

 $\bullet\,$  JeÅ›li wektor (X,Y)ma rozkÅ‚ad typu dyskretnego, to

$$\mathbb{P}(X=k|Y=n) = \frac{\mathbb{P}(X=k,Y=n)}{\mathbb{P}(Y=n)} = \frac{\mathbb{P}(Y=n|X=k)\mathbb{P}(X=k)}{\sum_{m}\mathbb{P}(Y=n|X=m)\mathbb{P}(X=m)}.$$

â€¢ JeÅ›li wektor (X,Y) ma rozkÅ‚ad typu absolutnie ciÄ…gÅ‚ego, to

$$f_{X|Y=y}(x) = \frac{f_{(X,Y)}(x,y)}{f_Y(y)} = \frac{f_{Y|X=x}(y)f_X(x)}{\int_{\mathbb{R}} f_{Y|X=u}(y)f_X(u)du}.$$

â€¢ JeÅ›li rozkÅ‚ad X|Y=y jest typu dyskretnego, a Y absolutnie ciÄ…gly, to

$$\mathbb{P}(X = k | Y = y) = \frac{f_{Y|X=k}(y)\mathbb{P}(X = k)}{f_{Y}(y)} = \frac{f_{Y|X=k}(y)\mathbb{P}(X = k)}{\sum_{m} f_{Y|X=m}(y)\mathbb{P}(X = m)}.$$

 $\bullet\,$  JeÅ›li rozkÅ‚ad X|Y=kjest typu absolutnie ciÄ…gÅ‚ego, a Yma rozkÅ‚ad dyskretny, to

$$f_{X|Y=k}(x) = \frac{\mathbb{P}(Y=k|X=x)f_X(x)}{\mathbb{P}(Y=k)} = \frac{\mathbb{P}(Y=k|X=x)f_X(x)}{\int_{\mathbb{P}} \mathbb{P}(Y=k|X=u)f_X(u)du}.$$

â€¢  $\bullet$  Niech  $X \sim \mathrm{U}([0,1])$  oraz  $Y|X = x \sim \mathrm{b}(n,x)$ . Wtedy

$$f_{X|Y=k}(x) = \frac{\binom{n}{k} x^k (1-x)^{n-k} \mathbb{1}_{[0,1]}(x)}{\int_{\mathbb{R}} \binom{n}{k} u^k (1-u)^{n-k} \mathbb{1}_{[0,1]}(u) du} = \dots = C_{n,k} x^k (1-x)^{n-k} \mathbb{1}_{[0,1]}(x).$$

Jest to tzw. rozkÅ‚ad beta pierwszego rodzaju z parametrami  $k+1,\,n-k+1.$ 

(15.7) ZbieÅ¼noÅ›ci:  $\xrightarrow{1}$ ,  $\xrightarrow{\mathbb{P}}$ ,  $\xrightarrow{L_p}$ ,  $\xrightarrow{d}$  i zwiazki miÄ™dzy nimi:

$$\begin{array}{ccc}
\stackrel{1}{\longrightarrow} & \Longrightarrow \stackrel{\mathbb{P}}{\longrightarrow}, \\
\stackrel{L_p}{\longrightarrow} & \Longrightarrow \stackrel{\mathbb{P}}{\longrightarrow}, \\
\stackrel{\mathbb{P}}{\longrightarrow} & \Longrightarrow \stackrel{d}{\longrightarrow}, \\
X_n \stackrel{d}{\longrightarrow} c & \Longrightarrow X_n \stackrel{\mathbb{P}}{\longrightarrow} c.
\end{array}$$

PozostaÅ‚e implikacje w ogÃ³lnoÅ›ci nie zachodza.

(15.8) Twierdzenia graniczne:

â€¢ PWL: JeÅ›li  $(X_n)_n$  sÄ… i.i.d. oraz  $\mathbb{E}[|X_1|] < \infty$ , to (MPWL KoÅ‚mogorowa II)

$$\frac{\sum_{k=1}^{n} X_k}{n} \xrightarrow{1} \mathbb{E}[X_1].$$

â€¢ CTG: JeÅ›li  $(X_n)_n$  sÄ… i.i.d. oraz  $\mathbb{E}[X_1^2] < \infty$ , to

$$\sqrt{n} \left( \frac{\sum_{k=1}^{n} X_k}{n} - \mathbb{E}[X_1] \right) = \frac{\sum_{k=1}^{n} (X_k - \mathbb{E}[X_1])}{\sqrt{n}} \xrightarrow{d} Z \sim \mathcal{N}(0, \text{Var}(X)).$$

- IstniejÄ… wersje obu powyÅ¼szych twierdzeÅ„, gdy  $(X_n)_n$  sÄ… (trochÄ™) zaleÅ¼ne oraz ich rozkÅ‚ady (trochÄ™) siÄ™ rÃ³Å¼niÄ…. OczywiÅ›cie istniejÄ… teÅ¼ wersje, gdy zamiast ciÄ…gu zmiennych losowych rozwaÅ¼amy ciÄ…gi wektorÃ³w (wtedy mamy zbieÅ¼noÅ›Ä‡ do wielowymiarowego rozkÅ‚adu normalnego).
- Na powyÅ¼szych twierdzeniach granicznych opierajÄ… siÄ™ (standardowe) metody Monte Carlo.
- Twierdzeniach graniczne majÄ… olbrzymie znaczenie w statystyce.
- (15.9) Wielowymiarowy rozkÅ‚ad normalny:

Standardowo definiowany przez gÄ™stoÅ›Ä‡ dla  $\mu \in \mathbb{R}^n$  oraz  $\Sigma \in \operatorname{Sym}_+(n)$ ,

$$f_{\underline{X}}(\underline{x}) = \frac{1}{(\sqrt{2\pi})^n \sqrt{\det \Sigma}} e^{-\frac{1}{2}(\underline{x} - \underline{\mu})^\top \cdot \Sigma^{-1} \cdot (\underline{x} - \underline{\mu})}, \qquad \underline{x} \in \mathbb{R}^n.$$

W szczegÃ³lnoÅ›ci dla n=2 mamy

$$f_{(X_1,X_2)}(x_1,x_2) = \frac{1}{2\pi\sigma_1\sigma_2\sqrt{1-\rho^2}} \exp\left\{-\frac{1}{2(1-\rho^2)} \left[ \frac{(x_1-m_1)^2}{\sigma_1^2} - 2\rho \frac{(x_1-m_1)(x_2-m_2)}{\sigma_1\sigma_2} + \frac{(x_2-m_2)^2}{\sigma_2^2} \right] \right\},$$

gdzie  $\Sigma = \begin{pmatrix} \sigma_1^2 & \rho \sigma_1 \sigma_2 \\ \rho \sigma_1 \sigma_2 & \sigma_2^2 \end{pmatrix}$  oraz  $\rho$  jest wspoÅ‚czynnikiem korelacji zmiennych  $X_1$  i  $X_2$ .

WÅ‚asnoÅ›ci:

â€¢ rozkÅ‚ady brzegowe sÄ… normalne: dla  $A \subset \{1, \ldots, n\}$ ,

$$\underline{X}_A := (X_i \colon i \in A) \sim \mathcal{N}_{|A|}(\mu_{A}, \Sigma_{AA}),$$

gdzie  $\underline{\mu}_A = (\mu_i : i \in A) \text{ oraz } \Sigma_{AA} = (\Sigma_{ij})_{i,j \in A}.$ 

â€¢ rozkÅ‚ady warunkowe sÄ… normalne:

$$X|Y = y \sim N\left(m_1 + \rho \frac{\sigma_X}{\sigma_Y}(y - m_2), (1 - \rho^2)\sigma_X^2\right)$$

â€¢ Sumy niezaleÅ¼nych zmiennych losowych o rozkÅ‚adach normalnych nadal majÄ… rozkÅ‚ady normalne. Fakt ten moÅ¼na uogÃ³lniÄ‡ na przeksztaÅ‚cenia afiniczne.

ZaÅ‚Ã³Å¼my, Å¼e X âˆ¼ Nn(Âµ, Î£). Niech Y = AX + B, gdzie A âˆˆ Mat(k, n) jest macierzÄ… rzÄ™du k â‰¤ n oraz B âˆˆ R k . Wtedy

$$\underline{Y} \sim N_k(A\mu + \underline{B}, A\Sigma A^{\top}).$$

â€¢ Wiemy, Å¼e jeÅ›li X i Y sÄ… niezaleÅ¼ne, to Cov(X, Y ) = 0 (o ile istnieje).

LEM. ZaÅ‚Ã³Å¼my, Å¼e (X, Y ) âˆ¼ N2. JeÅ›li Cov(X, Y ) = 0, to X i Y sÄ… niezaleÅ¼ne.

Szkic dowodu: Åatwo widaÄ‡ z postaci gÄ™stoÅ›ci dla n = 2.

3 JeÅ›li (X, Y ) âˆ¼ N<sup>2</sup> oraz Î± = Cov(X, Y )/Var(X), to zmienne losowe

$$X$$
 oraz  $\tilde{Y} = Y - \alpha X$ 

sÄ… niezaleÅ¼ne. RzeczywiÅ›cie, X YËœ = X <sup>Y</sup> <sup>âˆ’</sup> Î±X = 1 0 âˆ’Î± 1 X Y , wiÄ™c (X, YËœ ) ma rozkÅ‚ad normalny. Ponadto,

$$Cov(X, Y - \alpha X) = Cov(X, Y) - \alpha Var(X) = 0.$$

- (15.10) Y Fakt, Å¼e X i Y sÄ… niezaleÅ¼ne zwykle oznacza siÄ™ przez X âŠ¥âŠ¥ Y .
- (15.11) Warunkowa niezaleÅ¼noÅ›Ä‡:

Przypomnijmy, Å¼e zmienne losowe X i Y sÄ… niezaleÅ¼ne jeÅ›li dla borelowskich zbiorÃ³w A i B mamy

$$\mathbb{P}(X \in A, Y \in B) = \mathbb{P}(X \in A)\mathbb{P}(Y \in B).$$

Jest to nie tylko wÅ‚asnoÅ›Ä‡ pary (X, Y ), ale rÃ³wnieÅ¼ prawdopodobieÅ„stwa P. Zamiast prawdopodobieÅ„stwa P moÅ¼emy rozwaÅ¼aÄ‡ inne, w szczegÃ³lnoÅ›ci p-stwo warunkowe. Powiemy, Å¼e X i Y sÄ… warunkowo niezaleÅ¼ne pod warunkiem zmiennej losowej Z, jeÅ›li

$$\mathbb{P}(X \in A, Y \in B|Z) = \mathbb{P}(X \in A|Z)\,\mathbb{P}(Y \in B|Z).$$

Wiele twierdzeÅ„ (w tym twierdzenia graniczne) zachodzi "warunkowo", gdy zastÄ…pimy zwykÅ‚Ä… niezaleÅ¼noÅ›Ä‡ przez warunkowÄ… niezaleÅ¼noÅ›Ä‡.

Projekt "NERW 2 PW. Nauka - Edukacja - RozwÃ³j - WspÃ³Å‚praca" wspÃ³Å‚finansowany ze Å›rodkÃ³w Unii Europejskiej w ramach Europejskiego Funduszu SpoÅ‚ecznego.

Zadanie 10 pn. "Modyfikacja programÃ³w studiÃ³w na kierunkach prowadzonych przez WydziaÅ‚ Matematyki i Nauk Informacyjnych", realizowane w ramach projektu "NERW 2 PW. Nauka - Edukacja - RozwÃ³j - WspÃ³Å‚praca", wspÃ³Å‚finansowanego jest ze Å›rodkÃ³w Unii Europejskiej w ramach Europejskiego Funduszu SpoÅ‚ecznego.

![](_page_37_Picture_21.jpeg)

![](_page_37_Picture_22.jpeg)

![](_page_37_Picture_24.jpeg)